import pandas as pd
import re

# Sample data frames for photos and physical condition sheet
photos_df = pd.DataFrame({
    'photo_number': [1, 2, 3, 4],
    'general_label': ['exterior', 'interior', 'roof', 'deferred maintenance'],
    'specific_description': ['front view of building', 'living room', 'roof shingles', 'broken window']
})

physical_condition_df = pd.DataFrame({
    'category': ['Building Exteriors', 'Occupied Units / Space', 'Building Roofs', 'Deferred Maintenance Items'],
    'subcategories': [
        'Siding; Trim; Paint; Windows; Exterior Entry Ways; Stairs; Railings; Balconies; Patios; Gutters; Downspouts; Foundations; Doors; Fa√ßade; Structure (Beam/Joist)',
        'HVAC; Ceiling; Floors; Walls; Painting; Wall Cover; Floor Cover; Tiles; Windows; Countertop; Cabinets; Appliances; Lighting; Electrical; Bathroom Accessories; Plumbing Fixtures; Storage; Basements / Attics',
        'Roof Condition; Roof Access; Top Floor Ceilings; Shingles / Membrane; Skylights; Flashing; Parapet Walls; Mansard Roofs',
        'Majority or minority of maintenance items with associated photo and cost'
    ]
})

# Define keyword mapping
keyword_mapping = {
    'exterior': 'Building Exteriors',
    'interior': 'Occupied Units / Space',
    'roof': 'Building Roofs',
    'neighborhood': 'Curb Appeal',
    'routine maintenance': 'Routine Maintenance',
    'deferred maintenance': 'Deferred Maintenance Items',
    'life safety': 'Environmental'
}

subcategory_mapping = {
    'HVAC': 'HVAC',
    'paint': 'Painting',
    'pool': 'Pool',
    'window': 'Windows',
    'roof shingles': 'Shingles / Membrane'
}

def map_photo_to_category(photo):
    general_label = photo['general_label'].lower()
    specific_description = photo['specific_description'].lower()
    
    # Map general label to category
    category = keyword_mapping.get(general_label, 'Unknown Category')
    
    # Find matching subcategory
    for keyword, subcategory in subcategory_mapping.items():
        if re.search(keyword, specific_description):
            return category, subcategory
    
    return category, 'General'

# Apply mapping to photos data frame
photos_df[['mapped_category', 'mapped_subcategory']] = photos_df.apply(map_photo_to_category, axis=1, result_type='expand')

print(photos_df)













============================================
import openpyxl
import re

def extract_information_from_sheet(sheet):
    data = {}
    for row in sheet.iter_rows(values_only=True):
        if any(row):
            for cell in row:
                if cell:
                    if re.search(r'Physical Condition Assessment and Deferred Maintenance', str(cell)):
                        data['Physical Condition'] = {}
                    elif re.search(r'Curb Appeal', str(cell)):
                        data['Curb Appeal'] = {}
                    elif re.search(r'Site', str(cell)):
                        data['Site'] = {}
                    elif re.search(r'Building / Mechanical Systems', str(cell)):
                        data['Building / Mechanical Systems'] = {}
                    elif re.search(r'Building Exteriors', str(cell)):
                        data['Building Exteriors'] = {}
                    elif re.search(r'Building Roofs', str(cell)):
                        data['Building Roofs'] = {}
                    elif re.search(r'Occupied Units / Space', str(cell)):
                        data['Occupied Units / Space'] = {}
                    elif re.search(r'Vacant Units / Space / Hotel Rooms', str(cell)):
                        data['Vacant Units / Space / Hotel Rooms'] = {}
                    elif re.search(r'Down Units / Space / Hotel Rooms', str(cell)):
                        data['Down Units / Space / Hotel Rooms'] = {}
                    elif re.search(r'Interior Common Areas', str(cell)):
                        data['Interior Common Areas'] = {}
                    elif re.search(r'Amenities', str(cell)):
                        data['Amenities'] = {}
                    elif re.search(r'Environmental', str(cell)):
                        data['Environmental'] = {}
                    elif re.search(r'Inspector Comments', str(cell)):
                        last_key = list(data.keys())[-1]
                        last_subkey = list(data[last_key].keys())[-1]
                        data[last_key][last_subkey] = cell.split(": ")[1].strip()
                    elif re.search(r'Rating', str(cell)):
                        last_key = list(data.keys())[-1]
                        data[last_key]['Rating'] = cell.split(": ")[1].strip()
                    elif re.search(r'Trend', str(cell)):
                        last_key = list(data.keys())[-1]
                        data[last_key]['Trend'] = cell.split(": ")[1].strip()
                    else:
                        last_key = list(data.keys())[-1]
                        data[last_key]['Inspector Comments'] = cell.strip()
    return data

def main():
    # Load the workbook
    workbook = openpyxl.load_workbook('/path/to/your/excel/file.xlsx')

    # Select the relevant sheet
    sheet = workbook['Sheet1']  # Change to the correct sheet name

    # Extract information
    extracted_data = extract_information_from_sheet(sheet)

    # Print extracted information
    for section, details in extracted_data.items():
        print(f"{section}:")
        for key, value in details.items():
            print(f"  {key}: {value}")
        print()

if __name__ == "__main__":
    main()


-----------------------------------------------------------


import openpyxl
import re
from openpyxl.utils import get_column_letter

def parse_excel_form(file_path):
    workbook = openpyxl.load_workbook(file_path)
    sheet = workbook.active
    
    data = {}
    
    # Define the sections and their row ranges (adjust as needed)
    sections = {
        'Curb Appeal': (2, 5),
        'Site': (6, 10),
        'Building / Mechanical Systems': (11, 15),
        'Building Exteriors': (16, 20),
        'Building Roofs': (21, 25),
        'Occupied Units / Space': (26, 30),
        'Vacant Units / Space / Hotel Rooms': (31, 35),
        'Down Units / Space / Hotel Rooms': (36, 40),
        'Interior Common Areas': (41, 45),
        'Amenities': (46, 50),
        'Environmental': (51, 55)
    }
    
    for section, (start_row, end_row) in sections.items():
        section_data = {}
        for row in range(start_row, end_row + 1):
            cell_value = sheet[f'A{row}'].value
            if cell_value:
                if cell_value == 'Rating':
                    rating = sheet[f'B{row}'].value
                    section_data['Rating'] = rating
                elif cell_value == 'Trend':
                    trend = sheet[f'C{row}'].value
                    section_data['Trend'] = trend
                elif cell_value == 'Inspector Comments':
                    comments = sheet[f'B{row}'].value
                    section_data['Inspector Comments'] = comments
        data[section] = section_data
    
    # Extract additional descriptions
    exterior_desc = sheet['B56'].value
    interior_desc = sheet['B57'].value
    data['Exterior Additional Description'] = exterior_desc
    data['Interior Additional Description'] = interior_desc
    
    return data

# Usage
file_path = 'path_to_your_excel_file.xlsx'
parsed_data = parse_excel_form(file_path)

# Print the extracted data
for section, section_data in parsed_data.items():
    print(f"\n{section}:")
    for key, value in section_data.items():
        print(f"  {key}: {value}")

===========================================


import json
from PIL.TiffImagePlugin import IFDRational

def convert_unexpected_types(d):
    expected_types = (list, tuple, str, int, float, type(None))
    
    if isinstance(d, dict):
        return {k: convert_unexpected_types(v) for k, v in d.items()}
    elif isinstance(d, list) or isinstance(d, tuple):
        return [convert_unexpected_types(i) for i in d]
    elif isinstance(d, IFDRational):
        return float(d)
    elif not isinstance(d, expected_types):
        return str(d)  # Convert any other unexpected types to string
    else:
        return d
-----------------------------------------

def find_unexpected_type(d):
    expected_types = (list, tuple, str, int, float, type(None))
    
    if isinstance(d, dict):
        for key, value in d.items():
            if not isinstance(key, expected_types):
                return type(key)
            result = find_unexpected_type(value)
            if result is not None:
                return result
    elif isinstance(d, list) or isinstance(d, tuple):
        for item in d:
            result = find_unexpected_type(item)
            if result is not None:
                return result
    elif not isinstance(d, expected_types):
        return type(d)
    
    return None





==============================================
excel to image
-----------------------------------------

import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

# Function to convert a specific sheet of an xlsm file to an image
def convert_sheet_to_image(file_path, sheet_name, output_image_path):
    # Load the .xlsm file
    xlsm_file = pd.ExcelFile(file_path)

    # Load the specified sheet into a DataFrame
    df = pd.read_excel(xlsm_file, sheet_name=sheet_name)

    # Plot the DataFrame using matplotlib
    fig, ax = plt.subplots(figsize=(len(df.columns) * 2, len(df) * 0.5))  # Adjust the figure size as needed
    ax.axis('tight')
    ax.axis('off')
    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center', edges='B')

    # Save the plot to a high-quality image file
    plt.savefig(output_image_path, bbox_inches='tight', dpi=300)

    # Optionally, open the image and save it with Pillow for additional adjustments
    image = Image.open(output_image_path)
    image.save(output_image_path, 'PNG', quality=95)

    print(f"Spreadsheet '{sheet_name}' has been converted to an image at '{output_image_path}'.")

# Specify the file path, sheet name, and output image path
file_path = 'path/to/your/file.xlsm'
sheet_name = 'Sheet1'
output_image_path = 'spreadsheet_image.png'

# Convert the sheet to an image
convert_sheet_to_image(file_path, sheet_name, output_image_path)














------=========================

import openpyxl
from openpyxl.utils import get_column_letter
from PIL import Image, ImageDraw, ImageFont
import os

def excel_sheet_to_image(excel_file, sheet_name, output_file, dpi=300):
    # Load the workbook and select the sheet
    wb = openpyxl.load_workbook(excel_file)
    sheet = wb[sheet_name]

    # Calculate the image size based on the sheet dimensions and DPI
    max_row = sheet.max_row
    max_col = sheet.max_column
    cell_width = 100  # Adjust as needed
    cell_height = 20  # Adjust as needed
    img_width = max_col * cell_width
    img_height = max_row * cell_height

    # Create a new image with a white background
    img = Image.new('RGB', (img_width, img_height), color='white')
    draw = ImageDraw.Draw(img)

    # Use a monospaced font
    font_size = 10
    font = ImageFont.truetype("arial.ttf", font_size)

    # Draw cell contents
    for row in range(1, max_row + 1):
        for col in range(1, max_col + 1):
            cell = sheet.cell(row=row, column=col)
            cell_value = str(cell.value) if cell.value is not None else ""
            x = (col - 1) * cell_width
            y = (row - 1) * cell_height
            draw.text((x + 5, y + 5), cell_value, fill='black', font=font)

    # Draw grid lines
    for row in range(max_row + 1):
        y = row * cell_height
        draw.line([(0, y), (img_width, y)], fill='lightgray')

    for col in range(max_col + 1):
        x = col * cell_width
        draw.line([(x, 0), (x, img_height)], fill='lightgray')

    # Save the image
    img.save(output_file, dpi=(dpi, dpi))
    print(f"Image saved as {output_file}")

# Example usage
excel_file = "path/to/your/excel/file.xlsx"
sheet_name = "Sheet1"
output_file = "output_image.png"
excel_sheet_to_image(excel_file, sheet_name, output_file)

------------------------------------------------------------------------------------------------
import xlsx2image

# Load the Excel file
wb = openpyxl.load_workbook('your_spreadsheet.xlsx')
sheet = wb.active

# Convert the sheet to an image
img_path = 'output.png'
xlsx2image.convert_sheet_to_image(sheet, img_path, dpi=300)

---------------------------------------------------------------------------------------









====================================================
textract
------------------------------------------------------
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import boto3
import io

# Function to convert a DataFrame to an image
def df_to_image(df, filename):
    fig, ax = plt.subplots(figsize=(12, len(df) * 0.5))  # Adjust size as needed
    ax.axis('tight')
    ax.axis('off')
    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')
    fig.savefig(filename, bbox_inches='tight')
    plt.close(fig)

# Load Excel file
excel_file = 'your_excel_file.xlsx'
xls = pd.ExcelFile(excel_file)

# Convert each sheet to an image
image_files = []
for sheet_name in xls.sheet_names:
    df = pd.read_excel(xls, sheet_name=sheet_name)
    image_file = f'{sheet_name}.png'
    df_to_image(df, image_file)
    image_files.append(image_file)

# Initialize Textract client
textract = boto3.client('textract')

def extract_text_from_image(image_file):
    with open(image_file, 'rb') as img_file:
        img_bytes = img_file.read()

    response = textract.detect_document_text(Document={'Bytes': img_bytes})

    text = ""
    for item in response["Blocks"]:
        if item["BlockType"] == "LINE":
            text += item["Text"] + "\n"

    return text

# Extract text from each image
for image_file in image_files:
    extracted_text = extract_text_from_image(image_file)
    print(f"Extracted text from {image_file}:\n{extracted_text}")


















=-=======================================================
import openpyxl
from openpyxl_image_loader import SheetImageLoader
import os
import json
from PIL import Image
import io

def extract_image_metadata(sheet, output_dir):
    image_loader = SheetImageLoader(sheet)
    data = {}
    
    for row in sheet.iter_rows(min_row=2, values_only=True):
        title, mf_address, overall_rating, percentage_occupied, num_photos = row[:5]
        
        # Assuming images start from column F (6th column)
        for col in range(6, sheet.max_column, 2):
            cell = sheet.cell(row=row[0], column=col)
            if cell.value is not None:
                image = image_loader.get(cell.coordinate)
                if image:
                    photo_number = sheet.cell(row=row[0], column=col+1).value
                    general_label = sheet.cell(row=row[0]+1, column=col+1).value
                    description = sheet.cell(row=row[0]+2, column=col+1).value
                    
                    # Extract image metadata
                    img_byte_arr = io.BytesIO()
                    image.save(img_byte_arr, format='PNG')
                    img_byte_arr = img_byte_arr.getvalue()
                    
                    pil_image = Image.open(io.BytesIO(img_byte_arr))
                    metadata = {
                        "format": pil_image.format,
                        "mode": pil_image.mode,
                        "size": pil_image.size,
                    }
                    
                    # Save image
                    image_filename = f"{title}_{photo_number}.png"
                    image_path = os.path.join(output_dir, image_filename)
                    image.save(image_path)
                    
                    # Store data
                    if title not in data:
                        data[title] = {
                            "MF_address": mf_address,
                            "overall_rating": overall_rating,
                            "percentage_occupied": percentage_occupied,
                            "num_photos": num_photos,
                            "photos": []
                        }
                    
                    data[title]["photos"].append({
                        "photo_number": photo_number,
                        "general_label": general_label,
                        "description": description,
                        "image_filename": image_filename,
                        "metadata": metadata
                    })
    
    return data

def main():
    # Load the workbook and select the "Photos" sheet
    workbook = openpyxl.load_workbook('your_spreadsheet.xlsx')
    sheet = workbook['Photos']
    
    # Create output directory
    output_dir = 'outputs/image_metadata_output'
    os.makedirs(output_dir, exist_ok=True)
    
    # Extract data and save images
    data = extract_image_metadata(sheet, output_dir)
    
    # Save data as JSON
    with open(os.path.join(output_dir, 'metadata.json'), 'w') as f:
        json.dump(data, f, indent=2)
    
    print(f"Extraction complete. Data and images saved in {output_dir}")

if __name__ == "__main__":
    main()

-----------------------------------------

import os
import json
from openpyxl import load_workbook
from openpyxl.drawing.image import Image as OpenpyxlImage
from PIL import Image as PilImage
from openpyxl.utils import get_column_letter

# Function to save images
def save_images(output_dir, image, image_name):
    image_path = os.path.join(output_dir, f"{image_name}.png")
    image.save(image_path)
    return image_path

# Function to extract images and metadata
def extract_images_and_metadata(sheet, output_dir):
    data = {
        "title": sheet["A1"].value,
        "MF_address": sheet["A2"].value,
        "Overall_rating": sheet["A3"].value,
        "Percentage_occupied": sheet["A4"].value,
        "Number_of_photos": sheet["A5"].value,
        "photos": []
    }
    
    row = 6  # Assuming images and their metadata start from row 6
    col = 1  # Assuming images are in the first column

    while True:
        cell = sheet.cell(row=row, column=col)
        if not cell.value:
            break  # Exit loop if there is no more data

        img = None
        for image in sheet._images:
            if image.anchor._from.row == row - 1:  # Images are usually anchored to the row above their cell
                img = PilImage.open(image.ref)
                break

        if img:
            image_name = f"image_{row - 5}"
            image_path = save_images(output_dir, img, image_name)
            
            metadata = {
                "photo_number": sheet.cell(row=row, column=col + 1).value,
                "general_label": sheet.cell(row=row, column=col + 2).value,
                "detailed_description": sheet.cell(row=row, column=col + 3).value,
                "image_path": image_path
            }
            data["photos"].append(metadata)
        
        row += 1

    return data

# Load the Excel workbook
file_path = 'path_to_your_file.xlsm'
wb = load_workbook(filename=file_path, data_only=True)
sheet = wb["Photos"]

# Create output directory
output_dir = f"outputs/{os.path.splitext(os.path.basename(file_path))[0]}"
os.makedirs(output_dir, exist_ok=True)

# Extract images and metadata
data = extract_images_and_metadata(sheet, output_dir)

# Save metadata to a JSON file
metadata_file = os.path.join(output_dir, "metadata.json")
with open(metadata_file, "w") as f:
    json.dump(data, f, indent=4)

print("Data extraction and saving completed successfully.")






================================================================================

image metadata
--------------------------------------------------

import openpyxl
from openpyxl_image_loader import SheetImageLoader
from PIL import Image
import io
import os
import datetime

def extract_image_metadata(excel_file, output_folder):
    # Get Excel file modification time
    excel_mod_time = datetime.datetime.fromtimestamp(os.path.getmtime(excel_file))
    
    # Load the workbook
    workbook = openpyxl.load_workbook(excel_file)
    
    # Iterate through all sheets
    for sheet_name in workbook.sheetnames:
        sheet = workbook[sheet_name]
        image_loader = SheetImageLoader(sheet)
        
        # Iterate through all cells in the sheet
        for row in sheet.iter_rows():
            for cell in row:
                if image_loader.image_in(cell.coordinate):
                    # Extract image
                    image = image_loader.get(cell.coordinate)
                    
                    # Save image
                    image_filename = f"{sheet_name}_{cell.coordinate}.png"
                    image_path = os.path.join(output_folder, image_filename)
                    image.save(image_path)
                    
                    # Extract metadata
                    with Image.open(io.BytesIO(image.data)) as img:
                        metadata = {
                            "filename": image_filename,
                            "format": img.format,
                            "mode": img.mode,
                            "size": img.size,
                            "cell": cell.coordinate,
                            "sheet": sheet_name,
                            "excel_last_modified": excel_mod_time.isoformat()
                        }
                        
                        # If EXIF data is available, add it to metadata
                        exif_data = img._getexif()
                        if exif_data:
                            # Extract DateTimeOriginal and DateTimeDigitized if available
                            date_time_original = exif_data.get(36867)  # 36867 is the tag for DateTimeOriginal
                            date_time_digitized = exif_data.get(36868)  # 36868 is the tag for DateTimeDigitized
                            
                            if date_time_original:
                                metadata["image_date_time_original"] = date_time_original
                            if date_time_digitized:
                                metadata["image_date_time_digitized"] = date_time_digitized
                            
                            metadata["exif"] = exif_data
                    
                    # Save metadata (you can modify this to save in your preferred format)
                    metadata_filename = f"{sheet_name}_{cell.coordinate}_metadata.txt"
                    metadata_path = os.path.join(output_folder, metadata_filename)
                    with open(metadata_path, 'w') as f:
                        for key, value in metadata.items():
                            f.write(f"{key}: {value}\n")
                    
                    print(f"Extracted image and metadata from {sheet_name}, cell {cell.coordinate}")

# Usage
excel_file = "path/to/your/excel/file.xlsx"
output_folder = "path/to/output/folder"
extract_image_metadata(excel_file, output_folder)










































































import openpyxl
import pandas as pd

# Load the workbook
workbook = openpyxl.load_workbook('your_file.xlsm', data_only=True)

# Access different sheets
sheet_names = workbook.sheetnames
for sheet_name in sheet_names:
    sheet = workbook[sheet_name]
    # Process each sheet as needed

---------------------------

import pandas as pd
import openpyxl
from openpyxl.drawing.image import Image
import os
import re
from collections import defaultdict
from PIL import Image as PILImage
import io

def extract_xlsm_data(file_path):
    # Create output directories
    os.makedirs('output/text', exist_ok=True)
    os.makedirs('output/images', exist_ok=True)
    os.makedirs('output/dataframes', exist_ok=True)

    # Load the workbook
    wb = openpyxl.load_workbook(file_path, data_only=True)

    # Dictionary to store classified information
    classified_info = defaultdict(list)

    for sheet_name in wb.sheetnames:
        sheet = wb[sheet_name]
        
        # Extract tables and convert to dataframes
        tables = {}
        for table in sheet._tables:
            df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl', skiprows=table.ref.min_row - 1, nrows=table.ref.max_row - table.ref.min_row + 1)
            tables[table.name] = df
            df.to_csv(f'output/dataframes/{sheet_name}_{table.name}.csv', index=False)
            
            # Classify information
            for col in df.columns:
                if 'comment' in col.lower():
                    classified_info['comments'].extend(df[col].dropna().tolist())
                elif 'risk' in col.lower():
                    classified_info['risk_ratings'].extend(df[col].dropna().tolist())
                elif 'cost' in col.lower() or 'repair' in col.lower():
                    classified_info['cost_repair'].extend(df[col].dropna().tolist())

        # Extract text data
        text_data = []
        for row in sheet.iter_rows(values_only=True):
            text_data.extend([str(cell) for cell in row if cell is not None])
        
        with open(f'output/text/{sheet_name}_text.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(text_data))
        
        # Classify text data
        for text in text_data:
            if re.search(r'\d+(\.\d{2})?', text):  # Possible cost
                classified_info['cost_repair'].append(text)
            elif any(keyword in text.lower() for keyword in ['repair', 'fix', 'replace']):
                classified_info['repair'].append(text)
            elif len(text.split()) > 5:  # Assume longer texts are comments
                classified_info['comments'].append(text)

        # Extract images
        for idx, image in enumerate(sheet._images):
            if isinstance(image, Image):
                try:
                    image_data = image.ref
                    img = PILImage.open(io.BytesIO(image_data))
                    img.save(f'output/images/{sheet_name}_image_{idx}.png')
                except Exception as e:
                    print(f"Error saving image from {sheet_name}, image {idx}: {str(e)}")

    # Save classified information
    for category, items in classified_info.items():
        with open(f'output/text/classified_{category}.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(items))

    return tables, classified_info

# Usage
file_path = 'path_to_your_xlsm_file.xlsm'
tables, classified_info = extract_xlsm_data(file_path)

print("Extraction complete. Check the 'output' directory for results.")
-----------------------------

class PropertyComponent:
    def __init__(self, name, risk_rating, comments, repair_costs, images):
        self.name = name
        self.risk_rating = risk_rating
        self.comments = comments
        self.repair_costs = repair_costs
        self.images = images

class Unit(PropertyComponent):
    def __init__(self, unit_number, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.unit_number = unit_number

class Building(PropertyComponent):
    def __init__(self, building_number, units, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.building_number = building_number
        self.units = units

class Property:
    def __init__(self, name, buildings):
        self.name = name
        self.buildings = buildings





-------------------------

import os
import shutil

def organize_data(property):
    base_path = f"./organized_data/{property.name}"
    for building in property.buildings:
        for unit in building.units:
            for component in ['kitchen', 'bathroom', 'living_room']:  # Add more as needed
                component_path = f"{base_path}/building_{building.building_number}/unit_{unit.unit_number}/{component}"
                os.makedirs(component_path, exist_ok=True)
                # Save relevant data and images to this folder

---------------------------


from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing import image
from transformers import pipeline

# Load pre-trained models
image_model = ResNet50(weights='imagenet', include_top=False)
nlp_model = pipeline("sentiment-analysis")

def validate_risk_score(component):
    # Process images
    img_features = []
    for img_path in component.images:
        img = image.load_img(img_path, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        img_features.append(image_model.predict(x))
    
    # Process text
    text_sentiment = nlp_model(component.comments)[0]['score']
    
    # Combine features and predict risk score
    combined_features = np.concatenate([np.mean(img_features, axis=0), [text_sentiment]])
    predicted_score = your_custom_model.predict(combined_features)
    
    return abs(predicted_score - component.risk_rating) < threshold

============================

from ultralytics import YOLO

# Load a pretrained YOLOv8 model
model = YOLO('yolov8x.pt')

# Fine-tune the model on your custom dataset
results = model.train(data='path/to/your/dataset.yaml', epochs=100, imgsz=640)

# Run inference on an image
results = model('path/to/image.jpg')

# Process results
for r in results:
    boxes = r.boxes  # Bounding boxes
    masks = r.masks  # Segmentation masks
    probs = r.probs  # Class probabilities

---------------------------

from multimodal_model import load_model  # Hypothetical import

# Load the multimodal model
model = load_model("gpt4v")  # or "flamingo", etc.

def validate_inspection(image_paths, inspector_comments, risk_score):
    # Prepare the prompt
    prompt = f"Analyze these property inspection images and the inspector's comments: '{inspector_comments}'. Does the visual evidence support the given risk score of {risk_score}? Explain your reasoning."

    # Process images and text
    result = model.generate(images=image_paths, text=prompt)

    # Analyze the model's response
    if "The risk score appears accurate" in result:
        return True, result
    else:
        return False, result

# Example usage
image_paths = ["kitchen.jpg", "bathroom.jpg", "living_room.jpg"]
comments = "Noticed minor mold in bathroom, kitchen appliances outdated, living room in good condition."
risk_score = 3  # On a scale of 1-5

is_valid, explanation = validate_inspection(image_paths, comments, risk_score)
print(f"Risk score valid: {is_valid}")
print(f"Explanation: {explanation}")

====================================



import torch
import torchvision
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision.models import resnet50
from torchvision.transforms import functional as F
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

def load_image(image_path):
    image = Image.open(image_path).convert("RGB")
    return image

def preprocess_image(image):
    image = F.to_tensor(image)
    return image.unsqueeze(0)

# Load and use Mask R-CNN
def use_mask_rcnn(image_path):
    # Load pre-trained Mask R-CNN model
    model = maskrcnn_resnet50_fpn(pretrained=True)
    model.eval()

    # Load and preprocess the image
    image = load_image(image_path)
    input_tensor = preprocess_image(image)

    # Run inference
    with torch.no_grad():
        prediction = model(input_tensor)

    # Process results (example: print bounding boxes and labels)
    boxes = prediction[0]['boxes'].tolist()
    labels = prediction[0]['labels'].tolist()
    scores = prediction[0]['scores'].tolist()
    masks = prediction[0]['masks']

    print("Mask R-CNN Results:")
    for box, label, score in zip(boxes, labels, scores):
        if score > 0.5:  # You can adjust this threshold
            print(f"Label: {label}, Score: {score:.2f}, Box: {box}")

    # You can further process masks here if needed

# Load and use ResNet
def use_resnet(image_path):
    # Load pre-trained ResNet model
    model = resnet50(pretrained=True)
    model.eval()

    # Load and preprocess the image
    image = load_image(image_path)
    input_tensor = preprocess_image(image)

    # Run inference
    with torch.no_grad():
        output = model(input_tensor)

    # Process results
    probabilities = torch.nn.functional.softmax(output[0], dim=0)
    top_prob, top_catid = torch.topk(probabilities, 1)

    print("ResNet Results:")
    print(f"Top category: {top_catid.item()}, Probability: {top_prob.item():.2f}")

# Example usage
image_path = "path/to/your/image.jpg"
use_mask_rcnn(image_path)
use_resnet(image_path)


------------------------


def use_mask_rcnn_for_property_inspection(image_path):
    # Assume model is fine-tuned for property inspection
    model = maskrcnn_resnet50_fpn(num_classes=your_num_classes)
    model.load_state_dict(torch.load('path_to_your_finetuned_model.pth'))
    model.eval()

    image = load_image(image_path)
    input_tensor = preprocess_image(image)

    with torch.no_grad():
        prediction = model(input_tensor)

    boxes = prediction[0]['boxes'].tolist()
    labels = prediction[0]['labels'].tolist()
    scores = prediction[0]['scores'].tolist()

    property_issues = []
    for box, label, score in zip(boxes, labels, scores):
        if score > 0.5:
            issue = your_class_list[label]
            property_issues.append({
                'issue': issue,
                'confidence': score,
                'location': box
            })

    return property_issues
-----------------

================


pip install ultralytics

from ultralytics import YOLO
import cv2
import numpy as np

def load_image(image_path):
    return cv2.imread(image_path)

def process_image_with_yolo(image_path, model_path='yolov8n.pt'):
    # Load a pretrained YOLOv8 model
    model = YOLO(model_path)

    # Load the image
    image = load_image(image_path)

    # Run inference on the image
    results = model(image)

    # Process and visualize results
    for result in results:
        boxes = result.boxes.cpu().numpy()
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].astype(int)
            conf = box.conf[0]
            cls = int(box.cls[0])

            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, f'{model.names[cls]} {conf:.2f}',
                        (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # Display the image
    cv2.imshow('YOLOv8 Detection', image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    return results

# Example usage
image_path = "path/to/your/property_image.jpg"
results = process_image_with_yolo(image_path)

# Print detection results
for r in results:
    print(r.boxes)  # print the detection boxes
    print(r.boxes.xyxy)  # print box coordinates
    print(r.boxes.conf)  # print confidence scores
    print(r.boxes.cls)   # print class indices


from ultralytics import YOLO

# Load a pretrained YOLOv8 model
model = YOLO('yolov8n.pt')

# Train the model on your custom dataset
results = model.train(data='path/to/your/dataset.yaml', epochs=100, imgsz=640)

# Evaluate the model's performance
results = model.val()

# Use the model for inference on new images
results = model('path/to/new/image.jpg')


from ultralytics import YOLO
import cv2

def inspect_property(image_path, model_path='path/to/your/finetuned_model.pt'):
    # Load your fine-tuned model
    model = YOLO(model_path)

    # Run inference
    results = model(image_path)

    # Process results
    issues_detected = []
    for r in results:
        boxes = r.boxes
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            conf = box.conf[0].item()
            cls = int(box.cls[0])
            issue_type = model.names[cls]
            
            issues_detected.append({
                'type': issue_type,
                'confidence': conf,
                'location': (x1, y1, x2, y2)
            })

    return issues_detected

# Example usage
image_path = "path/to/property_image.jpg"
issues = inspect_property(image_path)

for issue in issues:
    print(f"Detected {issue['type']} with {issue['confidence']:.2f} confidence at location {issue['location']}")




=============================


pip install transformers pytorch-lightning torchvision

import torch
from transformers import VisualBertForQuestionAnswering, VisualBertTokenizer
from torchvision.transforms import Resize, ToTensor, Normalize
from PIL import Image

def load_image(image_path):
    image = Image.open(image_path).convert("RGB")
    return image

def preprocess_image(image):
    transform = torch.nn.Sequential(
        Resize((224, 224)),
        ToTensor(),
        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    )
    return transform(image).unsqueeze(0)

def analyze_property(image_path, question, model, tokenizer):
    # Load and preprocess the image
    image = load_image(image_path)
    image_tensor = preprocess_image(image)

    # Tokenize the question
    inputs = tokenizer(question, return_tensors="pt", padding=True, truncation=True)

    # Forward pass
    with torch.no_grad():
        outputs = model(input_ids=inputs.input_ids,
                        attention_mask=inputs.attention_mask,
                        visual_embeds=image_tensor)

    # Get the predicted answer
    predicted_answer = tokenizer.decode(outputs.logits.argmax().item())

    return predicted_answer

# Load pre-trained VisualBERT model and tokenizer
model = VisualBertForQuestionAnswering.from_pretrained("uclanlp/visualbert-vqa")
tokenizer = VisualBertTokenizer.from_pretrained("bert-base-uncased")

# Example usage
image_path = "path/to/your/property_image.jpg"
question = "Is there any visible damage to the roof?"

answer = analyze_property(image_path, question, model, tokenizer)
print(f"Question: {question}")
print(f"Answer: {answer}")


def inspect_property(image_path, model, tokenizer):
    inspection_results = {}
    
    questions = [
        "Is there any visible damage to the roof?",
        "What is the condition of the exterior paint?",
        "Are there any signs of foundation issues?",
        "Is the landscaping well-maintained?",
        "Are there any visible plumbing issues?"
    ]
    
    for question in questions:
        answer = analyze_property(image_path, question, model, tokenizer)
        inspection_results[question] = answer
    
    return inspection_results

# Example usage
image_path = "path/to/property_image.jpg"
results = inspect_property(image_path, model, tokenizer)

for question, answer in results.items():
    print(f"Q: {question}")
    print(f"A: {answer}\n")


===============================


pip install torch torchvision transformers vilbert-python

import torch
from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize
from PIL import Image
from vilbert.vilbert import VILBertForVLTasks
from vilbert.vilbert_utils import BertTokenizer

def load_image(image_path):
    return Image.open(image_path).convert("RGB")

def preprocess_image(image):
    transform = Compose([
        Resize((224, 224)),
        CenterCrop(224),
        ToTensor(),
        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return transform(image).unsqueeze(0)

def analyze_property(image_path, question, model, tokenizer):
    # Load and preprocess the image
    image = load_image(image_path)
    image_tensor = preprocess_image(image)

    # Tokenize the question
    tokens = tokenizer.encode(question, add_special_tokens=True)
    tokens = torch.tensor(tokens).unsqueeze(0)

    # Prepare inputs
    image_features = torch.zeros(1, 36, 2048)  # Placeholder for image features
    image_locations = torch.zeros(1, 36, 4)    # Placeholder for image locations

    # Forward pass
    with torch.no_grad():
        vil_prediction, vil_logit, vil_binary_prediction = model(
            question=tokens,
            features=image_features,
            spatials=image_locations,
            segment_ids=None,
            input_mask=None,
            image_mask=None,
            task="VQA"
        )

    # Process the output (this will depend on your specific task and model output)
    # For this example, we'll just return the raw logits
    return vil_logit

# Load pre-trained ViLBERT model and tokenizer
model = VILBertForVLTasks.from_pretrained("bert-base-uncased")
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Example usage
image_path = "path/to/your/property_image.jpg"
question = "Is there any visible damage to the roof?"

logits = analyze_property(image_path, question, model, tokenizer)
print(f"Question: {question}")
print(f"Logits: {logits}")


def inspect_property(image_path, model, tokenizer):
    inspection_results = {}
    
    questions = [
        "Is there any visible damage to the roof?",
        "What is the condition of the exterior paint?",
        "Are there any signs of foundation issues?",
        "Is the landscaping well-maintained?",
        "Are there any visible plumbing issues?"
    ]
    
    for question in questions:
        logits = analyze_property(image_path, question, model, tokenizer)
        # Process logits to get a meaningful answer (this will depend on your specific setup)
        answer = process_logits(logits)
        inspection_results[question] = answer
    
    return inspection_results

def process_logits(logits):
    # This is a placeholder function. You'll need to implement this based on your model's output format
    # and your specific task (e.g., classification, question answering)
    return "Answer based on logits"

# Example usage
image_path = "path/to/property_image.jpg"
results = inspect_property(image_path, model, tokenizer)

for question, answer in results.items():
    print(f"Q: {question}")
    print(f"A: {answer}\n")



