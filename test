Thank you for providing the context and your request. I understand that you'd like to address the concerns raised about the lack of certain procedures in the model development process, particularly those mentioned as "out of scope" in the validation report. Let's craft a respectful and positive response to these concerns, which can be used to update the white paper or communicate with the reviewers.
Here's a suggested response:
We appreciate the thorough review of our Multifamily Prohibited Language Detection (MF-PLD) model and the valuable feedback provided. We acknowledge the concerns raised about the currently out-of-scope procedures, and we're committed to addressing these important aspects of model maintenance and improvement. Here's our plan to address each of these concerns:

Collecting "ground truth" data:
We recognize the importance of having accurate, human-validated data to assess and improve our model's performance. We are developing a systematic process for collecting ground truth data from our users in the MF Lender Risk Management team. This will involve:


Implementing a feedback mechanism within the user interface where reviewers can flag false positives and false negatives.
Establishing a regular review cycle where a sample of model outputs is manually validated by subject matter experts.
Creating a secure database to store and manage this ground truth data for future model improvements.


Adding & removing "biased phrases":
To ensure our model remains current and effective, we're establishing a dynamic process for updating the biased language categories and phrases. This will include:


Regular consultations with the Fair Lending team to review and update the list of biased phrases.
Implementing a version control system for our biased language database to track changes over time.
Developing a formal proposal and approval process for adding or removing phrases, ensuring all changes are well-documented and justified.


Adjusting thresholds for desired false positive rate:
We understand the need for fine-tuning our model's performance. We're working on:


Developing a systematic approach to analyze the trade-offs between false positive and false negative rates at various thresholds.
Creating a process for periodic threshold adjustments based on performance metrics and user feedback.
Implementing A/B testing capabilities to assess the impact of threshold changes before full deployment.


Re-training component models:
To keep our model up-to-date with the latest language trends and organizational needs, we're establishing a framework for regular model updates:


Setting up an automated pipeline for retraining the model with new data at scheduled intervals.
Developing a robust testing framework to validate retrained models before deployment.
Creating documentation and procedures for model versioning and rollback if needed.

We're committed to implementing these procedures in a phased approach, prioritizing based on impact and resource availability. We'll be updating our project roadmap to include these enhancements and will provide regular progress updates to all stakeholders.
We believe these additions will significantly strengthen our MF-PLD model, ensuring its continued effectiveness and alignment with fair lending principles. We welcome any further feedback or suggestions as we work to implement these improvements.


----------------------------------------------------------------------------------
Thank you for providing both the white paper and the validation report. I'll craft a detailed response to address the points raised in the validation report, based on the information from the white paper and the model's current state. This response will aim to address concerns, highlight improvements, and propose solutions for the issues identified.

Dear Validation Team,

We sincerely appreciate your thorough review of our Multifamily Prohibited Language Detection (MF-PLD) model. We're grateful for your assessment that the model is Low Risk and Acceptable with Remediation. We'd like to address the points raised in your report and outline our plans for improvement.

1. Inconsistency in Prohibited Language Definitions

We acknowledge the critical finding regarding inconsistencies between MF definitions of prohibited language, "biased phrases," and development data. To address this:

- We will initiate a collaborative effort with business representatives and Compliance to establish a comprehensive, consistent definition of prohibited language.
- We'll review and update our "biased phrases" list to align with this new definition.
- We'll create a new, consistently labeled evaluation dataset.
- We'll update the biased phrases used by MF-PLD in production once these steps are complete.

2. Model Improvements and Benefits

We're pleased that you've recognized the improvements in our new model:

- The use of the open-source all-MiniLM-L6-v2 sentence transformer model eliminates annual license fees.
- Our approach of associating multiple biased phrases to each category has proven more effective than the previous method.

3. Additional Model Risks

a) Model Misuse/Parametric Settings:
- We confirm our intention to develop a supervised learning model as a secondary stage to minimize false positive and negative rates.
- In the interim, we'll provide clear guidelines for users on adjusting the global threshold to maintain consistency.

b) Context Window Limitations:
- We're exploring options to extend the context window beyond 7 words while balancing computational efficiency.

c) Data Risk:
- We're developing a system to collect and utilize user feedback data for continuous improvement.

d) Resource Allocation:
- We're conducting a thorough cost-benefit analysis of the current process and will optimize where possible.

4. Non-Model Risks

a) Business Resiliency:
- We're developing a comprehensive training program for the workforce using MF FLCR.
- We're streamlining the process to ensure it's more efficient than the current manual approach.

b) Technology:
- We're optimizing the model to reduce processing time, aiming for under 5 minutes for long documents.
- We're exploring cloud computing options to manage computational costs effectively.

c) Data Management:
- We're implementing a robust data quality assurance process for model development and evaluation.
- We're developing a system to persist model outputs and user actions for audits and refinement.

d) Compliance:
- We'll ensure that Compliance/Fair Lending thoroughly vets the MF-PLD rules and "biased phrases."
- We're expanding our prohibited language detection capabilities to cover all types mentioned in the FHFA MRA.
- We're implementing fairness metrics to ensure the model performs equally well across all protected classes.

e) Reputation:
- We're refining our model to reduce false positives while maintaining high sensitivity to truly problematic language.

5. Addressing MRM Recommendations

a) Ground Truth Dataset:
- We're creating a larger, more diverse dataset for evaluation and tuning, including numerous negative examples.

b) User Feedback:
- We're implementing a user-friendly feedback mechanism to collect additional ground truth data.

c) Negative Exemplars:
- We'll incorporate negative exemplars to improve classification accuracy.

d) Vector Database:
- We're exploring the use of a vector database with approximate nearest neighbors search to speed up semantic similarity operations.

e) Document-Level Risk Computation:
- We're developing functionality to compute risk at the document level for more efficient screening.

f) Model Refinement:
- We're creating a mechanism to refine the categorization model, including the ability to add/delete biased phrases and adjust thresholds.

g) Monitoring Functionality:
- We're adding monitoring capabilities to track the rate of prohibited bases mentions over time.

In conclusion, we're committed to addressing all the points raised in your report. We believe these improvements will significantly enhance the MF-PLD model's effectiveness and reliability. We'll provide regular updates on our progress and welcome any further feedback as we implement these changes.

Thank you again for your invaluable input in helping us improve this critical compliance tool.

Sincerely,
[Your Name]
MF-PLD Model Development Team

------------------------------------------------------------------------------------------------------------
Addressing Concerns in the White Paper
1. Comprehensive Definition of Prohibited Language
Concern:
MF definitions of prohibited language, “biased phrases,” and development data are inconsistent.

Response:
We acknowledge the inconsistency in the definitions and examples of prohibited language. We are actively working with business representatives and the Compliance team to develop a comprehensive and consistent definition of prohibited language. This effort includes:

Reviewing and refining the list of biased phrases.
Ensuring that the development data aligns with the updated definitions.
Regularly updating the biased phrases to reflect new insights and feedback.
2. Inconsistencies in Data Annotation and Labeling
Concern:
The development data and annotation process lack consistency, leading to incorrect lists for some prohibited language categories.

Response:
To address this, we are implementing the following steps:

Conducting thorough reviews and updates of the annotation guidelines to ensure consistency.
Training annotators to follow these guidelines precisely.
Introducing a quality control process where multiple annotators review a subset of the data to ensure agreement and consistency.
3. Model Misuse and Parametric Settings
Concern:
The model uses a raw sentence similarity model with an ad hoc list of biased phrases and a global threshold adjustable by users.

Response:
We recognize the limitations of the current approach and plan to develop a supervised learning model to improve performance. This future model will:

Minimize false positive and false negative rates.
Learn predictive patterns from labeled data.
Enhance the overall efficiency and accuracy of the system.
In the interim, we are:

Providing detailed guidance on the appropriate use of the model.
Setting default parameters that balance sensitivity and specificity.
Monitoring user adjustments to refine the model further.
4. Limited Context in Text Snippets
Concern:
Difficulty in distinguishing between prohibited and allowed language in a 7-word snippet.

Response:
We understand the limitation of the 7-word context window. To mitigate this, we are:

Experimenting with varying context windows to find the optimal length.
Considering additional contextual information where relevant.
Collecting feedback to adjust and improve the model's context handling capabilities.
5. Data Collection and Feedback Mechanism
Concern:
Lack of user feedback data collection to improve the system over time.

Response:
We are implementing mechanisms to collect user feedback systematically. This will include:

Integrating a feedback loop within the tool for users to report false positives, false negatives, and general comments.
Analyzing feedback regularly to update the model and biased phrases.
Ensuring that feedback data is stored and utilized for continuous model improvement.
6. Resource Allocation and Computational Efficiency
Concern:
The model requires significant human actions and computational resources.

Response:
To address these concerns, we are:

Streamlining the review process to reduce human workload.
Optimizing the model to reduce computational time and costs.
Evaluating the cost-benefit tradeoff to ensure that the model provides value over the current manual process.
7. Compliance and Bias Detection
Concern:
Ensuring that the biased phrases and model outputs are vetted for compliance and fairness.

Response:
We are working closely with the Compliance and Fair Lending teams to:

Vet the biased phrases and rules comprehensively.
Regularly audit the model to ensure it detects prohibited language accurately and without bias.
Address any identified biases to maintain fairness and compliance.
8. Monitoring and Reporting
Concern:
Lack of monitoring functionality to assess the rate of prohibited language mentions over time.

Response:
We are developing monitoring capabilities to:

Track the occurrence of prohibited language mentions.
Provide regular reports on model performance and detected instances.
Use these insights to refine and improve the model continuously.
Conclusion
We appreciate the detailed feedback and are committed to addressing all concerns raised in the validation report. By implementing these measures, we aim to enhance the consistency, accuracy, and efficiency of the MF-PLD model, ensuring it serves as a valuable tool for detecting prohibited language in compliance with Fair Lending guidelines.

-------------------------------------------------------------------------------------
111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111






Thank you for providing this detailed section of the validation report. I'll address each point raised and outline our plans to improve the MF-PLD model based on these observations.
Dear Validation Team,
We appreciate your thorough analysis of our MF-PLD model specification, assumptions, and limitations. We acknowledge the areas for improvement you've identified and would like to address them as follows:
3.2 Model Specification
We agree that the current model specification, while adequate for initial use, can be enhanced. We propose the following improvements:

Label-specific thresholds:
We plan to implement individual threshold values for each label. This will allow for more nuanced detection of different types of prohibited language.
Threshold optimization:
Instead of relying on ad hoc user adjustments, we will develop an automated process to optimize threshold values. This will be based on performance metrics and historical data, ensuring more consistent and accurate results.
Dynamic biased phrases:
We will implement a mechanism for MF FLCR to add and delete biased phrases over time. This will be based on additional training examples derived from user feedback, allowing the model to adapt to evolving language patterns and improve its accuracy.
Fine-tuning for prohibited language detection:
While the current sentence transformer model provides a good starting point, we recognize the need for domain-specific tuning. We will explore fine-tuning techniques to make the model more sensitive to prohibited language and protected bases in the context of MF documents.

3.3 Model Assumptions
We acknowledge the limitations in our current assumptions:

Embedding vector similarity:
We recognize that the language use in MF documents may differ from the all-MiniLM-L6-v2 training data. To address this, we will:

Collect a corpus of MF-specific documents to fine-tune the embedding model.
Experiment with different context window sizes to capture more relevant information.


Biased phrases selection:
We agree that our current approach to selecting biased phrases needs refinement. We will:

Conduct a thorough analysis of our current biased phrases.
Develop a systematic approach to refine and expand our biased phrases through experimentation and data analysis.
Implement a regular review process to update and improve our biased phrases list.



We will update the MUSE system to reflect these assumptions and our plans to address them.
3.4 Model Limitations
We appreciate your identification of key limitations in our current model:

High false positive rate:
To address the issue of flagging most documents and the high false positive rate, we will:

Implement a two-stage classification process, where the first stage identifies potentially problematic sentences, and the second stage performs a more detailed analysis to reduce false positives.
Develop a scoring system that prioritizes flagged content based on the likelihood of containing prohibited language, allowing reviewers to focus on the most critical cases first.


Generic sentence similarity model:
We acknowledge the limitations of using a generic model. As mentioned in our whitepaper, we will:

Develop a PLD-specific machine learning model as a secondary stage to minimize false positive and negative rates.
Fine-tune the existing model on a dataset of MF documents to improve its performance in our specific domain.


Context window limitations:
To address the limitations of the 7-word context window, we will:

Experiment with larger context windows, potentially using multi-sentence chunks.
Implement a sliding window approach to capture more context while maintaining efficiency.


Updating biased phrases and thresholds:
We will develop a comprehensive system for maintaining and improving our model, including:

A user-friendly interface for subject matter experts to add, delete, or modify biased phrases.
An automated system to adjust thresholds based on performance metrics and user feedback.
Regular review cycles to assess the effectiveness of current biased phrases and thresholds.



We believe these improvements will significantly enhance the performance and utility of the MF-PLD model. We're committed to implementing these changes and will provide regular updates on our progress.
Thank you again for your valuable insights and recommendations. We look forward to continuing this collaborative effort to refine and improve our model.
Sincerely,
[Your Name]
MF-PLD Model Development Team


--------------------------------------------------------------------------------------------------------------------

### Addressing Concerns in Model Specification and Assumptions

#### 3.2 Model Specification

**Concern:**
The model specification could be improved by:
1. Assigning each label its own threshold value.
2. Optimizing threshold values through MF-PLD rather than user adjustments.
3. Allowing MF FLCR to add and delete biased phrases over time based on user feedback.

**Response:**

1. **Individual Threshold Values:**
   - We recognize the importance of having specific threshold values for each label to improve precision. We will implement a feature where each label has its own optimized threshold value, improving the model's accuracy in identifying prohibited language.

2. **Optimization of Threshold Values:**
   - The ad hoc adjustment of threshold values by users can lead to inconsistencies. We are developing an internal optimization algorithm to determine the best threshold values for each label, ensuring more reliable and consistent model performance.

3. **Dynamic Updates to Biased Phrases:**
   - The ability to add and delete biased phrases based on new training examples and user feedback is crucial. We will establish a systematic process for incorporating feedback from the MF FLCR team and updating the biased phrases database. This will ensure the model evolves and remains relevant over time.

**Enhancements to the Sentence Transformer Model:**
   - The sentence transformer model is primarily designed to yield an embedding space where vectors of context and response snippets are close. Although it is not explicitly tuned for prohibited language detection, we are exploring ways to fine-tune the model for better performance in identifying prohibited phrases and protected bases.

#### 3.3 Model Assumptions

**Concern:**
The assumption that the all-MiniLM-L6-v2 embedding vectors for MF-PLD’s biased phrases are close to vectors for sentences mentioning prohibited bases may be flawed due to:
1. Differences in language usage between training data and MF documents.
2. Selection of biased phrases via expert judgment with minimal experimental analysis.

**Response:**

1. **Differences in Language Usage:**
   - We acknowledge that the language used in the all-MiniLM-L6-v2 training data might differ from that in MF documents. To address this, we will:
     - Continuously refine the training data to better reflect the language used in MF documents.
     - Conduct experiments to ensure the embedding vectors accurately represent the desired type of similarity for prohibited language detection.

2. **Selection of Biased Phrases:**
   - The initial selection of biased phrases was based on expert judgment. Moving forward, we will:
     - Perform detailed analysis and iterative experimentation to refine these phrases.
     - Utilize data-driven methods to validate and improve the selection of biased phrases, ensuring they accurately capture various types of prohibited language.

#### 3.4 Model Limitations

**Concern:**
The model's limitations include a high false positive rate, generic sentence similarity model limitations, a restrictive 7-word context window, and no mechanism for updating biased phrases or adding negative exemplars.

**Response:**

1. **High False Positive Rate:**
   - We are aware of the high false positive rate and its impact. To mitigate this, we will:
     - Implement a PLD-specific machine learning model as a secondary stage, which will help reduce both false positives and false negatives, as outlined in the white paper.
     - Continuously monitor and adjust the model to balance precision and recall.

2. **Generic Sentence Similarity Model:**
   - The current model's generic nature limits its ability to distinguish between prohibited and allowed language. By training a PLD-specific model, we can enhance the categorization performance and reduce misclassifications, such as those involving the terms “DEI” and “diverse.”

3. **7-Word Context Window:**
   - The use of a 7-word context window is restrictive. We plan to:
     - Experiment with longer context windows or multi-sentence chunks to capture a broader context, which should improve the model's accuracy.
     - Adjust the chunking strategy to align better with the model's capabilities, potentially leading to improved classification performance.

4. **Updating Biased Phrases and Adding Negative Exemplars:**
   - Currently, there is no mechanism to update biased phrases or add negative exemplars. To enhance the model:
     - We will develop functionality to manually or automatically add/delete biased phrases and adjust thresholds based on feedback and new data.
     - Introduce negative exemplars to help the model differentiate between biased and non-biased language more effectively.
     - Use a feedback loop to refine thresholds and biased phrases continually, aiming for a target false positive rate.

By addressing these concerns and implementing the proposed improvements, we aim to enhance the MF-PLD model's performance, ensuring it more accurately detects prohibited language and serves as a valuable compliance tool.

---

Please incorporate these responses and corrections into the white paper to ensure that all concerns are adequately addressed, and the model specification, assumptions, and limitations are clearly communicated.


33333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333

Thank you for providing this detailed section on the Analytical Validation of the MF-PLD model. I'll address each point and propose solutions to improve our model based on these observations.

Dear Validation Team,

We appreciate your thorough analysis of our MF-PLD model's input data, goodness-of-fit, and performance tracking. We acknowledge the areas for improvement you've identified and would like to address them as follows:

4.1 Input Data

4.1.1 Production Data:
We recognize the limitations of using PDF documents as input. To address this, we propose:

1. Developing a standardized input format: We will work with the business units to create a structured format (e.g., XML or JSON) for document submission that preserves formatting and reduces conversion errors.

2. Improving text extraction: We will implement advanced OCR techniques to enhance the quality of text extracted from PDFs when structured formats are not available.

3. Version control: We will implement a system to track document versions and changes, ensuring we always work with the most up-to-date and accurate information.

4.1.2 Development Data:
We acknowledge the low quantity and quality of our development and test data. To improve this:

1. Data collection initiative: We will launch a comprehensive data collection effort to significantly increase our dataset size.

2. Quality assurance process: We will implement a rigorous QA process for all collected data, ensuring high-quality, accurately labeled examples.

3. Synthetic data generation: We will explore techniques to generate synthetic examples of prohibited language to augment our dataset while maintaining privacy and relevance.

4.2.2 Goodness-of-Fit

We appreciate your analysis of our model's performance. To address the high false positive rate and improve overall performance:

1. Threshold optimization: We will implement category-specific thresholds and develop an algorithm to optimize these thresholds based on business requirements and performance metrics.

2. Two-stage classification: As mentioned earlier, we will implement a two-stage classification process to reduce false positives at the document level.

3. Ensemble methods: We will explore ensemble techniques, combining multiple models to improve overall classification accuracy.

4. Fine-tuning: We will fine-tune the all-MiniLM-L6-v2 model on our domain-specific data to improve its performance on MF documents.

5. Robustness improvement: We will significantly increase our ground truth dataset to improve the robustness of our model results.

4.2.5 Model Performance Tracking

We acknowledge the limitations in our current feedback collection and performance tracking system. To address this:

1. User feedback mechanism: We will implement a user-friendly interface within MF FLCR v1 that allows users to provide categorization feedback at both sentence and document levels.

2. Standardized data collection: We will develop a standardized format for feedback data and store it in a centralized database for easy access and analysis.

3. Automated performance tracking: We will implement an automated system to regularly analyze user feedback and model performance, generating reports and alerting the team to any significant changes or issues.

4. Continuous learning: We will develop a pipeline to incorporate user feedback into our training data, allowing the model to continuously improve over time.

5. Version control: We will implement a robust version control system for our model, allowing us to track performance changes across different versions and rollback if necessary.

Implementation Plan:

1. Short-term (1-3 months):
   - Implement the user feedback mechanism in MF FLCR v1
   - Develop the standardized input format for documents
   - Begin the data collection initiative for increasing our ground truth dataset

2. Medium-term (3-6 months):
   - Implement the two-stage classification process
   - Develop and implement the automated performance tracking system
   - Fine-tune the all-MiniLM-L6-v2 model on our domain-specific data

3. Long-term (6-12 months):
   - Implement the continuous learning pipeline
   - Explore and implement ensemble methods
   - Develop synthetic data generation techniques

We believe these improvements will significantly enhance the performance, reliability, and usefulness of the MF-PLD model. We're committed to implementing these changes and will provide regular updates on our progress.

Thank you again for your valuable insights and recommendations. We look forward to continuing this collaborative effort to refine and improve our model.

Sincerely,
[Your Name]
MF-PLD Model Development Team


------------------------------------------------------------------------------------------------------------------------------


### Addressing Concerns in Analytical Validation

#### 4 Analytical Validation

#### 4.1 Input Data

**4.1.1 Production Data**

**Concern:**
The primary input data consists of actual MF lending documents, such as Sponsor Reviews, in PDF form. Converting these documents to plain text can introduce errors and lose information. 

**Response:**
- **Improved Data Format:** To enhance the quality and efficiency of the input data, we recommend transitioning to a more suitable format, such as structured text files (e.g., XML or JSON). These formats preserve the integrity of the data and eliminate the potential for errors introduced during the conversion process from PDF to text.
- **Preprocessing Pipeline:** We will develop a robust preprocessing pipeline to handle the conversion more accurately, ensuring that critical information is retained and errors are minimized.

**4.1.2 Development Data**

**Concern:**
The quantity and quality of the data used to develop and test the MF-PLD document categorization capability are low.

**Response:**
- **Enhanced Data Collection:** We are committed to increasing the volume and diversity of the development data. This includes gathering more documents and ensuring they cover a wider range of scenarios and language use.
- **Quality Improvement:** Implementing rigorous data cleaning and annotation processes will ensure higher quality development data, leading to better model performance.

#### 4.2.2 Goodness-of-Fit

**Concern:**
The MF-PLD model exhibits a high false positive rate for some categories at the sentence level. Aggregating results across multiple sentences causes most documents to be flagged for review, which is undesirable.

**Response:**
- **Threshold Optimization:** We will optimize the threshold values for each category to reduce the false positive rate. This involves fine-tuning the model parameters and conducting extensive testing to identify the most effective thresholds.
- **Contextual Analysis:** By improving the context analysis, such as considering multi-sentence chunks instead of single sentences, the model can make more accurate classifications, reducing unnecessary document flags.

**Performance Comparison:**
- The performance comparison between the new MF-PLD model and the previous Abacus model, as shown in the confusion matrix and the true positive vs. false positive rate graph, highlights areas for improvement. Our goal is to enhance the robustness of the model by addressing these performance gaps.

#### 4.2.5 Model Performance Tracking

**Concern:**
MF FLCR v1 lacks a mechanism for users to provide categorization feedback at a sentence or document level. Manually uploaded records to SharePoint are not standardized and are less accessible for performance tracking.

**Response:**
- **Feedback Mechanism:** We will implement an integrated feedback system that allows users to provide real-time categorization feedback at both the sentence and document levels. This feedback will be standardized and automatically collected in a database, making it easily accessible for performance tracking.
- **Standardized Data Collection:** Establishing a standardized format for feedback data will ensure consistency and reliability, facilitating more effective performance monitoring and model refinement.

#### Summary of Actions:
1. **Improve Data Formats:** Transition to structured text files for input data and enhance the preprocessing pipeline.
2. **Enhance Development Data:** Increase the volume and quality of development data through rigorous data collection and cleaning.
3. **Optimize Thresholds:** Fine-tune threshold values to reduce false positives.
4. **Contextual Analysis:** Improve context analysis by considering larger text chunks.
5. **Feedback System:** Implement a real-time, standardized feedback mechanism for users.
6. **Performance Monitoring:** Ensure accessible and reliable performance tracking through standardized data collection.

By addressing these concerns and implementing the proposed improvements, we aim to enhance the accuracy, robustness, and usability of the MF-PLD model, ensuring it better serves its intended business purpose.

---

Please incorporate these responses and corrections into the white paper to ensure all concerns are adequately addressed and the analytical validation section is clearly communicated.



44444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444



Thank you for providing this section on the Modern Modeling Methods Assessment. I'll address each point and propose solutions to improve our MF-PLD model based on these observations.

Dear Validation Team,

We appreciate your thorough analysis of our MF-PLD model's explainability, data risks, calibration, overfitting, model drift, and potential bias. We acknowledge the areas for improvement you've identified and would like to address them as follows:

5.1 Black Box Risk – Explainability, Interpretability, and Transparency

We recognize the challenge in interpreting the similarity scores produced by the all-MiniLM-L6-v2 model. To improve explainability:

1. Feature importance: We will implement techniques like LIME (Local Interpretable Model-agnostic Explanations) or SHAP (SHapley Additive exPlanations) to provide more detailed explanations of why specific sentences are flagged.

2. Visualization tools: We will develop visualization tools to help users understand the relationship between input text and biased phrases in the embedding space.

3. Confidence scores: We will introduce confidence scores alongside similarity scores to give users a better understanding of the model's certainty in its classifications.

5.2 Data Risk

We acknowledge the limitations in our current dataset and data management practices. To address these:

1. Expanded dataset: We will significantly increase our dataset size, aiming for at least 1,000 positive exemplars per category.

2. Ground truth consensus: We will establish a panel of experts from various departments (Legal, Compliance, Fair Lending) to review and reach consensus on ground truth data.

3. Data persistence: We will implement a robust data persistence system that captures all necessary information for Fair Lending compliance monitoring and model improvement.

4. User feedback collection: We will develop a user-friendly interface for collecting and storing user feedback, which will be used for future model tuning and system improvements.

5.3 Model Calibration and Feedback (Dynamic Updating)

To improve model calibration and implement dynamic updating:

1. Automated threshold adjustment: We will develop an algorithm to automatically adjust threshold values based on performance metrics and user feedback.

2. Periodic retraining: We will implement a system for periodic model retraining using accumulated user feedback and new ground truth data.

3. A/B testing framework: We will create an A/B testing framework to evaluate the performance of updated models against the current production model before deployment.

5.4 Overfitting

To address the potential overfitting due to limited data:

1. Cross-validation: We will implement k-fold cross-validation to more robustly evaluate our model's performance.

2. Regularization techniques: We will explore regularization methods appropriate for our model to reduce overfitting.

3. Expanded dataset: As mentioned earlier, we will significantly increase our dataset size to reduce the risk of overfitting.

5.5 Model Drift

While model drift may not be expected, we recognize the potential for changes in language interpretation. To address this:

1. Monitoring system: We will implement a monitoring system to track changes in language use and interpretation over time.

2. Regular reviews: We will establish a quarterly review process with stakeholders to discuss any potential changes in prohibited language interpretation.

3. Version control: We will implement a robust version control system for our model parameters, allowing us to track changes and rollback if necessary.

5.6 Bias

To address potential bias in the model's detection capabilities:

1. Balanced dataset: We will ensure our training data includes a balanced representation of prohibited language across all protected classes.

2. Bias audits: We will conduct regular audits to assess the model's performance across different protected classes and adjust as necessary.

3. Fairness metrics: We will implement fairness metrics to quantitatively measure and monitor the model's performance across different protected classes.

4. Diverse review panel: We will establish a diverse panel of experts to regularly review the model's outputs and provide feedback on potential biases.

Implementation Plan:

1. Short-term (1-3 months):
   - Begin expanding our dataset and establishing the expert panel for ground truth consensus
   - Implement the data persistence system
   - Develop the user feedback collection interface

2. Medium-term (3-6 months):
   - Implement explainability techniques (LIME or SHAP)
   - Develop the automated threshold adjustment system
   - Conduct the first comprehensive bias audit

3. Long-term (6-12 months):
   - Implement the periodic retraining system
   - Develop and deploy the A/B testing framework
   - Implement the model drift monitoring system

We believe these improvements will significantly enhance the robustness, fairness, and transparency of the MF-PLD model. We're committed to implementing these changes and will provide regular updates on our progress.

Thank you again for your valuable insights and recommendations. We look forward to continuing this collaborative effort to refine and improve our model.

Sincerely,
[Your Name]
MF-PLD Model Development Team

--------------------------------------------------------------------------------------------------------------------------------------------------------------
### Addressing Concerns in Modern Modeling Methods Assessment

#### 5 Modern Modeling Methods Assessment

#### 5.1 Black Box Risk – Explainability, Interpretability, and Transparency

**Concern:**
The MF-PLD text categorization relies on the all-MiniLM-L6-v2 sentence similarity model. While it is straightforward to interpret that a sentence was flagged as prohibited language because it is similar to a specific biased phrase, it is difficult to interpret the similarity score of any sentence with respect to a biased phrase.

**Response:**
- **Enhanced Explainability Tools:** We will implement tools that provide more detailed explanations for similarity scores. These tools will help users understand why certain sentences are flagged by breaking down the components of the similarity score.
- **User Training:** Providing comprehensive training for users on how to interpret similarity scores will enhance transparency and trust in the model.

#### 5.2 Data Risk

**Concern:**
The data used to select category labels and evaluate the model is insufficient (144 positive exemplars) and not well-agreed upon as "ground truth" data. Additionally, there are concerns about the persistence of data needed for auditing Fair Lending compliance and user feedback for future model tuning.

**Response:**
- **Expand Ground Truth Dataset:** We are committed to expanding the ground truth dataset by collecting more positive exemplars and ensuring they are representative and well-agreed upon.
- **Data Persistence:** We will establish robust data persistence mechanisms to ensure all relevant data, including user feedback, is stored securely and is accessible for auditing and future model improvements.
- **Collaborative Definition:** Engaging stakeholders, including compliance and business representatives, will help ensure the data is comprehensive and agreed upon.

#### 5.3 Model Calibration and Feedback (Dynamic Updating)

**Concern:**
Model calibration could be carried out by adjusting threshold values, but dynamic updating is not currently implemented or planned.

**Response:**
- **Dynamic Updating:** We plan to implement dynamic updating mechanisms that allow the model to adjust threshold values and other parameters based on ongoing user feedback and new data. This will help maintain model accuracy and relevance over time.
- **Regular Calibration:** Regularly scheduled calibration sessions will be conducted to fine-tune the model's parameters and thresholds, ensuring optimal performance.

#### 5.4 Overfitting

**Concern:**
The MF-PLD text classification categories were selected based on the fewest number of labels needed to identify the maximum number of true positives, using a dataset of 74 positive exemplars of questionable quality, leading to potential overfitting.

**Response:**
- **Mitigate Overfitting:** To mitigate overfitting, we will increase the size and diversity of the training dataset. This includes collecting more high-quality exemplars and employing cross-validation techniques during model training.
- **Regular Review:** Conducting regular reviews of the model's performance on new data will help identify and address any signs of overfitting.

#### 5.5 Model Drift

**Concern:**
Model drift is not expected, but Fannie Mae’s interpretation of prohibited language may change over time, necessitating updates to model parameters.

**Response:**
- **Monitor and Update:** We will continuously monitor for potential model drift and establish a protocol for updating biased phrases and thresholds to reflect any changes in the interpretation of prohibited language.
- **Stakeholder Collaboration:** Regular collaboration with stakeholders will ensure that the model parameters remain aligned with current standards and interpretations.

#### 5.6 Bias

**Concern:**
The MF-PLD model may exhibit bias in detecting prohibited language referring to some protected classes better than others.

**Response:**
- **Bias Mitigation:** We will implement bias mitigation techniques, such as ensuring a balanced representation of all protected classes in the training data. Additionally, we will use fairness-aware algorithms to detect and correct any biases in the model's performance.
- **Ongoing Monitoring:** Regular audits and monitoring of the model's performance across different protected classes will help identify and address any disparities.

#### Summary of Actions:
1. **Enhance Explainability:** Implement tools and training to improve the interpretability of similarity scores.
2. **Expand Dataset:** Increase the volume and quality of ground truth data and ensure robust data persistence.
3. **Implement Dynamic Updating:** Develop mechanisms for dynamic model updates based on user feedback and new data.
4. **Mitigate Overfitting:** Collect more high-quality exemplars and use cross-validation techniques.
5. **Monitor Model Drift:** Establish protocols for updating model parameters as interpretations change.
6. **Address Bias:** Implement bias mitigation techniques and conduct regular audits for fairness.

By addressing these concerns and implementing the proposed improvements, we aim to enhance the accuracy, fairness, and transparency of the MF-PLD model, ensuring it effectively identifies prohibited language while minimizing risks.

---

Please incorporate these responses and corrections into the white paper to ensure all concerns are adequately addressed and the modern modeling methods assessment section is clearly communicated.

555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555



appppppppppppppppppppppppeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeediiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiixxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx


Thank you for providing this additional information from Appendix B. I'll address the automation plans and their implications for the MF-PLD model.

Dear Validation Team,

We appreciate your attention to our automation plans for the Multifamily Fair Lending Content Reviewer (MF FLCR) application. We'd like to provide more context and detail about our plans for the MF-PLD model as a key component of this automation effort.

B.2 Automation Plans

We acknowledge that the MF-PLD model is a crucial first step towards a more comprehensive automated solution for identifying prohibited language in MF lending documents. To further enhance this capability and align with our automation goals, we propose the following:

1. Continuous Improvement Framework:
   - Implement a system for continuous model updating based on user feedback and new data.
   - Develop a pipeline for regular model retraining and evaluation to ensure the model stays current with evolving language patterns and business needs.

2. Integration with Existing Workflows:
   - Work closely with the MF lending teams to seamlessly integrate the MF-PLD model into existing document review processes.
   - Develop user-friendly interfaces that allow reviewers to easily interact with the model's outputs and provide feedback.

3. Scalability:
   - Design the system architecture to handle increasing document volumes as the automation effort expands.
   - Implement cloud-based solutions to ensure computational resources can scale with demand.

4. Multi-stage Processing:
   - Develop a multi-stage document processing pipeline that includes:
     a) Initial screening using the MF-PLD model
     b) Secondary review of flagged content using more sophisticated NLP techniques
     c) Human review for edge cases and high-risk content

5. Customization and Flexibility:
   - Allow for customization of prohibited language categories and thresholds based on different document types or business units.
   - Implement a flexible rule engine that can be easily updated as prohibited language definitions evolve.

6. Reporting and Analytics:
   - Develop comprehensive reporting tools to track the performance of the automated system over time.
   - Implement analytics dashboards to provide insights into trends in prohibited language usage and model performance.

7. Compliance and Audit Trail:
   - Ensure the automated system maintains a detailed audit trail of all decisions and actions.
   - Implement robust data retention policies to support potential audits or regulatory inquiries.

8. Expansion to Other Document Types:
   - Plan for the expansion of the MF-PLD model to handle a wider range of document types beyond the current scope.
   - Develop strategies for handling structured and unstructured data within the same framework.

9. Collaboration with Other Teams:
   - Work closely with the Fair Lending and Compliance teams to ensure the automated solution aligns with all regulatory requirements.
   - Collaborate with the Legal team to stay informed about any changes in prohibited language definitions or related regulations.

10. Training and Change Management:
    - Develop comprehensive training materials for users of the automated system.
    - Implement a change management strategy to ensure smooth adoption of the new automated processes.

Implementation Timeline:

1. Short-term (0-6 months):
   - Complete the integration of the current MF-PLD model into the MF FLCR application.
   - Develop and implement the user feedback system.
   - Begin the continuous improvement framework implementation.

2. Medium-term (6-12 months):
   - Implement the multi-stage processing pipeline.
   - Develop and deploy the reporting and analytics dashboards.
   - Complete the scalability enhancements.

3. Long-term (12-24 months):
   - Expand the system to handle additional document types.
   - Implement advanced NLP techniques for secondary review.
   - Fully automate the model updating and retraining process.

We believe these automation plans will significantly enhance the capabilities of the MF-PLD model and the overall efficiency of the prohibited language detection process. We're committed to working closely with all stakeholders to ensure the success of this automation effort.

We look forward to your feedback on these plans and are open to any suggestions for further improvements or considerations.

Sincerely,
[Your Name]
MF-PLD Model Development Team

----------------------------------------------------------------------------------------------------------------

### Appendix B: Multifamily Manual Document Review Process and Automation Plans

#### B.2 Automation Plans

The Multifamily Fair Lending Content Reviewer (MF FLCR) application represents an initial step towards a permanent automated solution for identifying prohibited language in MF lending documents. The present MF-PLD model is designed to offer this search capability.

**Key Points:**

1. **Current Capabilities:**
   - The MF-PLD model currently facilitates the automated detection of prohibited language within MF lending documents, streamlining the review process.

2. **Future Enhancements:**
   - **Improved Detection Accuracy:** Enhancements to the model, including dynamic updating and the inclusion of a broader dataset, are planned to improve detection accuracy.
   - **User Feedback Integration:** Mechanisms to integrate user feedback directly into the model updates will be developed, ensuring continuous improvement based on real-world use.
   - **Threshold Optimization:** Optimization of threshold values for individual labels will be implemented to reduce false positives and improve categorization precision.

3. **Long-term Goals:**
   - **Comprehensive Automation:** The goal is to evolve MF FLCR into a fully automated system capable of efficiently and accurately flagging prohibited language across all MF lending documents.
   - **Scalability and Adaptability:** The system will be designed to scale and adapt to changing compliance requirements and linguistic patterns, maintaining its relevance and effectiveness over time.

4. **Collaboration and Compliance:**
   - **Stakeholder Engagement:** Ongoing collaboration with stakeholders, including compliance officers and business units, will ensure the model aligns with regulatory standards and business needs.
   - **Regular Updates:** Regular updates to the model based on new data, feedback, and changing regulations will ensure it remains compliant and effective.

---

This approach ensures that the MF-PLD model not only addresses current needs but also evolves to meet future requirements, ultimately leading to a robust and reliable automated solution for detecting prohibited language in MF lending documents.



bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb

Thank you for providing this detailed appendix on Prohibited Language Guidelines, Ground Truth Data, and MF-PLD Biased Phrases. This information is crucial for refining our approach to prohibited language detection. I'll address the key points and propose solutions to improve our MF-PLD model based on these observations.

Dear Validation Team,

We appreciate the thorough breakdown of the complexities surrounding prohibited language in MF lending documents. We acknowledge the challenges and inconsistencies identified, and we propose the following approach to address these issues:

1. Clarification of Scope:
   We recognize the need to clearly define what our model should detect. We propose:
   - Collaborating with the Fair Lending and Legal teams to create a comprehensive, nuanced definition of prohibited language.
   - Distinguishing between prohibited language indicating bias against protected bases and subjective language that doesn't necessarily indicate discrimination.
   - Developing clear guidelines on how to handle mentions of property characteristics (age, location) that affect valuation but should not affect mortgage approval.

2. Refinement of Categories:
   Based on the MF Fair Lending Protected Categories, we will:
   - Develop more nuanced detection categories that align with the 13 points listed in the Fair Lending Presentation.
   - Create specific guidelines for handling mentions of property age and location, ensuring we flag only instances where these factors are used "in a manner that has a discriminatory effect."

3. Context-Aware Detection:
   To address the complexities in language interpretation, we will:
   - Implement advanced NLP techniques to better understand context and intent in statements.
   - Develop a multi-stage review process where potentially problematic statements are flagged for human review to determine if they truly constitute prohibited language.

4. Addressing Inconsistencies:
   To tackle the inconsistencies noted in the MF-PLD development data, we will:
   - Conduct a comprehensive review of our training data, ensuring consistent labeling across similar examples.
   - Implement a regular data quality check process involving subject matter experts from Fair Lending and Legal teams.

5. Alignment with FHFA Findings:
   To address the MRAs identified by the FHFA, we will:
   - Enhance our model to specifically flag references to a sponsor's age, marital status, and mentions of tenant demographics.
   - Develop capabilities to identify subjective, non-risk-based commentary in sponsor reviews.
   - Implement detection for subjective assessments of borrower relationships, such as being on "good terms" with Fannie Mae.

6. Continuous Learning and Adaptation:
   To ensure our model stays current with evolving guidelines and interpretations, we will:
   - Implement a feedback loop system where reviewers can provide input on model decisions.
   - Regularly update our training data and model parameters based on this feedback and any new guidelines.

7. Transparency and Explainability:
   To aid in the review process and ensure proper use of the model, we will:
   - Develop a system that provides clear explanations for why specific text was flagged as potentially prohibited.
   - Create detailed documentation on how the model interprets different types of statements, especially those related to property age and location.

Implementation Plan:

1. Short-term (0-3 months):
   - Convene a task force including representatives from Data Science, Fair Lending, Legal, and Business teams to refine our definition of prohibited language.
   - Begin the comprehensive review of our training data for consistency.

2. Medium-term (3-6 months):
   - Implement the advanced NLP techniques for context-aware detection.
   - Develop and deploy the multi-stage review process.
   - Create the feedback loop system for continuous model improvement.

3. Long-term (6-12 months):
   - Fully implement the refined categorization system aligned with MF Fair Lending Protected Categories.
   - Deploy the enhanced explainability features.
   - Conduct a comprehensive evaluation of the model's performance against the FHFA MRAs.

We believe these enhancements will significantly improve the accuracy and usefulness of our MF-PLD model, addressing the complexities and nuances highlighted in the appendix. We're committed to ongoing collaboration with all relevant stakeholders to ensure our model aligns with Fannie Mae's fair lending principles and regulatory requirements.

We welcome your feedback on this proposed approach and are open to further discussions to refine our strategy.

Sincerely,
[Your Name]
MF-PLD Model Development Team


-------------------------------------------------------------------

### Appendix C: Prohibited Language Guidelines, Ground Truth Data, and MF-PLD Biased Phrases

This appendix outlines the initial steps toward making the Multifamily (MF) Prohibited Language guidelines, "ground truth" data, and MF-PLD biased phrases more comprehensive and consistent. Several issues and questions are identified:

1. **Distinguishing Prohibited and Subjective Language:**
   - There is a need to differentiate between language that indicates bias against protected bases and subjective language that does not mention prohibited bases. For instance, stating that a property owner specializes in high-end properties is subjective but not discriminatory. The question arises whether MF-PLD should detect only prohibited language or all subjective language.

2. **Property Characteristics:**
   - Mentioning property characteristics such as location or vintage affects valuation but should not influence mortgage pricing or approval. Examples include properties near beaches or downtown areas, and newer properties. The question is which mentions of a property's age or location are prohibited.

3. **Student Tenants:**
   - Determining whether mentioning the fraction of student tenants is prohibited language, as it correlates with applicant age.

4. **Crime Rates:**
   - There is a common mention of crime rates in the area, including the use of LexisNexis crime reports. Clarification is needed on whether this constitutes prohibited language.

5. **Bias Column Inconsistencies:**
   - The MF-PLD development data's Bias column shows inconsistencies. For example, "Half of the student tenants were those attending Montana Bible College" is not considered biased/prohibited, whereas "Criminal, credit, and rent history checks are also run on prospective tenants and they cannot have any felonies" is considered bias/prohibited. This inconsistency needs addressing.

#### C.1 MF Fair Lending Protected Categories

This section conveys guidelines from three MF policy documents. The documents do not provide enough detail to settle the aforementioned questions. Key factors affecting detection of prohibited language include the age of the property, location, and subjective language. It is essential to determine which language indicates that these characteristics have been used discriminatorily. 

**Guidelines:**
- **Age and Location of Property:**
  - These factors are necessary for determining property value for mortgage approval but should not have a discriminatory effect.
- **Subjective Statements:**
  - Determining the point at which subjective statements become prohibited language.

#### C.1.2 Getting to Yes: Expediting the Fannie Mae Internal Fair Lending Review Process

The presentation by Caroline Elmendorf lists Fair Lending Flags / protected categories:
1. Age of the property
2. Age of the neighborhood
3. Location of the property
4. Impact on one market over another
5. Race
6. Color
7. Religion
8. Sex, sexual orientation, gender identity
9. Disability
10. Familial status (married couples, children)
11. Age (of renters, KPs, Guarantors)
12. National origin
13. Receipt of income derived from public assistance, such as vouchers

Some reviewers interpret items 1-3 as prohibiting any mention of a property’s age or location.

#### C.1.3 Multifamily Selling and Servicing Guide

The guide specifies that the underwriter should consider “the Property's effective age and current physical condition.”

#### C.1.4 Multifamily Sponsor Review Fair Lending Compliance Examination

The FHFA Office of Fair Lending Oversight’s March 29, 2022, Supervisory Findings and Report identified several Matters Requiring Attention (MRA) related to prohibited language. The MF-PLD model aims to help address MRAs 6, 7, and 8:

- **Finding #6:** References to prohibited bases and reliance on non-creditworthiness factors in Sponsor Review Narratives pose a risk of fair lending violations. Enhanced monitoring and controls are required.
- **Finding #7:** Lack of clear policies and procedures for sponsor review activities, leading to reliance on subjective, non-risk-based factors.
- **Finding #8:** Provision of liquidity based on subjective assessments of borrower relationships poses fair lending risk. Addressing weak internal controls is necessary to avoid discretion based on relationships.


c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1cc1c1c1c1c1c1c1c1c1c1c1c1c1c1c1c1


Thank you for providing the context about the Multifamily Prohibited Language Detection (MF-PLD) model and the feedback you've received. I understand you're looking to address concerns and improve the white paper. Let's address the points raised about the procedures for categories of prohibited/biased language:

1. Category Selection Process:
To address the concern about the somewhat arbitrary nature of category selection, we can clarify the process in the white paper:

"The MF-PLD text classification categories were initially selected based on a preliminary analysis of 74 positive exemplars. While this approach provided a starting point, we acknowledge the need for a more comprehensive and systematic method. We are committed to expanding our dataset and refining our categories to ensure a stronger alignment with the protected classes and prohibited bases defined by FNMA's Fair Lending team."

2. Coverage of Protected Categories:
To address the gaps in coverage, we can add:

"We recognize that our current categories do not fully cover all protected categories outlined in the Fair Lending Presentation. Specifically, we're working on expanding our model to include detection for:
- Age of the property
- Age of the neighborhood
- Impact on specific markets
We're actively developing phrases and keywords to capture these categories and will incorporate them in the next iteration of the model."

3. The "Desirability" Category:
To clarify the purpose of this category, we can add:

"The 'Desirability' category was included to capture subjective language that, while not directly corresponding to a protected category, may indirectly lead to biased assessments. We're working closely with the Fair Lending team to refine this category and ensure it aligns with fair lending principles."

4. Age-related Terms:
We can address this by stating:

"We're expanding our age-related terms to more comprehensively cover various aspects, including property age and neighborhood age. This will help us better align with all age-related fair lending concerns."

5. Occupation/Employment Status:
To address this gap, we can add:

"We're in the process of incorporating a wider range of occupation and employment status terms, including 'retired', 'student', and others, to ensure more comprehensive coverage of potential biases in this area."

6. Ethnicity and Nationality Terms:
To address the imbalance in ethnic and nationality terms, we can state:

"We acknowledge the current limitations in our coverage of ethnic and nationality terms. We're actively working to expand our phrase list to include a more comprehensive and balanced representation of various ethnicities, nationalities, and racial groups. This will help reduce potential bias in the model's detection capabilities."

7. Subjective Assessments:
To address the lack of phrases for detecting subjective assessments, we can add:

"We recognize the importance of detecting subjective language that may indicate preferential treatment or bias. We're developing a new category specifically for phrases like 'on good terms' or 'highly regarded client' to better capture these subtle forms of potential bias."

8. Continuous Improvement:
To emphasize our commitment to ongoing refinement, we can conclude with:

"We view the development of the MF-PLD model as an iterative process. We're committed to continuous improvement, regular updates to our phrase lists and categories, and ongoing collaboration with the Fair Lending team to ensure our model remains effective and aligned with fair lending principles."

By addressing these points in the white paper, we demonstrate our awareness of the current limitations and our proactive approach to improving the model. This should help alleviate concerns while highlighting our commitment to developing a robust and fair language detection system.


---------------------------------------------------------------------------------------------------------

### C.2 MF-PLD Categories of Prohibited/Biased Language

The MF-PLD text classification categories were designed by the MF FLCR developers to maximize the detection of true positives with the fewest number of keywords (labels) using the Abacus sentence transformer model. This design was based on a dataset of 74 positive exemplars of questionable quality, making the MF-PLD categories somewhat arbitrary. They do not directly align with the protected classes/prohibited bases defined by Fannie Mae’s Fair Lending team.

#### MF-PLD Categories and Corresponding Protected Categories:
1. **Age [of a person] (#11)**
2. **Demographics:**
   - Bundles multiple other categories including age, race, religion (#7), military.
3. **Desirability**
4. **Disability (#9)**
5. **Familial Status (#10)**
6. **Gender (#8)**
7. **Income-Level (related to #13)**
8. **Location (#3)**
9. **Race (#5, #6, #12)**
10. **Sex (#8)**

#### Categories Not Covered by MF-PLD:
1. **Age of the property (#1)**
2. **Age of the neighborhood (#2)**
3. **Impact on one market over another (#4)**

Since the biased phrases in section *C.3 MF-PLD Biased Phrases* do not include terms related to these categories, the MF-PLD model may not effectively detect prohibited language pertaining to these areas.

#### Desirability Category:
- This does not correspond to any protected category listed in *C.1.2 Getting to Yes: Expediting the Fannie Mae Internal Fair Lending Review Process*. 
- Includes biased phrases related to crime, schools, wealth, neighborhood, etc., and subjective phrases like "pride of ownership" and "exclusive lifestyle."

#### Keywords and Phrases:
- Records containing “young” include the same 8 keywords plus “young professionals” and “young families.”
- No biased phrases contain the word “age” or directly address the *age of the property* or *age of the neighborhood*.
- Missing terms include: retired, student, caucasian, white, classy, atheist, protestant, sikh, immigrant, american, english, british, filipino, arab, and many other countries/ethnic origins.
- Biased phrases include sets like citizen, people, citizens, person, investor, tenant, investors, tenants.
  
Due to these limitations, MF-PLD may exhibit bias by preferentially recognizing terms like "black" over "white," etc., as discussed in Section 5.6 Bias.

#### Subjective Assessments:
- None of the biased phrases are tailored to detect subjective assessments, such as those listed in *C.1.4 Multifamily Sponsor Review Fair Lending Compliance Examination*, e.g., describing a sponsor as “on good terms” with Fannie Mae or a “highly regarded client.”
- Adding such phrases might improve the MF-PLD model's ability to detect subjective language indicating potential bias.


c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c22c2c2c2c2c2c2c2c2c2c2c22cc2c22c2c2c2c2c2c2c2c2c2c2c2c2



Thank you for bringing these important observations to our attention. These points highlight areas where we can improve the consistency and effectiveness of our MF-PLD model. Let's address each of these concerns and outline how we plan to enhance our approach:

1. Lack of "black" and "white" references:
"We acknowledge the limitation in our current dataset regarding references to 'black' and 'white'. To address this, we're expanding our dataset to include a more diverse range of racial references. This will allow us to better train and evaluate the model's performance on these common terms, ensuring fair and consistent detection across all racial categories."

2. Inconsistent labeling of religious references:
"We've identified inconsistencies in labeling religious references, as exemplified by Record 3. We're revising our labeling guidelines to ensure all references to tenants' religion are consistently flagged as prohibited language, aligning with fair lending principles."

3. References to student tenants:
"We recognize the ambiguity surrounding references to student tenants. To clarify, we're developing specific guidelines on how to handle such references, considering their potential as proxies for age and familial status. We'll ensure consistent labeling across all instances and provide clear documentation on when such references constitute prohibited language."

4. Inconsistency in crime rate references:
"We've noted the inconsistency in labeling between factual descriptions of tenant screening policies and references to area crime rates. We're refining our guidelines to distinguish between objective property policies and potentially biased area descriptions. This will lead to more consistent and fair labeling in our dataset."

5. Unlabeled explicit racial references:
"The oversight in not labeling explicit racial references (Records 14 and 15) as prohibited language has been identified. We're implementing a thorough review process to catch and correct such inconsistencies, ensuring all explicit racial references are appropriately flagged."

6. Subjective assessments of client relationships:
"We appreciate the reference to the FHFA's guidance on language suggesting sponsors are on 'good terms' with Fannie Mae. We're updating our labeling criteria to flag such subjective assessments of client relationships (like in Record 16) as prohibited language, aligning with FHFA's recommendations."

7. Appraisal language:
"Regarding Record 17, we're developing clearer guidelines on appraiser language. We'll consult with our Fair Lending team to determine which descriptors are appropriate in appraisals and which might introduce bias. This will help us consistently label such language in our dataset."

8. Overall inconsistency in labeling:
"We acknowledge the inconsistencies found in our ground truth labels. To address this:
   a) We're conducting a comprehensive review of our entire dataset to ensure consistent labeling.
   b) We're developing more detailed and precise labeling guidelines.
   c) We're implementing a multi-step review process for our labels to catch and correct inconsistencies.
   d) We're considering involving multiple annotators and implementing an inter-annotator agreement process to improve label reliability."

9. Continuous Improvement and Transparency:
"We're committed to ongoing improvement of our dataset and model. We'll be:
   a) Regularly reviewing and updating our dataset with new, consistently labeled examples.
   b) Implementing periodic audits of our model's performance across various categories.
   c) Maintaining transparent documentation of our labeling criteria and any changes made to the dataset or model."

By addressing these points, we demonstrate our commitment to developing a more accurate, consistent, and fair language detection model. We appreciate the thorough review that brought these issues to light, as it allows us to significantly improve the quality and reliability of our MF-PLD model.


-------------------------------------------------------------------------------------------------------------------------


### C.4.1 Observations

1. **Common Terms "Black" and "White":**
   - No sentence in the development data contains the term "black," and only two records contain the term "white" (Records 11 and 12).
   - Due to the absence or scarcity of these terms, it is challenging to evaluate how the model handles common terms that may or may not indicate race.

2. **Religion Reference:**
   - Record 3 explicitly refers to the religion of tenants but is not labeled as containing prohibited language.

3. **Student Tenants as Proxy for Age and Familial Status:**
   - Records 1, 3, 4, 13, and 15 mention student tenants, which serves as a proxy for age and familial status.
   - Record 13 is labeled as containing prohibited language (likely due to the mention of property age), whereas the others are not.
   - There is a need for clarification on whether referencing students constitutes prohibited language.

4. **Crime Rates and Tenant Screening Policy:**
   - Records 6-10 refer to crime rates in the surrounding area and seem more clearly biased/prohibited compared to Record 5, which factually describes the property’s tenant screening policy.
   - This demonstrates internal inconsistency in the development dataset.

5. **Explicit References to Race:**
   - Records 14 and 15 explicitly refer to the race of likely tenants but are not labeled as containing prohibited language.

6. **FHFA Findings on Sponsor Relationships:**
   - The FHFA Office of Fair Lending Oversight’s March 29, 2022, Supervisory Findings and Report indicate that Fannie Mae must address weak internal controls leading to discretion in sponsor relationships.
   - Record 16 includes the text “Real Estate Experience Case is a long time and highly regarded Newmark/Fannie Mae client,” which is similar to the “on good terms” statement objected to by FHFA but was not labeled as containing prohibited language.

7. **Appraisal References:**
   - Record 17 quotes an appraiser mentioning “riverside setting, proximity to shopping, dining, recreation, and support facilities along with immediate highway and bus and railroad access.”
   - There is a question about whether such descriptions in appraisals are prohibited.

8. **Inconsistency in Ground Truth Labels:**
   - MRM examined records filtered by keywords like “black,” “white,” “crime,” “student,” and “high.”
   - The ground truth labels were so inconsistent that verification of the true_flag column values (1 = prohibited, 0 = allowed) with the model developer was necessary.


c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4c4cc4c4c4c4c4c4c4c4c4c









-----------------------------------------------------------------------------------------------------------

### C.5 MF-PLD Validation by MF Team

**Overview:**
- The MF-PLD model was used to score 16 Sponsor Credit Review and LIHTC Review documents.
- It flagged 3 to 108 sentences per document, totaling 584 sentences, as potentially containing prohibited language.
- All 16 documents were flagged.
- The MF team reviewed these flagged sentences and used expert judgment to determine if they contained prohibited language.
- Their findings were documented in the file "Sponsor Credit Reviews and LIHTC Reviews - Output.xlsm".
- They identified 14 sentences from 4 documents as containing prohibited language, listed in Table 2.

**Detailed Observations:**
1. **Duplicate Records:**
   - Records 1 and 2 are duplicates.
   - These records seem to violate the ECOA prohibition against considering applicant income from a public assistance program.
   - They also appear to breach the GSE Act by using the dwelling's location in a discriminatory manner.

2. **Age of the Property:**
   - Records 3-9 mention the property's age.
   - It's unclear if these mentions are discriminatory, e.g., “Average vintage is 1983, with the oldest asset being built in 1908 and the newest in 2021.”

3. **Limitations of MF-PLD:**
   - Records 7-14 highlight the model's limitations, particularly in the demographic category.
   - Terms like “DEI” and “diverse” in contexts such as “Douglas Emmett, Inc. (DEI)” and “strong, diverse sub-markets” might indicate demographic characteristics if used differently.

4. **Subjective Language:**
   - Records 10-14 include language deemed subjective by MF reviewers.
   - Examples include “AIR Communities professionally manages high-quality properties in most major markets.”

**Impact of Clarification:**
- If the definition and interpretation of prohibited language clarified that Records 3-14 do not pertain to protected classes/prohibited bases:
  - The estimated percentage of Sponsor Credit Review and LIHTC Review documents containing prohibited language would drop from 25% to 6%.


c5c5c5c55c5c55c5cc5c5c5c5c5555555555555555555555cccccccccccccccccccccc55555555555555555555

