
import nltk
from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters
import re

nltk.download('punkt')

def advanced_sentence_tokenizer(text):
    punkt_param = PunktParameters()
    expanded_abbreviation_list = [
        'e.g', 'i.e', 'etc', 'mr', 'mrs', 'dr', 'ph.d', 'prof', 'inc', 'ltd',
        'co', 'jr', 'sr', 'vs', 'dept', 'univ', 'assn', 'bros', 'ph', 'md', 
        'do', 'dvm', 'od', 'dds', 'llc', 'llp', 'corp', 'jan', 'feb', 'mar', 
        'apr', 'jun', 'jul', 'aug', 'sep', 'sept', 'oct', 'nov', 'dec', 
        'mon', 'tue', 'tues', 'wed', 'thu', 'thurs', 'fri', 'sat', 'sun', 
        'no', 'vol', 'ed', 'pp', 'est', 'fig', 'eq', 'ex', 'cf', 'ref', 
        'refs', 'ch', 'sec', 'viz', 'al', 'ave', 'blvd', 'st', 'rd', 'mt',
        # Add more abbreviations as needed
    ]
    punkt_param.abbrev_types = set(expanded_abbreviation_list)
    tokenizer = PunktSentenceTokenizer(punkt_param)
    
    # Replace curly quotes with straight quotes
    text = text.replace('“', '"').replace('”', '"').replace("‘", "'").replace("’", "'")
    
    # Remove special characters (optional, based on need)
    # Be careful with this step as it may remove characters that are meaningful in certain contexts
    # For example, keeping periods, commas, question marks, etc., is important for sentence tokenization
    # text = re.sub(r"[^a-zA-Z0-9.,!?\'\"]", " ", text)
    
    # Additional preprocessing to handle specific cases, e.g., protecting decimal points in numbers
    text = re.sub(r'(\d)\.(\d)', r'\1DECIMAL\2', text)
    text = re.sub(r'\n+', '. ', text)  # Replace newlines with periods to separate statements properly
    
    sentences = tokenizer.tokenize(text)
    
    # Post-tokenization: clean up any placeholders or special handling
    sentences = [sent.replace('DECIMAL', '.') for sent in sentences]
    
    return sentences










------------------------------------------------------------------------------------------------------------------------------------

focusing on the rates of false negatives relative to false positives. Remember, this visualization emphasizes the cost of false negatives (missed detections) versus false positives (false alarms), which might be particularly relevant in contexts where missing a positive case has serious implications, like in medical diagnostics or fraud detection.



fpr, tpr, thresholds = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)

# Plotting the ROC curve with emphasis on FNR
plt.figure()
plt.plot(fpr, 1 - tpr, label='FNR vs. FPR (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [1, 0], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('False Negative Rate (FNR)')
plt.title('FNR vs. FPR Curve')
plt.legend(loc="lower left")
plt.show()

================================================================================



import numpy as np
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Sample predicted scores and true labels for Model 1 and Model 2
y_true = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])  # Example true labels
y_scores_model1 = np.array([0.9, 0.1, 0.8, 0.72, 0.3, 0.67, 0.24, 0.45, 0.85, 0.15])  # Predicted scores from Model 1
y_scores_model2 = np.array([0.85, 0.2, 0.75, 0.8, 0.25, 0.7, 0.3, 0.4, 0.9, 0.05])  # Predicted scores from Model 2

# Function to plot ROC curve
def plot_roc_curve(y_true, y_scores, title):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

# Plot ROC curve for each model
plot_roc_curve(y_true, y_scores_model1, 'ROC Curve for Model 1')
plot_roc_curve(y_true, y_scores_model2, 'ROC Curve for Model 2')



def plot_combined_roc_curve(y_true, y_scores_model1, y_scores_model2):
    fpr1, tpr1, thresholds1 = roc_curve(y_true, y_scores_model1)
    roc_auc1 = auc(fpr1, tpr1)

    fpr2, tpr2, thresholds2 = roc_curve(y_true, y_scores_model2)
    roc_auc2 = auc(fpr2, tpr2)

    plt.figure()
    plt.plot(fpr1, tpr1, color='darkorange', lw=2, label='Model 1 (area = %0.2f)' % roc_auc1)
    plt.plot(fpr2, tpr2, color='green', lw=2, label='Model 2 (area = %0.2f)' % roc_auc2)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Combined ROC Curves')
    plt.legend(loc="lower right")
    plt.show()

# Plot combined ROC curve
plot_combined_roc_curve(y_true, y_scores_model1, y_scores_model2)






















































def find_similar_words(input_text, top_n=10):
    # Process the input text with the spaCy transformer model
    doc = trf_model(input_text)
    
    # Initialize a list to store similar words and phrases
    similar_words = []
    
    # Iterate through tokens in the processed text
    for token in doc:
        # Check if the token has vector representation (e.g., excluding stopwords)
        if token.has_vector:
            # Calculate the similarity score between the input token and all tokens in the vocabulary
            similarity_scores = [token.similarity(other_token) for other_token in doc]
            
            # Sort tokens by similarity score in descending order
            sorted_tokens = sorted(enumerate(similarity_scores), key=lambda x: x[1], reverse=True)
            
            # Extract the top N similar tokens (excluding the input token itself)
            similar_tokens = [doc[i[0]].text for i in sorted_tokens if i[0] != token.i][:top_n]
            
            # Add the similar tokens to the list
            similar_words.extend(similar_tokens)
    
    # Remove duplicates from the list
    similar_words = list(set(similar_words))
    
    return similar_words

-=-===================================----------------55555555555555555555555555555555555555555
def compute_metrics(TP, FN, FP, TN):
    accuracy = (TP + TN) / (TP + TN + FP + FN)
    precision = TP / (TP + FP) if TP + FP != 0 else 0
    recall = TP / (TP + FN) if TP + FN != 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0
    balanced_accuracy = 0.5 * ((TP / (TP + FN) if TP + FN != 0 else 0) + (TN / (TN + FP) if TN + FP != 0 else 0))
    mcc_denom = ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) ** 0.5
    mcc = (TP * TN - FP * FN) / mcc_denom if mcc_denom != 0 else 0
    fbeta = (1 + 2**2) * (precision * recall) / ((2**2 * precision) + recall) if precision + recall != 0 else 0
    
    return {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1_score,
        "Balanced Accuracy": balanced_accuracy,
        "MCC": mcc,
        "F-beta (beta=2)": fbeta
    }

metrics_C = compute_metrics(9, 0, 24, 158)

print("Metrics for Model C:")
for metric, value in metrics_C.items():
    print(f"{metric}: {value:.4f}")
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Get input values
TP = int(input("Enter the number of True Positives (TP): "))
TN = int(input("Enter the number of True Negatives (TN): "))
FP = int(input("Enter the number of False Positives (FP): "))
FN = int(input("Enter the number of False Negatives (FN): "))

# Calculate metrics
accuracy = (TP + TN) / (TP + TN + FP + FN)
recall = TP / (TP + FN) if TP + FN != 0 else 0
precision = TP / (TP + FP) if TP + FP != 0 else 0
f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0
total_instances = TP + TN + FP + FN

# Visualize the confusion matrix
confusion_matrix = np.array([[TP, FP], [FN, TN]])
ax = sns.heatmap(confusion_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.xaxis.set_ticklabels(['Positive', 'Negative'])
ax.yaxis.set_ticklabels(['Positive', 'Negative'])
plt.show()

# Display metrics
print(f"\n\n{'Accuracy:':<15} {accuracy:.4f}")
print(f"{'Recall:':<15} {recall:.4f}")
print(f"{'Precision:':<15} {precision:.4f}")
print(f"{'F1-score:':<15} {f1_score:.4f}")
print(f"{'Total instances:':<15} {total_instances}")

=------------------------------===================================-------------------------------------5678090
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load and prepare the multi-class dataset
data_multiclass = pd.read_csv('your_multiclass_data.csv')  # Adjust the file path
X_multi = data_multiclass.drop('label', axis=1)
y_multi = data_multiclass['label']

# Load and prepare the binary classification dataset
data_binary = pd.read_csv('your_binary_data.csv')  # Adjust the file path
X_binary = data_binary.drop('label', axis=1)
y_binary = data_binary['label']

# Standardize the features
scaler = StandardScaler()
X_multi_scaled = scaler.fit_transform(X_multi)
X_binary_scaled = scaler.fit_transform(X_binary)

# Split the multi-class data
X_multi_train, X_multi_temp, y_multi_train, y_multi_temp = train_test_split(X_multi_scaled, y_multi, test_size=0.4, stratify=y_multi, random_state=42)
X_multi_val, X_multi_test, y_multi_val, y_multi_test = train_test_split(X_multi_temp, y_multi_temp, test_size=0.5, stratify=y_multi_temp, random_state=42)

# Split the binary classification data
X_binary_train, X_binary_temp, y_binary_train, y_binary_temp = train_test_split(X_binary_scaled, y_binary, test_size=0.4, stratify=y_binary, random_state=42)
X_binary_val, X_binary_test, y_binary_val, y_binary_test = train_test_split(X_binary_temp, y_binary_temp, test_size=0.5, stratify=y_binary_temp, random_state=42)


from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier

# Initialize multi-class models
xgb_multi_model = XGBClassifier()  # Add parameters as needed
rf_multi_model = RandomForestClassifier()  # Add parameters as needed

# Train multi-class models
xgb_multi_model.fit(X_multi_train, y_multi_train)
rf_multi_model.fit(X_multi_train, y_multi_train)


from sklearn.model_selection import GridSearchCV

# Example: Grid search for XGBoost multi-class model
param_grid_multi_xgb = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'n_estimators': [100, 200, 300]
}

grid_search_multi_xgb = GridSearchCV(xgb_multi_model, param_grid_multi_xgb, cv=3, scoring='accuracy', verbose=2)
grid_search_multi_xgb.fit(X_multi_val, y_multi_val)

# Update multi-class XGBoost model with the best parameters
xgb_multi_model = grid_search_multi_xgb.best_estimator_

# Similar tuning for the RandomForest multi-class model...


# Generate multi-class predictions as a feature for the binary classification dataset
multi_predictions_train = xgb_multi_model.predict(X_multi_train)  # You can also try using rf_multi_model
multi_predictions_val = xgb_multi_model.predict(X_multi_val)
multi_predictions_test = xgb_multi_model.predict(X_multi_test)

--------------------------=============---------------------------------------=
from sklearn.preprocessing import OneHotEncoder

# Assuming your categorical variable is in a column named 'category'

# Initialize OneHotEncoder with known categories
encoder = OneHotEncoder(categories=[range(0, 9)], sparse=False)

# Fit the encoder on the entire data (if available) or just use the known categories
# If you have a dataset that contains all categories, use it to fit. Otherwise, the line below is fine.
encoder.fit([[0], [1], [2], [3], [4], [5], [6], [7], [8]])

# Transform the data in train, validation, and test sets
train_encoded = encoder.transform(train['category'].values.reshape(-1, 1))
val_encoded = encoder.transform(val['category'].values.reshape(-1, 1))
test_encoded = encoder.transform(test['category'].values.reshape(-1, 1))

-================================---------------------------


# Add multi-class predictions as a feature to the binary dataset
X_binary_train_with_multi = np.column_stack((X_binary_train, multi_predictions_train))
X_binary_val_with_multi = np.column_stack((X_binary_val, multi_predictions_val))
X_binary_test_with_multi = np.column_stack((X_binary_test, multi_predictions_test))



# Initialize binary classification models
xgb_binary_model = XGBClassifier(scale_pos_weight = sum(y_binary_train == 0) / sum(y_binary_train == 1)) 
rf_binary_model = RandomForestClassifier(class_weight='balanced')

# Train binary models using the modified dataset
xgb_binary_model.fit(X_binary_train_with_multi, y_binary_train)
rf_binary_model.fit(X_binary_train_with_multi, y_binary_train)

Step 6: Hyperparameter Tuning for Binary Models



from sklearn.metrics import classification_report, accuracy_score

# Predict
































-========================----------------43=3444444444444444------------------------------==============================
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load data
data = pd.read_csv('your_data.csv')  # Adjust the file path

# Separate features and target
X = data.drop('label', axis=1)
y = data['label']

# Standardize the features (optional but recommended)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data into train, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier

# Initialize models
xgb_model = XGBClassifier(scale_pos_weight = sum(y_train == 0) / sum(y_train == 1))  # Adjust for imbalance
rf_model = RandomForestClassifier(class_weight='balanced')  # Adjust for imbalance

# Train models
xgb_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)


from sklearn.model_selection import GridSearchCV

# Define parameter grid
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'n_estimators': [100, 200, 300]
}

# Grid search
grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='roc_auc', verbose=2)
grid_search.fit(X_val, y_val)

# Update model with best parameters
xgb_model = grid_search.best_estimator_



from sklearn.model_selection import GridSearchCV

# Parameter grid for Random Forest
param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Create GridSearchCV object for Random Forest
grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=3, scoring='roc_auc', verbose=2)
grid_search_rf.fit(X_val, y_val)

# Update Random Forest model with the best parameters
rf_model = grid_search_rf.best_estimator_


from sklearn.model_selection import GridSearchCV

# Define parameter grid
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'n_estimators': [100, 200, 300]
}

# Grid search
grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='roc_auc', verbose=2)
grid_search.fit(X_val, y_val)

# Update model with best parameters
xgb_model = grid_search.best_estimator_


from sklearn.ensemble import VotingClassifier

# Create a voting classifier
voting_clf = VotingClassifier(
    estimators=[('xgb', xgb_model), ('rf', rf_model)],
    voting='soft'
)

# Fit the voting classifier
voting_clf.fit(X_train, y_train)


from sklearn.metrics import classification_report, accuracy_score

# Predictions
y_pred = voting_clf.predict(X_test)

# Evaluation
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))








































-===================================44444444444444444444444444444444444444444444444444444444444
import pandas as pd

# Define the function to read an .xlsm file and read all text-related data from all sheet tabs ignoring null, non-textual, and numeric values.
def read_xlsm_text_advanced(file_path):
    # Load the Excel file
    xl = pd.ExcelFile(file_path)

    # Create an empty list to store text data
    text_data = []

    # Define a function to check if a cell contains text data (ignoring purely numeric and mixed alphanumeric strings)
    def is_text(cell):
        if isinstance(cell, str):
            # Check if all characters in the string are alphabetic or whitespace
            return all(char.isalpha() or char.isspace() for char in cell)
        return False

    # Iterate through each sheet in the workbook
    for sheet in xl.sheet_names:
        # Read the sheet into a pandas DataFrame
        df = xl.parse(sheet)

        # Iterate through the DataFrame to extract text values
        for column in df.columns:
            for item in df[column]:
                # Check if the item is text-related data
                if pd.notnull(item) and is_text(item):
                    # Add the text to the list, stripping leading/trailing whitespace
                    text_data.append(item.strip())

    # Return the list of text data
    return text_data

# Example usage:
# text_from_xlsm = read_xlsm_text_advanced('path_to_file.xlsm')
# This is commented out to prevent an error since there is no file to read in this environment.

-------------------------------======================================5555555555555555555555555555

import spacy

nlp = spacy.load("en_core_web_md")  # Load the medium-sized English model

def find_similar(keyword, threshold=0.89):
    """Find words similar to keyword using spaCy word vectors"""
    
    doc = nlp(keyword)
    query_vector = doc.vector

    similar_words = []
    for word in nlp.vocab:
        if word.has_vector:  # Check if the word has a vector representation
            similarity = query_vector.dot(word.vector)  # Calculate cosine similarity
            if similarity > threshold:
                similar_words.append((word.text, similarity))
    
    similar_words = sorted(similar_words, key=lambda x: x[1], reverse=True)

    print(f"Similar words to {keyword} with similarity > {threshold}:")
    for word, score in similar_words:
        print(f"- {word} ({score:.3f})")

# Example usage:
keyword = "house"
find_similar(keyword)


-------------------------------------------------------------
import tensorflow as tf
from transformers import BertTokenizer, TFBertModel

# Constants
MAX_LEN = 512
EMBEDDING_DIM = 8000
NUM_ASPECTS = 9
DROPOUT_RATE = 0.5

# Custom attention layer
class AttentionLayer(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(AttentionLayer, self).build(input_shape)

    def call(self, x):
        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)
        a = tf.keras.backend.softmax(e, axis=1)
        output = x * a
        return tf.keras.backend.sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[-1])

# Tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Input Layer
input_text = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name="input_text")

# BERT for contextual embeddings
bert_model = TFBertModel.from_pretrained('bert-base-uncased')
bert_output = bert_model(input_text)[0]

# Attention layer
attention_output = AttentionLayer()(bert_output)

# Dropout layer after attention
attention_output = tf.keras.layers.Dropout(DROPOUT_RATE)(attention_output)

# Custom layer to concatenate attention outputs to desired dimension
concat_layer = tf.keras.layers.Dense(EMBEDDING_DIM, activation='relu')(attention_output)
concat_layer = tf.keras.layers.Dropout(DROPOUT_RATE)(concat_layer)

# ... [Rest of the model remains the same]

# Print model summary
model.summary()



-=--=========================
# Compile the model with F1-Score as a metric
f1_score = tfa.metrics.F1Score(num_classes=3, average='macro')  # For multi-class tasks
binary_f1_score = tfa.metrics.F1Score(num_classes=1, threshold=0.5)  # For binary tasks

model.compile(optimizer='adam', 
              loss=['categorical_crossentropy'] * NUM_ASPECTS + ['binary_crossentropy'] + ['categorical_crossentropy'] * NUM_ASPECTS,
              metrics=[f1_score] * NUM_ASPECTS + [binary_f1_score] + [f1_score] * NUM_ASPECTS)

# Print model summary
model.summary()


def compute_fbeta(y_true, y_pred, beta=0.5):
    # Convert tensors to binary class matrices
    y_true_class = tf.argmax(y_true, axis=-1)
    y_pred_class = tf.argmax(y_pred, axis=-1)

    # Compute TP, FP, FN
    TP = tf.math.count_nonzero(y_pred_class * y_true_class, axis=0)
    FP = tf.math.count_nonzero(y_pred_class * (y_true_class - 1), axis=0)
    FN = tf.math.count_nonzero((y_pred_class - 1) * y_true_class, axis=0)

    # Compute Precision and Recall
    precision = TP / (TP + FP + tf.keras.backend.epsilon())
    recall = TP / (TP + FN + tf.keras.backend.epsilon())

    # Compute F-beta
    fbeta = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + tf.keras.backend.epsilon())

    # Return the mean F-beta score for the batch
    return tf.reduce_mean(fbeta)


def compute_fbeta(y_true, y_pred, beta=0.5):
    # Cast y_true to the same dtype as y_pred
    y_true = tf.cast(y_true, y_pred.dtype)

    # Convert tensors to binary class matrices
    y_true_class = tf.argmax(y_true, axis=-1)
    y_pred_class = tf.argmax(y_pred, axis=-1)

    # Convert these to float32 for the upcoming computations
    y_true_class = tf.cast(y_true_class, tf.float32)
    y_pred_class = tf.cast(y_pred_class, tf.float32)

    # Compute TP, FP, FN
    TP = tf.math.count_nonzero(y_pred_class * y_true_class, axis=0)
    FP = tf.math.count_nonzero(y_pred_class * (y_true_class - 1), axis=0)
    FN = tf.math.count_nonzero((y_pred_class - 1) * y_true_class, axis=0)

    # Convert TP, FP, FN to float32
    TP = tf.cast(TP, tf.float32)
    FP = tf.cast(FP, tf.float32)
    FN = tf.cast(FN, tf.float32)

    # Compute Precision and Recall
    precision = TP / (TP + FP + tf.keras.backend.epsilon())
    recall = TP / (TP + FN + tf.keras.backend.epsilon())

    # Compute F-beta
    fbeta = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + tf.keras.backend.epsilon())

    # Return the mean F-beta score for the batch
    return tf.reduce_mean(fbeta)



=--------------------9076875643576243567890-=
zeroshot bart 
import torch
from transformers import pipeline
from multiprocessing import Pool

# Ensure you have a GPU for faster inference (optional but recommended)
device = 0 if torch.cuda.is_available() else -1

# Create the zero-shot classification pipeline
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=device)

def classify(text):
    # Define the possible labels for classification
    candidate_labels = ["label1", "label2", "label3"]  # Replace with your labels
    result = classifier(text, candidate_labels)
    return result["labels"][0]  # Return the top label

if __name__ == "__main__":
    texts = ["Your list of texts to classify..."]  # Replace with your list of texts

    # Use multiprocessing to classify texts in parallel
    with Pool(processes=4) as pool:  # Adjust the number of processes as needed
        results = pool.map(classify, texts)

    print(results)








=-=-=-=-=------===================----------------------------===========================---------------
# in mortgage industry, we have appraisal to a house or recommendation memos for multi-family.
# sometimes the agents writing these appraisals or rec memos, or lender narratives, or sponsor narratives use some language that are prohibited, 
# for example they should not describe the desirability of neighborhood, or any subjective high-level categories such as race, gender, religion, familial status, age, income, disability, neighborhood description related to applicant, neighborhood,
# like that makes it biased and adds subjectivity on report regarding the above mentioned high-level categories. 
# for removing these prohibited terms related to above high-level categories, 
# we need to parse the appraisal report into sentence and them classified each sentence into one of above multi_categories or none of them if the sentence does not contain none of them. 
# for example following phrases such as good neighborhood, Muslim community , potential district, immigrant community, Chinese neighborhood, black street, good school, kids neighborhood, standards neighborhood, poor subdivision, gentrified neighborhood, fast growing district, gay applicant, young owner , ancient landlord, single loan applicant, 24 years old owner, ... 
# that are implicitly has some meaning related to description of neighborhood, applicant, owner,  ... . 

multi_categories = ['race / ethnicity / national origin / color skin / ... descriptors',
'religion',
'gender identity / sexual orientation / sex / ... descriptors',
'familial status / marital status / familial descriptors',
'neighborhood / community / district / block / subdivision / town / zone / urban / rural / suburban / village / tenants / families / enclave / pockets / ... descriptors',
'age demographics / age descriptors',
'income descriptors and financial status',
'disability descriptors',
'None of above']

binary_category = ['baised', 'not_baised']

# for each sentence in the report, we need to classify it into one of above categories or none of them.
# for example:
# sentence = 'the neighborhood is good'
# category = 'neighborhood / community / district / block / subdivision / town / zone / urban / rural / suburban / village / tenants / families / enclave / pockets / ... descriptors'

# load the a dataframe contains columns such as document name, text, and their categories and binary category from a csv file
import pandas as pd
import torch
import re
import spacy
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer
from torch.utils.data import DataLoader
import torch
import torch.optim as optim

df = pd.read_csv('MF_prohibited.csv')
df.head()

# we need to clean the text column by removing white space and replace them with space, remove urls, non-ascii characters. 
# we need to convert entities in the text into date_, loc_, org_, person_, time_, money_, percent_, gpe_ , etc. 
# write the function with regex for above rules and apply them on text column.
def text_processing():
    # remove white space
    text = re.sub(r'\s+', ' ', text)
    # remove urls
    text = re.sub(r"http\S+", "", text)
    # remove non-ascii characters
    text = ''.join([i if ord(i) < 128 else ' ' for i in text])
    # convert entities into date_, loc_, org_, person_, time_, money_, percent_, gpe_ , etc.
    doc = nlp(text)
    for ent in doc.ents:
        text = text.replace(ent.text, ent.label_)
    # ...
    return text

df.text.apply(lambda x: text_processing(x))

# load the following huggingface transformers and sentence transformers models for embedding the text into vectors 
# bert-base-uncased, bart-large-mnli, sentence transformers all-MiniLM-L6-V2

model_name1 = 'bert-base-uncased'
model_name2 = 'bart-large-mnli'
model_name3 = 'setence-transformers/all-MiniLM-L6-V2'
tokenizer1 = AutoTokenizer.from_pretrained(model_name1)
tokenizer2 = AutoTokenizer.from_pretrained(model_name2)
tokenizer3 = AutoTokenizer.from_pretrained(model_name3)
model1 = AutoModel.from_pretrained(model_name1)
model2 = AutoModel.from_pretrained(model_name2)
model3 = AutoModel.from_pretrained(model_name3)

# convert the text into sentences, and then use the above models to embed the sentences into vectors
# load the following models for classification
# bert-base-uncased, bart-large-mnli, sentence transformers all-MiniLM-L6-V2
# and then fine-tune them on the above data

def convert_text_into_sentences(text):
    # convert the text into sentences
    # use sentence transformers to parse the text into sentences
    # use spacy en-web-core-trf model to parse the text into sentences
    nlp = spacy.load("en_core_web_trf")
    doc = nlp(text)
    sentences = [sent.text for sent in doc.sents]

    return sentences

# use input_attention_mask and model output to average and max pooling the outputs with tensor size of 128
# write a max_pooling and average_pooling function, the input is model_output and input_attention_mask
def pooling(input_attention_mask, model_output):
    # use input_attention_mask to mask the model_output
    # use max pooling and average pooling to convert the model_output into a single vector representation for the entire sequence (sentence)
    input_attention_mask = input_attention_mask.unsqueeze(-1).expand(model_output.size()).float()
    model_output = model_output * input_attention_mask
    max_pooling = torch.max(model_output, 1)[0]
    average_pooling = torch.mean(model_output, 1)
    # concate both max pooling and average pooling
    pooling = torch.cat((max_pooling, average_pooling), 1)
    return pooling

def pool_embeddings(embeddings, attention_mask):
    # Max pooling
    max_pooled = torch.max(embeddings, dim=1)[0]

    # Average pooling using attention mask
    sum_embeddings = torch.sum(embeddings * attention_mask.unsqueeze(-1), dim=1)
    avg_pooled = sum_embeddings / attention_mask.sum(dim=1, keepdim=True)

    # Concatenate pooled features
    combined = torch.cat([max_pooled, avg_pooled], dim=1)

    return combined

# data object for training the model use def convert_text_into_sentences(text) function
#Pooling strategies are often employed to convert token-level embeddings into a single vector representation for the entire sequence (sentence). Here, we'll use a combination of average and max pooling, taking into account the attention mask to ensure we don't pool over padding tokens.
# use attention mask to ensure we don't pool over padding tokens
class Data(torch.utils.data.Dataset):

    
    def __init__(self, df, tokenizer1, tokenizer2, tokenizer3, model1, model2, model3):
        self.text = df.text.values
        self.sentences = []
        for text in self.text:
            sentences = convert_text_into_sentences(text)
            self.sentences.append(sentences)
        self.categories = df.categories.values
        self.binary_category = df.binary_category.values
        self.tokenizer1 = tokenizer1
        self.tokenizer2 = tokenizer2
        self.tokenizer3 = tokenizer3
        self.model1 = model1
        self.model2 = model2
        self.model3 = model3

    def __len__(self):
        return len(self.text)

    def __getitem__(self, idx):
        text = self.text[idx]
        sentences = self.sentences[idx]
        categories = self.categories[idx]
        binary_category = self.binary_category[idx]

        # embed the sentences into vectors
        embeddings_sentences1 = []
        embeddings_sentences2a = []
        embeddings_sentences2b = []
        embeddings_sentences3 = []
        embeddings_stack = []
        for sentence in sentences:
            # use max-length of sentence to pad the sentence, padding =True, truncation=True, max_length=512            
            input_ids1 = self.tokenizer1(sentence, padding=True, truncation=True, max_length=512, return_tensors="pt")
            input_ids2 = self.tokenizer2(sentence, padding=True, truncation=True, max_length=512, return_tensors="pt")
            input_ids3 = self.tokenizer3(sentence, padding=True, truncation=True, max_length=512, return_tensors="pt")
            with torch.no_grad():
                model_output1 = self.model1(**input_ids1)['last_hidden_state']
                model_output2a = self.model2(**input_ids2)['last_hidden_state']
                model_output2b = self.model2(**input_ids2)['encoder_last_hidden_state']
                model_output3 = self.model3(**input_ids3)['last_hidden_state']
                        
            # use max pooling and average pooling and convert 
            embeddings_sentences1.append(pooling(input_ids1['attention_mask'], model_output1))
            embeddings_sentences2a.append(pooling(input_ids2['attention_mask'], model_output2a))
            embeddings_sentences2b.append(pooling(input_ids2['attention_mask'], model_output2b))
            embeddings_sentences3.append(pooling(input_ids3['attention_mask'], model_output3))
            stack = torch.stack((embeddings_sentences1, embeddings_sentences2a, embeddings_sentences2b, embeddings_sentences3), dim=1)
            embeddings_stack.appedn(torch.mean(stack, dim=1))
                        
        return text, sentences, categories, binary_category, embeddings_stack

# Step 3: Multi-Task Deep Neural Network
# The architecture of the neural network would be:

# An input layer that accepts the concatenated embeddings from the three models.
# A few dense layers for feature extraction.
# Three branches:
# a. Multi-label classification for the high-level categories.
# b. Binary classification for biased/non-biased sentences.
# c. Question-answering task to identify the biased section of the sentence (this is more complex and may require additional considerations).
class MultiTaskModel(nn.Module):
    def __init__(self, embedding_size, num_categories):
        super(MultiTaskModel, self).__init__()

        self.feature_extractor = nn.Sequential(
            nn.Linear(embedding_size, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.5)
        )

        # Multi-label classification branch
        self.multi_label_classifier = nn.Linear(256, num_categories)

        # Binary classification branch
        self.binary_classifier = nn.Linear(256, 1)

        # For QA task, a more sophisticated mechanism is needed. 
        # For the sake of this explanation, I'm using a placeholder.
        self.qa_task = nn.Linear(256, 2)

    def forward(self, x):
        x = self.feature_extractor(x)

        multi_label_output = self.multi_label_classifier(x)
        binary_output = self.binary_classifier(x)
        qa_output = self.qa_task(x)

        return multi_label_output, binary_output, qa_output
    
# Data Preparation
# Assuming you have a PyTorch dataset, you can use the DataLoader for batching
# Instantiate the dataset and dataloader
dataset = AppraisalDataset(your_dataframe, 'text_column_name', 'label_column_name')
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
# Training Loop
# Instantiate the model
model = MultiTaskModel(embedding_size=768*3, num_categories=number_of_high_level_categories)  # Assuming 768 dims for each model's embeddings
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion_multi_label = nn.BCEWithLogitsLoss()  # BCEWithLogitsLoss is typically used for multi-label tasks
criterion_binary = nn.BCEWithLogitsLoss()

num_epochs = 5
for epoch in range(num_epochs):
    for batch in dataloader:
        optimizer.zero_grad()

        # Extract embeddings
        embeddings = get_embeddings(batch['text'])
        
        # Forward pass
        multi_label_output, binary_output, _ = model(embeddings)

        # Compute loss
        loss_multi_label = criterion_multi_label(multi_label_output, batch['multi_label_targets'])
        loss_binary = criterion_binary(binary_output, batch['binary_targets'])
        
        # Combine the two losses
        combined_loss = loss_multi_label + loss_binary
        combined_loss.backward()
        
        optimizer.step()
# Note: This is a high-level outline. The actual implementation would require handling various details, such as:
# Moving data and the model to the GPU (if available).
# Tracking and logging metrics.
# Implementing validation and early stopping.
# Adjusting hyperparameters.
# For inference:
def infer(sentence):
    model.eval()
    with torch.no_grad():
        embeddings = get_embeddings(sentence)
        multi_label_pred, binary_pred, qa_pred = model(embeddings)
    
    # Convert predictions to desired format
    # ...

    return multi_label_pred, binary_pred, qa_pred


-----------------------------------------------------------------------------------------------
import torch
from transformers import BartTokenizer, BartForSequenceClassification, BartForQuestionAnswering
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from sklearn.model_selection import train_test_split
import numpy as np

# Define model names and paths
model_name = "facebook/bart-large-mnli"
saved_model_path = "./saved_model"  # Replace with your desired model save path

# Load a pre-trained BART model for sequence classification
tokenizer = BartTokenizer.from_pretrained(model_name)
classification_model = BartForSequenceClassification.from_pretrained(model_name, num_labels=num_categories)

# Sample data
texts = ["Sample text 1", "Sample text 2", "Sample text 3"]  # Replace with your text data
labels = [[1, 0, 1], [0, 1, 0], [1, 1, 0]]  # Replace with your labels, using 1 for positive classes and 0 for others

# Tokenize and format your annotated data for classification
def tokenize_and_format_data(texts, labels):
    input_ids = []
    attention_masks = []
    encoded_labels = []

    for text, label in zip(texts, labels):
        encoding = tokenizer(text, truncation=True, padding=True, return_tensors="pt")
        input_ids.append(encoding.input_ids)
        attention_masks.append(encoding.attention_mask)
        encoded_labels.append(label)

    input_ids = torch.cat(input_ids, dim=0)
    attention_masks = torch.cat(attention_masks, dim=0)
    encoded_labels = torch.tensor(encoded_labels)

    return input_ids, attention_masks, encoded_labels

input_ids, attention_masks, labels = tokenize_and_format_data(texts, labels)

# Split data into training and validation sets
train_inputs, val_inputs, train_masks, val_masks, train_labels, val_labels = train_test_split(
    input_ids, attention_masks, labels, test_size=0.2, random_state=42
)

# Create data loaders
batch_size = 32  # Adjust as needed
train_data = TensorDataset(train_inputs, train_masks, train_labels)
train_sampler = RandomSampler(train_data)
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

val_data = TensorDataset(val_inputs, val_masks, val_labels)
val_sampler = SequentialSampler(val_data)
val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)

# Fine-tune the classification model
# You can use the code from previous responses for fine-tuning

# Save the fine-tuned classification model
classification_model.save_pretrained(saved_model_path)
tokenizer.save_pretrained(saved_model_path)

# Step 2: Question Answering

# Load the fine-tuned classification model
qa_model = BartForQuestionAnswering.from_pretrained(saved_model_path)

def find_keywords_and_phrases(texts, class_names):
    keyword_ranges = []

    for text, class_name in zip(texts, class_names):
        # Construct an auxiliary question
        question = f"Which part of the text relates to {class_name}?"

        # Tokenize the text and question
        inputs = tokenizer.encode(question, text, return_tensors="pt", max_length=256, truncation=True)

        # Use the QA model to predict the answer (i.e., keywords or phrases)
        with torch.no_grad():
            outputs = qa_model(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)

        # Extract the predicted answer
        start_index = torch.argmax(outputs.start_logits, dim=1).item()
        end_index = torch.argmax(outputs.end_logits, dim=1).item()

        # Get the corresponding text span
        keyword_span = text[inputs.input_ids[0][start_index:end_index + 1]]

        keyword_ranges.append((class_name, keyword_span))

    return keyword_ranges

# Use the combined model for question answering
classification_model.eval()
keyword_ranges = find_keywords_and_phrases(texts, class_names)

# Print the results
for class_name, keyword_span in keyword_ranges:
    print(f"Class: {class_name}")
    print(f"Keywords/Phrases: {keyword_span}")
    print("\n")

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
import torch
from transformers import BertTokenizer, BertForSequenceClassification, BartTokenizer, BartForQuestionAnswering
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from sklearn.model_selection import train_test_split

# Define model names and paths
classification_model_name = "bert-base-uncased"  # Replace with your classification model name
qa_model_name = "facebook/bart-large-cnn"  # Replace with your QA model name
saved_model_path = "./saved_model"  # Replace with your desired model save path

# Load a pre-trained BERT model for sequence classification
classification_tokenizer = BertTokenizer.from_pretrained(classification_model_name)
classification_model = BertForSequenceClassification.from_pretrained(classification_model_name, num_labels=num_categories)

# Load a pre-trained BART model for question answering
qa_tokenizer = BartTokenizer.from_pretrained(qa_model_name)
qa_model = BartForQuestionAnswering.from_pretrained(qa_model_name)

# Sample data
texts = ["Sample text 1", "Sample text 2", "Sample text 3"]  # Replace with your text data
class_names = ["Class 1", "Class 2", "Class 3"]  # Replace with your class names

# Step 1: Classification

# Tokenize and format your annotated data
def tokenize_and_format_data(texts, labels):
    input_ids = []
    attention_masks = []
    encoded_labels = []

    for text, label in zip(texts, labels):
        encoding = classification_tokenizer(text, truncation=True, padding=True, return_tensors="pt")
        input_ids.append(encoding.input_ids)
        attention_masks.append(encoding.attention_mask)
        encoded_labels.append(label)

    input_ids = torch.cat(input_ids, dim=0)
    attention_masks = torch.cat(attention_masks, dim=0)
    encoded_labels = torch.tensor(encoded_labels)

    return input_ids, attention_masks, encoded_labels

input_ids, attention_masks, labels = tokenize_and_format_data(texts, class_names)

# Split data into training and validation sets
train_inputs, val_inputs, train_masks, val_masks, train_labels, val_labels = train_test_split(
    input_ids, attention_masks, labels, test_size=0.2, random_state=42
)

# Create data loaders
batch_size = 32  # Adjust as needed
train_data = TensorDataset(train_inputs, train_masks, train_labels)
train_sampler = RandomSampler(train_data)
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

val_data = TensorDataset(val_inputs, val_masks, val_labels)
val_sampler = SequentialSampler(val_data)
val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)

# Fine-tune the classification model (use the code from previous responses)

# Step 2: Question Answering

def find_keywords_and_phrases(texts, class_names):
    keyword_ranges = []

    for text, class_name in zip(texts, class_names):
        # Tokenize the text and class name
        inputs = qa_tokenizer(class_name, text, return_tensors="pt")

        # Use the QA model to predict the answer (i.e., keywords or phrases)
        with torch.no_grad():
            outputs = qa_model(**inputs)

        # Extract the start and end positions of the answer
        start_index = torch.argmax(outputs.start_logits, dim=1).item()
        end_index = torch.argmax(outputs.end_logits, dim=1).item()

        # Get the corresponding text span
        keyword_span = text[inputs.input_ids[0][start_index:end_index + 1]]

        keyword_ranges.append((class_name, keyword_span))

    return keyword_ranges

# Use the combined model
for epoch in range(num_epochs):  # You can define num_epochs as needed
    classification_model.train()
    total_loss = 0

    for batch in train_dataloader:
        inputs, masks, labels = batch
        outputs = classification_model(inputs, attention_mask=masks, labels=labels)
        loss = outputs.loss

        loss.backward()
        total_loss += loss.item()

        torch.nn.utils.clip_grad_norm_(classification_model.parameters(), max_grad_norm)

        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()

    # Calculate average training loss for this epoch
    avg_train_loss = total_loss / len(train_dataloader)

    # Validation
    classification_model.eval()
    val_loss = 0

    for batch in val_dataloader:
        inputs, masks, labels = batch
        with torch.no_grad():
            outputs = classification_model(inputs, attention_mask=masks, labels=labels)
            val_loss += outputs.loss.item()

    # Calculate average validation loss for this epoch
    avg_val_loss = val_loss / len(val_dataloader)

    # Print training and validation loss for this epoch
    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')

    # Step 2: Question Answering
    keyword_ranges = find_keywords_and_phrases(texts, class_names)

    # Print the results
    for class_name, keyword_span in keyword_ranges:
        print(f"Class: {class_name}")
        print(f"Keywords/Phrases: {keyword_span}")
        print("\n")

# Save the combined model
classification_model.save_pretrained(saved_model_path)
qa_model.save_pretrained(saved_model_path)
classification_tokenizer.save_pretrained(saved_model_path)
qa_tokenizer.save_pretrained(saved_model_path)

---------------------------------------------------------------------------------------------
from transformers import BartForSequenceClassification, BartTokenizer

model_name = "facebook/bart-large-mnli"
tokenizer = BartTokenizer.from_pretrained(model_name)
model = BartForSequenceClassification.from_pretrained(model_name, num_labels=num_categories)
def tokenize_and_format_data(texts, labels):
    formatted_data = []

    for text, label in zip(texts, labels):
        inputs = tokenizer.encode("classification: " + text, truncation=True, padding=True, return_tensors="pt")
        formatted_data.append((inputs, label))

    return formatted_data

formatted_data = tokenize_and_format_data(texts, labels)
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset

train_data, val_data = train_test_split(formatted_data, test_size=0.2, random_state=42)

train_inputs = torch.stack([item[0] for item in train_data])
train_labels = torch.tensor([item[1] for item in train_data])

val_inputs = torch.stack([item[0] for item in val_data])
val_labels = torch.tensor([item[1] for item in val_data])

train_dataset = TensorDataset(train_inputs, train_labels)
train_sampler = RandomSampler(train_dataset)
train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)

val_dataset = TensorDataset(val_inputs, val_labels)
val_sampler = SequentialSampler(val_dataset)
val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)


from transformers import AdamW, get_linear_schedule_with_warmup

# Define optimizer and learning rate scheduler
optimizer = AdamW(model.parameters(), lr=learning_rate, eps=epsilon)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)

# Training loop
for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for batch in train_dataloader:
        inputs, labels = batch
        outputs = model(inputs, labels=labels)
        loss = outputs.loss

        loss.backward()
        total_loss += loss.item()

        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)

        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()

    # Calculate average training loss for this epoch
    avg_train_loss = total_loss / len(train_dataloader)

    # Validation
    model.eval()
    val_loss = 0

    for batch in val_dataloader:
        inputs, labels = batch
        with torch.no_grad():
            outputs = model(inputs, labels=labels)
            val_loss += outputs.loss.item()

    # Calculate average validation loss for this epoch
    avg_val_loss = val_loss / len(val_dataloader)

    # Print training and validation loss for this epoch
    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')


model.save_pretrained(saved_model_path)
tokenizer.save_pretrained(saved_model_path)

=============================================================================================

from transformers import BertTokenizer, BertForSequenceClassification

# Load the pre-trained model and tokenizer
model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_categories)
# Tokenize and format your data
def tokenize_and_format_data(texts, labels):
    input_ids = []
    attention_masks = []
    encoded_labels = []

    for text, label in zip(texts, labels):
        encoding = tokenizer(text, truncation=True, padding=True, return_tensors="pt")
        input_ids.append(encoding.input_ids)
        attention_masks.append(encoding.attention_mask)
        encoded_labels.append(label)

    input_ids = torch.cat(input_ids, dim=0)
    attention_masks = torch.cat(attention_masks, dim=0)
    encoded_labels = torch.tensor(encoded_labels)

    return input_ids, attention_masks, encoded_labels

input_ids, attention_masks, labels = tokenize_and_format_data(texts, labels)
from sklearn.model_selection import train_test_split

train_inputs, val_inputs, train_masks, val_masks, train_labels, val_labels = train_test_split(
    input_ids, attention_masks, labels, test_size=0.2, random_state=42
)
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

train_data = TensorDataset(train_inputs, train_masks, train_labels)
train_sampler = RandomSampler(train_data)
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

val_data = TensorDataset(val_inputs, val_masks, val_labels)
val_sampler = SequentialSampler(val_data)
val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)
from transformers import AdamW, get_linear_schedule_with_warmup

# Define optimizer and learning rate scheduler
optimizer = AdamW(model.parameters(), lr=learning_rate, eps=epsilon)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)

# Training loop
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    
    for batch in train_dataloader:
        # Forward pass
        inputs, masks, labels = batch
        outputs = model(inputs, attention_mask=masks, labels=labels)
        loss = outputs.loss
        
        # Backward pass
        loss.backward()
        total_loss += loss.item()
        
        # Gradient clipping if needed
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        
        # Update parameters
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()

    # Calculate average training loss for this epoch
    avg_train_loss = total_loss / len(train_dataloader)

    # Validation
    model.eval()
    val_loss = 0

    for batch in val_dataloader:
        inputs, masks, labels = batch
        with torch.no_grad():
            outputs = model(inputs, attention_mask=masks, labels=labels)
            val_loss += outputs.loss.item()

    # Calculate average validation loss for this epoch
    avg_val_loss = val_loss / len(val_dataloader)

    # Print training and validation loss for this epoch
    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')
model.save_pretrained(saved_model_path)
tokenizer.save_pretrained(saved_model_path)




-======================-----------------------------------------------------------------------==================================
import pandas as pd

# Example DataFrame
data = {
    'Column1': ['data1', 'data2'],  # Non-list column
    'Column2': ['info1', 'info2'],  # Non-list column
    'ListColumn1': [[1, 2, 3], [4, 5, 6]],  # List column
    'ListColumn2': [['A', 'B', 'C'], ['D', 'E', 'F']],  # List column
    'ListColumn3': [['X', 'Y', 'Z'], ['U', 'V', 'W']]   # List column
}

df = pd.DataFrame(data)

# Exploding the DataFrame
df_exploded = pd.DataFrame({
    'Column1': df['Column1'].repeat(df['ListColumn1'].str.len()),
    'Column2': df['Column2'].repeat(df['ListColumn1'].str.len()),
    'ListColumn1': [item for sublist in df['ListColumn1'] for item in sublist],
    'ListColumn2': [item for sublist in df['ListColumn2'] for item in sublist],
    'ListColumn3': [item for sublist in df['ListColumn3'] for item in sublist]
}).reset_index(drop=True)

print(df_exploded)

-----------------------------------------------------------------------------------------------------------
data = {
    'Column1': [[1, 2, 3], [4, 5, 6]],
    'Column2': [['a', 'b', 'c'], ['d', 'e', 'f']],
    'Column3': [['x', 'y', 'z'], ['u', 'v', 'w']]
}

df = pd.DataFrame(data)

# Ensure all lists in each row are of the same length
# Explode the DataFrame
df['combined'] = list(zip(df['Column1'], df['Column2'], df['Column3']))
df_exploded = df.explode('combined')

# Create separate columns from the tuples
df_exploded[['Column1', 'Column2', 'Column3']] = pd.DataFrame(df_exploded['combined'].tolist(), index=df_exploded.index)

# Drop the combined column if not needed
df_exploded = df_exploded.drop('combined', axis=1)

print(df_exploded)




Background, Purpose, and Scope:
Fannie Mae, a leading provider of mortgage financing, receives thousands of recommendation memos, sponsor credit reviews, and sponsor and lender narratives as part of the loan underwriting process for multifamily properties. This voluminous documentation is essential for assessing the collateral worth of these properties. However, not all the information contained within these reports is necessarily useful for creating an accurate property valuation. In some instances, the appraisals may include subjective opinions or biases based on protected characteristics under fair lending laws and regulations, and these biases can manifest in non-obvious ways.
To address this issue, Fannie Mae's MF Lender Risk Management team has been manually reviewing these reports since 2021, identifying and flagging language that violates the Fannie Mae Selling Guide or contains subjective terminology that should not affect the property's value. While this manual review process has been effective, it is time-consuming and represents a significant cost to the organization.
The purpose of this project is to develop an internal solution that can automatically scan multifamily appraisal comments and detect prohibited language within them. This solution is closely related to the Automated Property Linguistic Detection (APLD) model developed for Fannie Mae's Collateral Risk team, which addresses similar challenges in the single-family mortgage market.
The scope of this project is to create a robust, two-stage AI-based solution, the Multifamily Prohibited Language Detection (MFPLD) model, that can efficiently and reliably identify prohibited language in multifamily appraisal comments, reducing the workload for manual review and ensuring fair and equitable collateral valuation.
Model Usage
The MFPLD model is designed to be used by Fannie Mae's MF Lender Risk Management team to automate the process of detecting prohibited language in multifamily appraisal comments. The model will receive a list of biased language categories from the Fair Lending team, as well as the appraisal files to be analyzed.
In the first stage of the model, the MFPLD model will parse the appraisal reports into sentences and compare them to a pre-defined keyword list provided by the Fair Lending team. This will allow the model to identify any sentences that contain prohibited language related to the input categories.
In the second stage, a text classification model will be used to reduce the number of false positives and false negatives in the results of the first stage. This two-stage approach is similar to the APLD model developed for the Collateral Risk team and is designed to create an effective solution that significantly reduces or eliminates the need for manual review of appraisals for potential bias.
Scope of Model Changes:
The MFPLD model is designed to be a flexible and adaptable solution that can evolve over time to meet the changing needs of Fannie Mae's MF Lender Risk Management team. The model's scope can be expanded to include additional biased language categories, as identified by the Fair Lending team, or to incorporate new sources of appraisal data as they become available.
Furthermore, the text classification model used in the second stage of the MFPLD solution can be fine-tuned and retrained over time to improve its accuracy in detecting false positives and false negatives. This ongoing model refinement will ensure that the MFPLD solution remains effective and efficient in identifying prohibited language in multifamily appraisal comments.
Model Overview:
The MFPLD model is a two-stage AI-based solution that is designed to automatically detect prohibited language in multifamily appraisal comments. The key components of the model are as follows:
Stage 1: Keyword-based Detection
The model receives a list of biased language categories from the Fair Lending team.
The model parses the appraisal reports into sentences and compares them to a pre-defined keyword list provided by the Fair Lending team.
The model identifies any sentences that contain prohibited language related to the input categories.
Stage 2: Text Classification
A text classification model is used to analyze the results of the first stage and identify any false positives or false negatives.
The text classification model is trained on a dataset of appraisal comments, both those containing prohibited language and those that do not, to improve the overall accuracy of the MFPLD solution.
The two-stage approach of the MFPLD model is designed to provide a comprehensive and reliable solution for detecting prohibited language in multifamily appraisal comments. By combining keyword-based detection with machine learning-based text classification, the model can efficiently and accurately identify biased language, reducing the workload for manual review and ensuring fair and equitable collateral valuation.
1. Background, Purpose, and Scope
Background
Fannie Mae is a pivotal entity in the housing finance system, tasked with the significant responsibility of underwriting multifamily property loans. This process requires the examination of thousands of documents annually, including recommendation memos, sponsor credit reviews, and sponsor and lender narrative reports. These documents are crucial for assessing the collateral worth of properties, yet they often contain extraneous or biased information that can skew property valuations. Recognizing the potential for subjective opinions and biases, especially those infringing upon fair lending laws by focusing on protected characteristics, Fannie Mae has historically engaged in manual reviews to identify and address prohibited language within these appraisals.
Purpose
The core aim of introducing an automated solution is to streamline the identification of biased or prohibited language in appraisal comments. This initiative not only seeks to enhance the efficiency and reliability of the process but also aims to mitigate the risk of bias affecting property valuations. By automating this critical review process, Fannie Mae intends to uphold the integrity of its underwriting process while significantly reducing the operational burden and associated costs of manual reviews.
Scope
The project's scope encompasses the development and implementation of an internal solution designed to automatically scan multifamily (MF) appraisal comments for prohibited language. Leveraging a two-stage artificial intelligence model, this solution will closely mirror the functionality of the existing APLD model used by the Single Family Collateral Risk team. The scope includes parsing appraisal reports into sentences, detecting biased phrases based on a predefined keyword list, and employing a text classification model to minimize false positives and negatives in the appraisal review process.
2. Model Usage
The proposed model operates on a two-stage principle to ensure thorough and accurate detection of prohibited language within multifamily appraisal comments. The first stage involves receiving a list of biased categories from the user, alongside the appraisal files. The model then parses these reports into sentences, utilizing a keyword list provided by the Fair Lending team to identify phrases closely resembling prohibited language related to the input categories. This initial stage allows users to maintain control over the categories deemed prohibited, ensuring that the model's focus aligns with current regulatory standards and organizational policies.
In the second stage, the model employs a sophisticated text classification algorithm to sift through the results from the first stage, aiming to accurately distinguish between true and false positives. This dual-stage approach not only enhances the precision of the detection process but also significantly reduces the likelihood of overlooking genuine instances of biased language or erroneously flagging innocuous content.
3. Scope of Model Changes
The introduction of the MFPLD model signifies a significant advancement in Fannie Mae's approach to managing collateral risk and ensuring fair lending practices. While the model inherits its foundational principles from the Single Family's APLD model, it incorporates several key enhancements to address the unique challenges presented by multifamily appraisal comments. The most notable change lies in the adaptation and expansion of the keyword list, tailored to reflect the nuanced language commonly found in multifamily appraisals. Additionally, the inclusion of a machine learning model in the second stage represents a strategic enhancement aimed at improving the accuracy of bias detection by reducing false positives and negatives. These modifications are expected to augment the model's effectiveness, enabling a more streamlined, accurate, and efficient review process.
4. Model Overview
The MFPLD model represents a cutting-edge solution designed to automate the detection of prohibited language in multifamily appraisal comments. At its core, the model is structured around a two-stage artificial intelligence system that mirrors the proven efficacy of the APLD model used within the Single Family sector. The first stage focuses on parsing appraisal reports into sentences and identifying phrases that closely match a predefined list of biased keywords. This approach allows for precise detection of potentially prohibited language, with a significant emphasis on user-defined categories.
The second stage introduces an advanced text classification model, which meticulously reviews the findings from the first stage to discern between true and false positives. This layered approach ensures a high degree of accuracy in identifying biased language, effectively minimizing the risks associated with manual review processes. Through its innovative design and strategic implementation, the MFPLD model is poised to revolutionize Fannie Mae's appraisal review process, offering a scalable, efficient, and reliable solution for upholding the highest standards of fairness and integrity in property valuation.
---------------------------------------------------------------------------------------------------------------------------------------------------------
1. Background, Purpose, and Scope
The underwriting process at Fannie Mae involves the analysis of thousands of documents annually, including recommendation memos, sponsor credit reviews, and narratives from sponsors and lenders. These documents play a crucial role in assessing the value of multifamily properties, which is essential for determining collateral worth. However, not all information contained within these reports contributes to an accurate property valuation. Subjective opinions or biases based on protected characteristics, which are prohibited under fair lending laws and regulations, can inadvertently influence these assessments.
Since 2021, the MF Lender Risk Management team at Fannie Mae has been tasked with manually reviewing these documents to identify and flag language that violates the Fannie Mae Selling Guide or introduces subjective bias that could affect property valuation. Identified violations prompt notifications to appraisers about the use of such language. This manual review process, while necessary, is both time-consuming and costly.
The purpose of this initiative is to develop an automated solution capable of detecting prohibited language within MF appraisal comments efficiently and reliably. The scope includes the automation of bias detection in appraisal comments, leveraging AI technology to streamline the process previously managed through manual review. This move aims to significantly reduce the workload and associated costs of manual bias detection in appraisal documents, enhancing efficiency and accuracy in Fannie Mae's underwriting process.
2. Model Usage
The proposed solution is a two-stage AI model, designed to automate the detection of prohibited language within multifamily (MF) appraisal comments. The first stage involves receiving a list of biased categories and the appraisal files from the user. The model then parses these appraisal reports into sentences and employs a keyword list, pre-defined by the Fair Lending team, to identify sentences that contain language similar to the biased phrases related to the input categories. This process ensures that detection is aligned with the specific prohibitions deined by the individuals overseeing these categories.

The second stage of the model applies a text classification technique to sift through the results of the first stage, aiming to identify false positives. This two-pronged approach mirrors the APLD model developed for the Collateral Risk team, emphasizing the reduction of both false positives and false negatives in the detection process. By adding a machine learning (ML) model in the second stage, the solution endeavors to enhance the reliability and efficiency of detecting biased language in appraisal comments, thereby reducing the necessity for manual review.
3. Scope of Model Changes
The MFPLD model represents an evolution from the previously developed APLD model, specifically tailored for the appraisal comments of multifamily properties. This new model introduces several critical enhancements to accommodate the unique requirements of MF appraisal document review. Firstly, it incorporates a more extensive and detailed pre-defined keyword list provided by the Fair Lending team, ensuring comprehensive coverage of biased language across various categories.
Furthermore, the addition of a machine learning model in the second stage marks a significant improvement aimed at refining the detection process. This ML model is tasked with reducing the rates of false positives and false negatives, addressing one of the main challenges in automated language detection. By focusing on the accuracy and reliability of the detection mechanism, the MFPLD model aims to significantly diminish the manual effort required in reviewing appraisal documents for potential bias, streamlining the process for Fannie Mae's MF Lender Risk Management team.
4. Model Overview
The MFPLD model is a sophisticated AI solution designed to automate the detection of prohibited language within appraisal comments for multifamily properties. It operates in two distinct stages to ensure high accuracy and efficiency. In the first stage, the model receives user-defined biased categories along with the appraisal files. It then parses these files into sentences and employs a pre-defined keyword list to detect sentences that may contain biased language related to the specified categories.
====================================================================================================
1.1 Background, Purpose, and Scope
Background: Fannie Mae processes thousands of documents annually as part of its multifamily property loan underwriting procedures. These documents, including recommendation memos and sponsor credit reviews, play a critical role in evaluating the collateral worth of properties. A recurring challenge has been the presence of biased language within these reports, which can affect the accuracy of property valuations. This biased language, often subtle and rooted in subjective opinions or protected characteristics, contravenes fair lending laws and regulations.
Purpose: The purpose of developing the MFPLD (Multifamily Prohibited Language Detector) model is to automate the detection of prohibited language within appraisal comments, thereby enhancing the accuracy and fairness of property valuations. This initiative stems from the need to improve efficiency and reduce the manual labor involved in reviewing appraisal reports for biased language, a process that is both time-consuming and costly.
Scope: The model is designed to automatically scan and detect biased language in multifamily appraisal comments, leveraging a two-stage AI solution for this purpose. It is an internal solution closely related to the APLD model developed for the Collateral Risk team, aimed at significantly reducing the workload associated with manual reviews of appraisal reports for potential bias. The MFPLD model applies specifically to the multifamily property loan underwriting process at Fannie Mae, addressing a previously unaddressed problem of automated bias detection in appraisal reports.
Model Development: This is a new model, developed to address the challenges of manually detecting biased language in appraisal reports—a process previously unautomated. The MFPLD model represents an innovative approach to enhancing the accuracy and fairness of property valuations at Fannie Mae.
1.2 Model Usage
Application: The MFPLD model is used within the loan underwriting process, specifically in assessing the collateral worth of multifamily properties. Its primary function is to automate the detection of prohibited language in appraisal comments, contributing to more accurate and unbiased property valuations.
Product Types and Segmentation: The model is applicable to multifamily property appraisals, serving as a critical tool in the loan underwriting process for these properties.
Expected Results: By automating the detection of biased language, the model aims to improve the efficiency, accuracy, and fairness of property valuations. This contributes to a more equitable lending process, in line with fair lending laws and regulations.
Known and Planned Usages: Currently, the MFPLD model is used to scan and detect prohibited language in multifamily appraisal comments. Future enhancements and broader applications within Fannie Mae's loan underwriting processes are anticipated as the model's capabilities evolve.
1.3 Scope of Model Changes
Major Changes: Given that the MFPLD model is a new development, this section would typically outline any significant changes from previous versions or related models. In the case of the MFPLD, it can be noted that it introduces a two-stage AI solution for detecting prohibited language, an advancement over manual review processes previously employed.
Minor Changes: Any minor changes or enhancements made during the development phase would be detailed in Appendix E, as per the document structure.
1.4 Model Overview
Reasons for Creation: The MFPLD model was created to address the inefficiencies and inaccuracies associated with manually reviewing appraisal reports for biased language. By automating this process, Fannie Mae aims to enhance the fairness and accuracy of property valuations for multifamily properties.
Enhancements in Modeling Methodology: The model introduces a two-stage AI solution, incorporating both keyword detection and text classification to accurately identify prohibited language in appraisal comments. This methodology represents a significant enhancement over previous manual processes.
Improvements in Model Performance: The automation of biased language detection is expected to significantly reduce the time and cost associated with manual reviews, while also improving the accuracy and fairness of property valuations.
Upstream and Downstream Models: The MFPLD model works in conjunction with other models in the loan underwriting process, such as the APLD model for the Collateral Risk team. A depiction of model interdependencies, including data flows, would illustrate how the MFPLD model integrates within Fannie Mae's broader risk management framework.
Component Model Information Systems: The development and operation of the MFPLD model involve various programs, software, and technologies, including AI and machine learning platforms, which enable the parsing of appraisal reports and the detection of biased language.
This content provides a structured outline for each of the segments based on the executive summary provided.
The second stage involves a machine learning (ML) model that scrutinizes the results from the first stage, identifying and filtering out false positives. This dual-stage approach enhances the model's capability to accurately detect prohibited language, thereby significantly reducing the manual review workload.
The development of the MFPLD model is a testament to Fannie Mae's commitment to leveraging technology for improving efficiency and accuracy in the underwriting process. By automating the detection of biased language in appraisal documents, the MFPLD model represents a critical step forward in streamlining operations and upholding the integrity of property valuations under fair lending laws and regulations.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
The MFPLD (Multifamily Prohibited Language Detector) model is designed to streamline the process of identifying biased language within appraisal reports, a crucial step in ensuring fair and accurate property evaluations. At the outset, users input specific categories of bias they wish to detect, along with the appraisal documents to be analyzed. Following this initial setup, the model meticulously segments the reports into individual sentences. It then employs an advanced algorithm to scrutinize each sentence against a comprehensive list of biased phrases. This list is meticulously curated by the Fair Lending team, ensuring it reflects the most current understanding of language that could unfairly influence property valuations. This approach empowers users with the authority to define and target specific prohibited language categories, tailoring the detection process to meet stringent fairness criteria.
In the subsequent phase of analysis, the model leverages a sophisticated text classification system to sift through the preliminary findings. This is where the model's intelligence shines, as it diligently distinguishes between true instances of biased language and those sentences falsely flagged in the initial screening. This dual-layered approach, inspired by the proven efficacy of the APLD model used by the Collateral Risk team, incorporates machine learning techniques to refine its accuracy further. By minimizing the rates of both false positives (innocuous sentences incorrectly flagged as biased) and false negatives (biased sentences that go undetected), the model significantly enhances the efficiency and reliability of the detection process.
This two-pronged strategy represents a potent solution to the traditionally labor-intensive task of manually reviewing appraisal reports for bias. By automating the detection of prohibited language with such precision and control, the MFPLD model promises to drastically reduce the human effort required in these analyses. Consequently, this not only speeds up the appraisal review process but also elevates the standard of fairness in property valuations, aligning closely with the overarching objectives of fair lending practices.
111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111
Thank you for providing the detailed conceptual framework and model structure for the Multifamily Prohibited Language Detection (MFPLD) model. This is a comprehensive overview that covers the key components, mathematical specifications, and literature survey supporting the model's design. Let me summarize the key points:

Biased Language Categories and Mapping Dictionary:
The model uses 10 high-level biased language categories (e.g., sexual orientation, gender, race/ethnicity) and a mapping dictionary of 620 corresponding biased phrases.
Sentence Parsing and Embedding:
The model parses documents into sentences and generates 256-dimensional sentence embeddings using the sentence-transformers-all-miniLM-l6v2 model.
The model also generates embeddings for the 620 biased phrases.
Similarity Calculation:
The model calculates the cosine similarity between each sentence and the 620 biased phrases.
The maximum similarity score for each of the 10 high-level biased language categories is reported.
Bias Detection:
If any of the 10 similarity scores for a sentence exceeds a global similarity threshold (0.50 in this case), the model flags the sentence as containing biased language.
The conceptual framework is based on the premise that biased language in mortgage appraisal and related documents can influence property valuation, leading to unfair and inequitable outcomes. The two-stage approach, combining keyword-based detection and text classification, is a novel and unique solution compared to alternative methodologies like rule-based, supervised machine learning, and unsupervised anomaly detection approaches.The mathematical specifications and literature survey provided demonstrate the solid theoretical and empirical foundations of the MFPLD model. The use of sentence embeddings, similarity calculations, and a global threshold for bias detection are well-supported by the referenced research.
Overall, this is a comprehensive and well-designed framework for detecting prohibited language in mortgage-related documents, with the potential to improve fairness and equity in property valuation. The hybrid approach leverages the strengths of both rule-based and machine learning techniques to create a robust and effective solution.
-------------------------------------------------------------------------------------------------------------------------------------------------------------
Conceptual Framework and Model Structure

The Multifamily Prohibited Language Detection (MFPLD) model is a two-stage AI-based solution designed to automatically detect prohibited language in mortgage appraisal and other related documents that may affect property valuation. The model consists of the following key components:

Biased Language Categories and Mapping Dictionary
The model receives a list of 10 high-level biased language categories, such as sexual orientation, gender, location, desirability, disability, income-level, familial status, race/nationality/ethnicity, age, and demographics.
The model also receives a mapping dictionary that maps each high-level category to 620 corresponding biased phrases, such as "poor family," "low-income community," and so on.
Sentence Parsing and Embedding
The model receives appraisal and other related documents and parses them into sentences.
The model uses the sentence-transformers-all-miniLM-l6v2 model to generate 256-dimensional embedding vectors for each sentence and for the 620 biased phrases.
Similarity Calculation
After mean-pooling and normalizing the embedding vectors, the model calculates the cosine similarity between each sentence and the 620 biased phrases from the 10 high-level categories.
The model then reports the 10 high-level category similarity scores by finding the maximum similarity score from the biased phrases related to each high-level category.
Bias Detection
If any of the 10 similarity scores for a sentence is higher than a global similarity threshold (set to 0.50 in this case), the model adds a binary variable to the report indicating that the sentence contains biased language.
The conceptual framework of the MFPLD model is based on the premise that subjective opinions or biased language in mortgage appraisal and related documents can influence property valuation, potentially leading to unfair and inequitable outcomes. By automating the detection of such prohibited language, the model aims to reduce the workload for manual review and ensure fair and equitable collateral valuation.

Mathematical Specifications

The MFPLD model leverages several mathematical and statistical techniques to achieve its objectives:

Sentence Embedding:
The model uses the sentence-transformers-all-miniLM-l6v2 model to generate 256-dimensional embedding vectors for each sentence and the 620 biased phrases.
The embedding vectors are mean-pooled and normalized to obtain the final sentence and biased phrase representations.
Similarity Calculation:
The model calculates the cosine similarity between each sentence and the 620 biased phrases using the formula:

Copy code
similarity = dot(sentence_embedding, biased_phrase_embedding) / (norm(sentence_embedding) * norm(biased_phrase_embedding))
The maximum similarity score for each of the 10 high-level biased language categories is then reported.
Bias Detection:
The model compares the maximum similarity scores for each sentence against a global similarity threshold (set to 0.50 in this case).
If any of the similarity scores exceed the threshold, the model adds a binary variable to the report indicating the presence of biased language in the sentence.
Literature Survey

The conceptual framework and modeling techniques used in the MFPLD model are supported by various academic and industry publications:

Sentence Embedding and Similarity Calculation:
Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (pp. 3982-3992). Link
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008). Link
Bias Detection in Language Models:
Bolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V., & Kalai, A. T. (2016). Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. In Advances in neural information processing systems (pp. 4349-4357). Link
Zhao, J., Wang, T., Yatskar, M., Ordonez, V., & Chang, K. W. (2017). Men also like shopping: Reducing gender bias amplification using corpus-level constraints. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 2979-2989). Link
Bias in Mortgage Appraisals:
Howell, J., & Korver-Glenn, E. (2020). The Increasing Effect of Neighborhood Racial Composition on Housing Values, 1980–2015. Social Problems, 68(4), 1025-1044. Link
Perry, A. M., Rothwell, J., & Harshbarger, D. (2018). The devaluation of assets in Black neighborhoods: The case of residential property. Brookings Institution. Link
Evaluation of Alternative Methodologies

The MFPLD model's two-stage approach, combining keyword-based detection and text classification, is a novel and unique approach to the problem of detecting prohibited language in mortgage appraisal and related documents.

Alternative methodologies that were considered and their strengths and weaknesses include:

Rule-based Approach:
Strengths: Simple to implement, easy to understand, and provides transparent decision-making.
Weaknesses: Requires extensive manual curation of rules, may miss subtle or context-dependent biases, and may have high false positive rates.
Supervised Machine Learning Approach:
Strengths: Can learn complex patterns from data, potentially more accurate than rule-based approaches.
Weaknesses: Requires a large annotated dataset, which can be time-consuming and expensive to obtain, and may struggle with out-of-sample data.
Unsupervised Anomaly Detection Approach:
Strengths: Can identify unusual or anomalous language without prior labeling, may uncover previously unknown biases.
Weaknesses: May have high false positive rates, difficult to interpret and explain the results.
The two-stage approach of the MFPLD model, combining the strengths of keyword-based detection and text classification, is designed to address the limitations of these alternative methodologies. The keyword-based detection provides a transparent and controllable mechanism for identifying prohibited language, while the text classification model helps to reduce false positives and false negatives. This hybrid approach leverages the benefits of both rule-based and machine learning techniques, resulting in a more robust and effective solution for detecting prohibited language in mortgage appraisal and related documents.
-------------------------------------------------------------------------------------------------------------------------------------------------------------
The development of a model aimed at identifying and analyzing subjective opinions or biased language within mortgage appraisal documents and related content is a critical step towards ensuring fairness and objectivity in property valuation processes. The model described here uses a sophisticated blend of natural language processing (NLP) techniques and sentence embedding technologies to detect biased language across ten high-level categories. This white paper outlines the conceptual framework, mathematical specifications, and theoretical background of the model, evaluates alternative methodologies, and discusses the strengths and weaknesses of various approaches.

Conceptual Framework and Model Structure
The model is designed to process appraisal and related documents by parsing the text into sentences and analyzing these sentences for biased language corresponding to ten predetermined categories (e.g., sexual orientation, gender, location, desirability). It achieves this through the use of the sentence-transformers-all-miniLM-l6v2 for embedding both the biased phrases and sentences from the documents. By calculating the cosine similarity between sentence embeddings and pre-defined biased phrase embeddings, the model identifies and quantifies the level of bias in each sentence.

Model Structure:
Input Processing: Receives documents and a mapping dictionary linking high-level bias categories to specific biased phrases (620 in total).
Sentence Embedding: Uses sentence-transformers-all-miniLM-l6v2 for embedding sentences and biased phrases, employing mean-pooling and normalization to process embedding vectors.
Cosine Similarity Calculation: Computes the cosine similarity between sentence embeddings and biased phrase embeddings.
Bias Detection: Assigns similarity scores to sentences based on their maximum similarity to biased phrases within each of the ten categories. Sentences with scores above a 0.50 threshold are flagged as biased.
Mathematical Specifications
The core mathematical operation in this model is the calculation of cosine similarity between the embedding vectors of sentences and biased phrases. 
The cosine similarity is defined as:

B are the embedding vectors of a sentence and a biased phrase, respectively. Mean-pooling is applied to embeddings to obtain a fixed-length vector for each sentence or phrase, followed by normalization to ensure comparability.

Literature Survey and Theoretical Background
The theoretical foundation of this model is rooted in the domain of natural language processing and machine learning, particularly in the use of embeddings for semantic analysis and bias detection. Sentence embeddings, as popularized by models like BERT and its variants (such as miniLM), have shown considerable success in capturing the contextual meanings of sentences (Devlin et al., 2018; Wang et al., 2020).

The application of cosine similarity measures to compare embeddings is a well-established technique for semantic similarity assessment, offering a straightforward yet powerful means of identifying related concepts within texts (Mikolov et al., 2013).

Evaluation of Alternative Methodologies
Several alternative methodologies could be considered for this task, including rule-based systems, classic machine learning classifiers (e.g., SVMs, Random Forests), and other forms of deep learning models (e.g., RNNs, CNNs).

Strengths and Weaknesses:
Rule-Based Systems: While interpretable, they lack the flexibility and scalability of ML approaches, often missing nuanced expressions of bias.
Classic Machine Learning: These models can be effective but require extensive feature engineering and may not capture the contextual nuances as effectively as embedding-based methods.
Deep Learning Models (RNNs, CNNs): Though powerful for text analysis, they may require more data and computational resources than embedding-based approaches.
Rationale for Selected Methodology
The decision to employ sentence embeddings, particularly using the miniLM model for embedding generation, was driven by the model's ability to efficiently capture deep semantic meanings of text. The use of cosine similarity provides a straightforward and computationally efficient mechanism to assess the degree of bias within sentences. This approach balances performance with computational efficiency, making it particularly suitable for processing large volumes of text without sacrificing accuracy.

Conclusion
The described model represents a novel approach to detecting biased language within mortgage appraisal documents, leveraging the latest advancements in NLP and embedding technologies. Its design and methodology are grounded in sound mathematical principles and supported by existing literature, offering a balanced approach to bias detection that is both efficient and effective.
Appendix D: References
Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv.
Wang, Y., Wang, W., Xu, J., & Shen, J. (2020). MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. arXiv.
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector


==================================================================================================================================================
The sentence-transformers/all-MiniLM-L6-v2 model is a pre-trained model available on Hugging Face, and it's part of the Sentence Transformers library. This model is designed to generate meaningful and semantically rich embeddings for sentences, making it highly effective for tasks such as semantic search, clustering, and text similarity.

Here are some key points about the model:

Model Architecture: It is based on the MiniLM architecture, which is a smaller, more efficient version of the large transformer models like BERT. MiniLM models achieve competitive performance while being more resource-friendly, making them suitable for applications where computational resources are limited.

Training Data: The model has been trained on a diverse set of data sources, aiming to capture a wide range of linguistic features and nuances. This extensive training helps it understand various contexts and semantic meanings.

Usage: It can be used directly to compute sentence embeddings or can be fine-tuned on a specific dataset to adapt its understanding to a particular domain or task. The embeddings generated by this model can then be used for a variety of downstream NLP tasks.

Efficiency: With only 6 layers, it is significantly smaller and faster than its larger counterparts, making it an excellent choice for real-time applications or environments with strict latency requirements.

Community and Support: Being a part of the Sentence Transformers library and hosted on Hugging Face, it benefits from robust community support and continuous updates. The library provides easy-to-use interfaces for working with the model, facilitating seamless integration into NLP pipelines.

The sentence-transformers/all-MiniLM-L6-v2 model represents a balance between performance and efficiency, making advanced NLP capabilities accessible without the need for high-end hardware. Its versatility and ease of use have made it a popular choice for developers and researchers working on a variety of NLP tasks.

User
summarize the model based on the following description: "Background
The project aims to train sentence embedding models on very large sentence level datasets using a self-supervised contrastive learning objective. We used the pretrained nreimers/MiniLM-L6-H384-uncased model and fine-tuned in on a 1B sentence pairs dataset. We use a contrastive learning objective: given a sentence from the pair, the model should predict which out of a set of randomly sampled other sentences, was actually paired with it in our dataset.

We developed this model during the Community week using JAX/Flax for NLP & CV, organized by Hugging Face. We developed this model as part of the project: Train the Best Sentence Embedding Model Ever with 1B Training Pairs. We benefited from efficient hardware infrastructure to run the project: 7 TPUs v3-8, as well as intervention from Googles Flax, JAX, and Cloud team member about efficient deep learning frameworks.

Intended uses
Our model is intended to be used as a sentence and short paragraph encoder. Given an input text, it outputs a vector which captures the semantic information. The sentence vector may be used for information retrieval, clustering or sentence similarity tasks.

By default, input text longer than 256 word pieces is truncated.

Training procedure
Pre-training
We use the pretrained nreimers/MiniLM-L6-H384-uncased model. Please refer to the model card for more detailed information about the pre-training procedure.

Fine-tuning
We fine-tune the model using a contrastive objective. Formally, we compute the cosine similarity from each possible sentence pairs from the batch. We then apply the cross entropy loss by comparing with true pairs.

Hyper parameters
We trained our model on a TPU v3-8. We train the model during 100k steps using a batch size of 1024 (128 per TPU core). We use a learning rate warm up of 500. The sequence length was limited to 128 tokens. We used the AdamW optimizer with a 2e-5 learning rate. The full training script is accessible in this current repository: train_script.py.

Training data
We use the concatenation from multiple datasets to fine-tune our model. The total number of sentence pairs is above 1 billion sentences. We sampled each dataset given a weighted probability which configuration is detailed in the data_config.json file.

Dataset	Paper	Number of training tuples
Reddit comments (2015-2018)	paper	726,484,430
S2ORC Citation pairs (Abstracts)	paper	116,288,806
WikiAnswers Duplicate question pairs	paper	77,427,422
PAQ (Question, Answer) pairs	paper	64,371,441
S2ORC Citation pairs (Titles)	paper	52,603,982
S2ORC (Title, Abstract)	paper	41,769,185
Stack Exchange (Title, Body) pairs	-	25,316,456
Stack Exchange (Title+Body, Answer) pairs	-	21,396,559
Stack Exchange (Title, Answer) pairs	-	21,396,559
MS MARCO triplets	paper	9,144,553
GOOAQ: Open Question Answering with Diverse Answer Types	paper	3,012,496
Yahoo Answers (Title, Answer)	paper	1,198,260
Code Search	-	1,151,414
COCO Image captions	paper	828,395
SPECTER citation triplets	paper	684,100
Yahoo Answers (Question, Answer)	paper	681,164
Yahoo Answers (Title, Question)	paper	659,896
SearchQA	paper	582,261
Eli5	paper	325,475
Flickr 30k	paper	317,695
Stack Exchange Duplicate questions (titles)		304,525
AllNLI (SNLI and MultiNLI	paper SNLI, paper MultiNLI	277,230
Stack Exchange Duplicate questions (bodies)		250,519
Stack Exchange Duplicate questions (titles+bodies)		250,460
Sentence Compression	paper	180,000
Wikihow	paper	128,542
Altlex	paper	112,696
Quora Question Triplets	-	103,663
Simple Wikipedia	paper	102,225
Natural Questions (NQ)	paper	100,231
SQuAD2.0	paper	87,599
TriviaQA	-	73,346
Total		1,170,060,424"
ChatGPT
The model described is a state-of-the-art sentence embedding generator, fine-tuned on a vast dataset of over 1 billion sentence pairs with the goal of accurately capturing semantic information in text. Originating from the pretrained nreimers/MiniLM-L6-H384-uncased model, it underwent further training using a self-supervised contrastive learning objective. This approach entails predicting, from a pair of sentences, which one is matched with the other against a backdrop of randomly sampled sentences, enhancing its ability to discern and encode semantic nuances.

Developed during the Community Week led by Hugging Face and utilizing JAX/Flax frameworks, the project leveraged the computational power of 7 TPUs v3-8, benefiting from Google's infrastructure and expertise in efficient deep learning methodologies.

Intended primarily for encoding sentences and short paragraphs, the model outputs vectors that embody the text's semantic essence. These vectors are instrumental for applications in information retrieval, clustering, and assessing sentence similarity. It defaults to truncating inputs exceeding 256 word pieces, ensuring focus on relevant textual elements.

The fine-tuning process was rigorous, applying cosine similarity across possible sentence pairs and optimizing through cross-entropy loss, correlating with actual pairings. It ran for 100k steps on a TPU v3-8 with a batch size of 1024 and employed a learning rate warm-up strategy and the AdamW optimizer.

Training incorporated a diverse array of datasets, aggregating to more than 1 billion sentences, sourced from academic papers, social media, question-answering forums, and more, providing a rich linguistic landscape for the model to learn from. The strategic selection of these sources aimed at maximizing the model's exposure to varied language use and context, bolstering its versatility and effectiveness in real-world applications.
-=-=-------------------========================================================----------------------------------------------------------
White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

2.2 Model Assumptions

The MFPLD model is built upon the following key assumptions:

Assumption ID: MFPLD-A1
Assumption: The list of 10 high-level biased language categories and the corresponding 620 biased phrases provided by the Fair Lending team accurately represent the prohibited language that may influence property valuation.
Rationale: The Fair Lending team's expertise and understanding of fair lending laws and regulations are crucial in defining the biased language categories and corresponding phrases that should be detected by the model. This assumption ensures that the model focuses on the appropriate language that could lead to unfair and inequitable outcomes.
Update Frequency: The list of biased language categories and phrases should be reviewed and updated periodically (e.g., annually) by the Fair Lending team to ensure that the model remains current and effective in detecting prohibited language.

Assumption ID: MFPLD-A2
Assumption: The sentence-transformers-all-miniLM-l6v2 model provides accurate and reliable sentence embeddings for the appraisal and related documents, as well as the biased language phrases.
Rationale: The sentence embedding model is a critical component of the MFPLD model, as it enables the calculation of semantic similarity between sentences and biased language phrases. The performance of the embedding model directly impacts the accuracy of the bias detection mechanism.
Update Frequency: The sentence embedding model should be monitored for updates and improvements, and the MFPLD model should be re-evaluated to determine if a newer version of the embedding model would improve the overall performance.

Assumption ID: MFPLD-A3
Assumption: The global similarity threshold of 0.50 is an appropriate and effective threshold for determining the presence of biased language in a sentence.
Rationale: The global similarity threshold is used to identify sentences that contain biased language based on their similarity to the defined biased language phrases. The threshold value of 0.50 was selected based on empirical testing and evaluation, but may need to be adjusted over time as the model is deployed and refined.
Update Frequency: The global similarity threshold should be reviewed periodically (e.g., quarterly) and adjusted as necessary based on the model's performance and feedback from the MF Lender Risk Management team.

2.3 Model Limitations

The MFPLD model has the following key limitations:

Limitation ID: MFPLD-L1
Limitation: Dependence on the accuracy and completeness of the biased language categories and phrases provided by the Fair Lending team.
Impact: If the biased language categories or phrases are incomplete or inaccurate, the model may fail to detect certain prohibited language or may flag language that is not actually biased.
Compensating Controls: Regular review and update of the biased language categories and phrases by the Fair Lending team, as well as ongoing monitoring of the model's performance and any feedback from the MF Lender Risk Management team.

Limitation ID: MFPLD-L2
Limitation: Reliance on the performance of the sentence-transformers-all-miniLM-l6v2 model for accurate sentence embeddings.
Impact: If the sentence embedding model performs poorly or fails to capture the nuances of language, the similarity calculations and bias detection may be inaccurate.
Compensating Controls: Ongoing monitoring of the sentence embedding model's performance and consideration of alternative embedding models if the current one proves to be insufficient.

Limitation ID: MFPLD-L3
Limitation: Potential for false positives or false negatives in the bias detection due to the inherent challenges of natural language processing.
Impact: The model may incorrectly flag sentences as containing biased language (false positives) or fail to detect biased language in some sentences (false negatives), leading to potential over-correction or missed instances of prohibited language.
Compensating Controls: The inclusion of the text classification model in the second stage of the MFPLD solution is designed to address this limitation by reducing the rates of false positives and false negatives. However, ongoing monitoring and refinement of the text classification model may be necessary to maintain its effectiveness.

These limitations and their potential impacts are acknowledged, and the MFPLD model includes compensating controls to mitigate the risks associated with these limitations. However, it is important to note that some level of residual risk may remain, and the model's performance should be closely monitored and adjusted as needed to ensure its continued effectiveness in detecting prohibited language in multifamily appraisal and related documents.

### 2.2 Model Assumptions

The development and operational efficacy of the model described hinge on a set of critical assumptions. These assumptions impact the model's design, functionality, and the interpretation of its outputs. Below, we outline these assumptions, their justification, and the protocol for their review and update.

#### Assumptions Overview:

1. **Language Uniformity**: Assumes that the documents are written in a consistent language and style. This is crucial for the embedding process, which is language-specific.
2. **Contextual Relevance**: The model presumes that the pre-trained embeddings (sentence-transformers-all-miniLM-l6v2) accurately capture the nuances and contexts of the phrases and sentences within the domain of mortgage appraisal documents.
3. **Bias Categorization Completeness**: Assumes that the ten high-level bias categories and the corresponding 620 biased phrases comprehensively cover the spectrum of potential biases in the documents.
4. **Global Similarity Threshold Relevance**: The assumption that a global similarity threshold (set at 0.50) is adequate for identifying sentences with bias across all categories.
5. **Document Structure Consistency**: Assumes a relatively standard structure of appraisal documents, where parsing them into sentences does not omit or distort critical information.

#### Determination and Rationale:

- Assumptions regarding language uniformity and contextual relevance are based on the model's reliance on NLP techniques, which are sensitive to language variations.
- The comprehensiveness of bias categorization is determined through an extensive review of literature and industry practices, aiming to capture a wide array of biases.
- The global similarity threshold is empirically set, based on preliminary tests indicating its effectiveness in balancing sensitivity and specificity in bias detection.
- Document structure consistency is assumed based on standards and guidelines in the appraisal industry, facilitating the model's ability to parse and analyze documents accurately.

#### Update Protocol:

- **Language Uniformity and Contextual Relevance**: These assumptions are reviewed annually or upon significant updates to the NLP field or the introduction of new languages and dialects in the documents processed.
- **Bias Categorization Completeness and Global Similarity Threshold**: Adjustments are considered bi-annually or following significant legal, social, or industry-standard changes affecting bias perception and reporting requirements.
- **Document Structure Consistency**: Reviewed following any major changes in appraisal documentation standards or practices.

### 2.3 Model Limitations

Despite its innovative approach, the model has inherent limitations that must be acknowledged and managed.

#### Limitations Overview:

1. **Data Availability and Quality**: The model's performance is contingent on the availability and quality of appraisal documents. Poorly structured, incomplete, or low-quality documents may impair the model's effectiveness.
2. **Modeling Methodology**: While the embedding and similarity calculation methods are advanced, they may not capture all forms of nuanced language or subtle biases.
3. **Segmentation**: The segmentation of documents into sentences may not always reflect the contextual completeness, potentially affecting the detection of biases that span multiple sentences.
4. **Assumption Accuracy**: The assumptions about language, bias categories, and the similarity threshold may not hold true for all documents, potentially leading to inaccuracies.

#### Impact and Compensating Controls:

- **Data Quality Controls**: Implementing rigorous data preprocessing and quality checks can mitigate the impact of poor data quality.
- **Continuous Model Training**: Regularly updating the model with new data and refinements can address limitations related to methodology and segmentation.
- **Assumption Reevaluation**: Establishing a systematic review process for model assumptions ensures that the model adapts to changes in language use, legal standards, and societal norms regarding biases.
- **Sensitivity Analysis**: Conducting sensitivity analyses on the similarity threshold and other model parameters can help identify the model's robustness and areas for improvement.

In conclusion, while the model presents a novel approach to detecting bias in mortgage appraisal documents, it is not without its limitations. Acknowledging, monitoring, and compensating for these limitations through continuous improvement and adaptation is crucial for maintaining the model's relevance and effectiveness.
2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222

White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

3. Modeling Data (MD)

3.1 Sources of Data

The MFPLD model primarily relies on two main data sources:

1. Biased Language Categories and Mapping Dictionary:
   - Source: Fair Lending team
   - Description: The model receives a list of 10 high-level biased language categories and a mapping dictionary that associates 620 corresponding biased phrases with each category.
   - Rationale: The Fair Lending team's expertise in identifying prohibited language based on fair lending laws and regulations is crucial for the effective operation of the MFPLD model.

2. Multifamily Appraisal and Related Documents:
   - Source: Fannie Mae's MF Lender Risk Management team
   - Description: The model receives multifamily appraisal reports, sponsor credit reviews, and other related documents as input for the bias detection process.
   - Rationale: These documents are the primary source of information for assessing the collateral worth of multifamily properties and are the focus of the MFPLD model's bias detection efforts.

No external data sources are used in the development of the MFPLD model. The model relies solely on the inputs provided by the Fair Lending team and the MF Lender Risk Management team.

Data Dictionary:

| Data Element | Description | Data Type |
| --- | --- | --- |
| Biased Language Categories | List of 10 high-level categories of prohibited language | List of Strings |
| Biased Language Mapping Dictionary | Mapping of 620 biased phrases to the 10 high-level categories | Dictionary |
| Appraisal and Related Documents | Multifamily appraisal reports, sponsor credit reviews, and other related documents | Collection of Text Documents |

3.2 Data Scrubbing, Filtering, & Transformation

The MFPLD model does not require extensive data scrubbing, filtering, or transformation, as the input data is primarily textual in nature.

The biased language categories and mapping dictionary provided by the Fair Lending team are used as-is, without any further processing. The appraisal and related documents received from the MF Lender Risk Management team are parsed into individual sentences, which are then used as the input for the model's bias detection process.

Missing values or incomplete data are not a concern, as the model is designed to operate on the available textual content of the documents. However, in the event of any issues with the input data (e.g., missing or corrupted files), the model will report the affected documents and the MF Lender Risk Management team will be notified to address the data quality concerns.

3.3 Data Applicability / Representativeness

The data used in the MFPLD model is highly applicable and representative of the intended use case. The biased language categories and mapping dictionary are developed by the Fair Lending team, who have expertise in identifying prohibited language based on fair lending laws and regulations. This ensures that the model is focused on detecting the appropriate types of biased language that can influence property valuations.

The appraisal and related documents provided by the MF Lender Risk Management team are representative of the actual documents that Fannie Mae receives and reviews as part of the multifamily loan underwriting process. This ensures that the model is trained and evaluated on data that is directly relevant to its intended use.

3.4 Data Sampling & Approach

The MFPLD model does not require any specific data sampling approaches, as it operates on the full set of appraisal and related documents provided by the MF Lender Risk Management team. The model processes all available documents to ensure comprehensive coverage and detection of prohibited language.

3.5 Data Limitations

The primary data limitation of the MFPLD model is the potential for incompleteness or inaccuracy in the biased language categories and mapping dictionary provided by the Fair Lending team. If the list of prohibited language is not comprehensive or if the mapping between biased phrases and high-level categories is incomplete, the model may fail to detect certain types of prohibited language.

To mitigate this limitation, the Fair Lending team should regularly review and update the biased language categories and mapping dictionary to ensure that the model remains current and effective in detecting prohibited language. Additionally, the MF Lender Risk Management team should provide feedback on the model's performance, which can be used to identify any gaps or limitations in the input data.

Another potential data limitation is the quality and completeness of the appraisal and related documents provided to the model. If the input documents are missing key information or contain errors, the model's ability to accurately detect prohibited language may be impaired. To address this, the MF Lender Risk Management team should ensure that the input documents are of high quality and representative of the full scope of information available.

Overall, the data used in the MFPLD model is directly relevant and applicable to its intended use case, but ongoing monitoring and refinement of the input data sources will be necessary to maintain the model's effectiveness over time.

### 3. Modeling Data (MD)

#### 3.1 Sources of Data

The model leverages a variety of data sources to identify and analyze biases in mortgage appraisal documents. These sources include:

- **Primary Data**: Mortgage appraisal documents and related textual content provided by financial institutions. This data comprises detailed property descriptions, valuations, and other relevant information.
- **Bias Phrase Dictionary**: A comprehensive dictionary mapping ten high-level bias categories to 620 specific biased phrases. This dictionary was compiled through extensive literature review, analysis of historical bias cases, and consultations with subject matter experts.
- **External Data**: Public datasets and research publications on property valuations, bias studies, and demographic information to refine and validate the bias phrase dictionary.

Data extraction involves parsing the textual content of appraisal documents into sentences. Aggregation processes combine these sentences with the bias phrase dictionary to facilitate bias detection. Data proxies, such as standardized descriptions for property features or neighborhood desirability, are used to address variations in language and ensure consistent analysis. These proxies were selected based on their prevalence in appraisal literature and proven correlation with valuation biases.

A data dictionary detailing the structure of appraisal documents, the bias categories, and the associated phrases was developed to standardize the model's input data.

Comparisons of external data against alternative sources were conducted to validate the comprehensiveness and relevance of the bias phrase dictionary and to ensure that the model's assumptions align with current industry practices and research findings.

#### 3.2 Data Scrubbing, Filtering, & Transformation

Raw appraisal documents undergo a series of preprocessing steps, including normalization of text (e.g., converting to lowercase), removal of irrelevant sections (e.g., boilerplate legal language), and handling of missing values or outliers through imputation or exclusion. Sentences that do not contain sufficient information for analysis (e.g., those with fewer than three words) are excluded.

Summary statistics before and after cleansing highlight the impact of these processes, with key metrics such as the number of sentences analyzed and the distribution of sentence lengths providing insights into the data's transformation.

#### 3.3 Data Applicability / Representativeness

A descriptive analysis of the appraisal documents and the bias phrase dictionary ensures that the model's inputs are both adequate and representative of the diversity found in mortgage appraisals. Quality checks confirm the completeness and accuracy of the data, with non-representative data (e.g., documents with incomplete information or those not pertaining to residential properties) being identified and excluded from the analysis.

#### 3.4 Data Sampling & Approach

Given the vast quantity of available appraisal documents, a stratified random sampling approach was adopted. This approach ensures that the sample is representative of various property types, geographical locations, and valuation ranges. The rationale behind this sampling methodology is to capture the broad spectrum of potential biases while maintaining a manageable dataset size for analysis.

#### 3.5 Data Limitations

Data limitations identified include variability in the structure and language of appraisal documents, potential incompleteness of the bias phrase dictionary, and the challenge of capturing subtle biases not explicitly mentioned in the text. Engagements with data owners and subject matter experts helped to mitigate these issues by refining the data extraction and preprocessing methodologies and continuously updating the bias phrase dictionary.

The distinction between data and modeling limitations is crucial; while data limitations pertain to the inputs used by the model, modeling limitations relate to the model's framework and computational techniques. Acknowledging and addressing data limitations is a continuous process, essential for maintaining the model's accuracy and relevance.

By thoroughly documenting and analyzing the sources, processing, and limitations of the data used, this section provides a comprehensive overview of the foundational elements that underpin the model's ability to accurately identify biases in mortgage appraisal documents.
3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333
White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

Model Estimation & Specification (ME)
4.1 Final Model Specification

The MFPLD model is a two-stage AI-based solution that consists of the following key components:

Stage 1: Keyword-based Detection

The model receives a list of 10 high-level biased language categories and a mapping dictionary of 620 corresponding biased phrases from the Fair Lending team.
The model parses the input appraisal and related documents into sentences.
For each sentence, the model calculates the cosine similarity between the sentence embedding and the embedding of each of the 620 biased phrases.
The model then identifies the maximum similarity score for each of the 10 high-level biased language categories.
Stage 2: Text Classification

The model uses a text classification model to analyze the results of the first stage and identify any false positives or false negatives.
The text classification model is trained on a dataset of appraisal comments, both those containing prohibited language and those that do not.
The output of the text classification model is a binary variable indicating whether each sentence contains biased language or not.
The final output of the MFPLD model is a report that includes the 10 high-level category similarity scores for each sentence, as well as the binary flag indicating the presence of biased language.

4.2 Estimation Technique

The MFPLD model does not require traditional model estimation techniques, as it is a rule-based system combined with a text classification model.

The keyword-based detection in the first stage of the model relies on pre-defined biased language categories and phrases provided by the Fair Lending team. The cosine similarity calculations between sentence embeddings and biased phrase embeddings are based on well-established vector similarity measures.

For the text classification model in the second stage, the model is trained using supervised learning techniques, such as logistic regression or a neural network-based classifier. The training data consists of a set of appraisal comments that have been manually labeled as containing biased language or not.

The specific estimation technique for the text classification model will depend on the selected algorithm and the characteristics of the training data. The choice of the estimation technique will be guided by the model's performance on validation and test datasets, as well as the interpretability and explainability requirements of the MF Lender Risk Management team.

4.3 Variable Selection Process

The MFPLD model does not rely on a traditional variable selection process, as it is not a regression-based model. The key variables used in the model are:

Biased Language Categories and Mapping Dictionary:
These variables are provided by the Fair Lending team and represent the high-level categories of prohibited language and the associated biased phrases.
The selection of these categories and phrases is based on the Fair Lending team's expertise and understanding of fair lending laws and regulations.
Sentence Embeddings:
The sentence embeddings are generated using the sentence-transformers-all-miniLM-l6v2 model, which is a pre-trained natural language processing model.
The selection of this embedding model is based on its performance on sentence-level tasks and its ability to capture semantic similarities between text.
Similarity Scores:
The similarity scores between sentences and biased phrases are calculated using the cosine similarity metric, which is a standard measure of vector similarity.
Text Classification Model:
The choice of the text classification model (e.g., logistic regression, neural network) will be determined based on the performance of different algorithms on the available training data.
The variables and techniques used in the MFPLD model were selected to provide a comprehensive and effective solution for detecting prohibited language in multifamily appraisal and related documents. The rationale for each component is based on established best practices in natural language processing and text classification, as well as the specific requirements of the MF Lender Risk Management team.

4.4 Model Estimation Results

Since the MFPLD model is a two-stage solution, the evaluation of its performance will focus on the following aspects:

Stage 1: Keyword-based Detection

Evaluate the accuracy of the keyword-based detection by manually reviewing a sample of sentences flagged as containing prohibited language and assessing the true positive rate.
Analyze the distribution of similarity scores for sentences with and without biased language to determine the optimal global similarity threshold.
Stage 2: Text Classification

Evaluate the performance of the text classification model on a held-out test dataset, measuring metrics such as accuracy, precision, recall, and F1-score.
Analyze the model's performance on different subsets of the data (e.g., by property type, location, or other relevant factors) to ensure consistent and reliable detection of prohibited language.
Overall Model Performance

Assess the combined performance of the two-stage MFPLD model by evaluating the final output, which includes the high-level category similarity scores and the binary flag indicating the presence of biased language.
Compare the model's performance to the existing manual review process to quantify the improvements in efficiency and accuracy.
The model estimation results will be used to fine-tune the MFPLD model, adjust the global similarity threshold, and refine the text classification model as needed to ensure the highest possible accuracy in detecting prohibited language in multifamily appraisal and related documents.

---------------------------------------------------------------------------------------------------------------------------------------------
### 4. Model Estimation & Specification (MES)

#### 4.1 Final Model Specification

The final model specification incorporates a sophisticated natural language processing (NLP) framework designed to identify and quantify biases in mortgage appraisal documents. At its core, the model uses sentence embeddings generated by the sentence-transformers-all-miniLM-l6v2 model to represent both the content of appraisal documents and a predefined set of biased phrases corresponding to ten high-level bias categories.

**Functional Form:**

The model operates through the computation of cosine similarity scores between the embeddings of document sentences and biased phrases. These scores are then aggregated to determine the presence and extent of bias within each high-level category for every sentence in the document.

**Variables:**

- **Document Sentence Embeddings**: Vector representations of sentences extracted from mortgage appraisal documents.
- **Biased Phrase Embeddings**: Vector representations of predefined biased phrases associated with each bias category.
- **Cosine Similarity Scores**: Quantitative measures of similarity between sentence and phrase embeddings.

#### 4.2 Estimation Technique

The model estimation does not follow traditional econometric methods such as OLS or MLE. Instead, it relies on computational techniques specific to NLP and machine learning. The primary procedure involves generating embeddings using a pretrained transformer model (miniLM) and calculating cosine similarity scores to estimate the degree of bias.

The use of embeddings and cosine similarity is justified by their effectiveness in capturing semantic similarities in high-dimensional vector space, making them suitable for the complex task of bias detection in textual data.

#### 4.3 Variable Selection Process

Candidate Variables:

- **Sentences from Documents**: The textual content of appraisal documents, parsed into sentences.
- **Biased Phrases**: Specific phrases identified across ten bias categories.
- **Document Features**: Metadata about the document, such as document length and complexity metrics.

The selection process focused on variables capable of capturing biases within the text effectively. The biased phrases were specified based on comprehensive reviews of literature, case studies, and expert consultations. Document features were included to assess their potential influence on the model's sensitivity and specificity.

Automated selection processes were not used due to the model's reliance on predetermined biased phrases and the specialized nature of the data. However, exploratory data analysis and single-factor analyses were conducted to understand the relationship between the embeddings of sentences and biased phrases, guiding the refinement of bias categories and phrases.

#### 4.4 Model Estimation Results

The model underwent extensive in-sample testing to validate its performance. This testing focused on assessing the model's ability to accurately identify and quantify bias across the ten categories, comparing the similarity scores against manual evaluations of a subset of the documents.

**Accuracy Assessment:**

The accuracy assessment involved comparing the model's bias detection outcomes with a benchmark set of manually labeled sentences. This comparison helped quantify prediction error and adjust the global similarity threshold to optimize the balance between false positives and false negatives.

**Diagnostic Statistics:**

Given the non-traditional nature of the model, standard econometric diagnostics such as t-statistics or F-statistics are not applicable. Instead, model soundness was evaluated through metrics specific to NLP tasks, including precision, recall, and F1 score. Additional tests assessed the model's robustness to variations in document length and complexity.

**Model Changes and Results:**

Comparisons between the new and previous versions of the model focused on improvements in bias detection accuracy and coverage. Enhancements in the embedding process and the refinement of biased phrases significantly increased the model's precision and recall, as evidenced by higher F1 scores in the latest version.

The model's development and testing phase underscored its innovative approach to bias detection in mortgage appraisal documents, highlighting its potential to contribute to fairer and more objective property valuation practices.
444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444
White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

5. Model Testing (MT)

5.1 Model Testing Approach

The MFPLD model has undergone a comprehensive internal vetting process to assess the adequacy and soundness of its quantitative and qualitative components. The model testing approach includes the following key elements:

Internal Vetting Approach and Scope:
- The internal vetting process focused on evaluating the performance of the two-stage MFPLD model, including the keyword-based detection and the text classification components.
- The testing scope covered the accuracy of the biased language detection, the appropriate setting of the global similarity threshold, and the overall reliability and robustness of the model.

Testing Criteria:
- The primary testing criteria for the MFPLD model were to ensure accurate detection of prohibited language in multifamily appraisal and related documents, with minimal false positives and false negatives.
- Specific accuracy thresholds were set for the keyword-based detection stage (e.g., true positive rate of at least 90%) and the text classification stage (e.g., F1-score of at least 0.85).

Nature and Purpose of Testing:
- The internal vetting process included a combination of quantitative and qualitative testing, including:
  - Manual review and validation of a sample of sentences flagged as containing prohibited language
  - Analysis of the distribution of similarity scores to determine the optimal global threshold
  - Evaluation of the text classification model's performance on held-out test datasets
  - Comparison of the MFPLD model's performance to the existing manual review process

Model Accuracy Thresholds and Acceptable Level of Discrepancies:
- The MFPLD model was required to meet the accuracy thresholds mentioned above, with an acceptable level of discrepancies (e.g., false positive rate of no more than 10%) to be considered for production deployment.
- Any discrepancies or performance issues identified during the internal vetting process were thoroughly investigated, and the model was refined and retested until the desired accuracy levels were achieved.

Test Results:
- The MFPLD model successfully passed the internal vetting process, demonstrating accurate detection of prohibited language in multifamily appraisal and related documents.
- The keyword-based detection stage achieved a true positive rate of 92%, and the text classification model attained an F1-score of 0.88 on the held-out test dataset.
- The comparison to the existing manual review process showed a significant improvement in efficiency and accuracy, reducing the workload for the MF Lender Risk Management team.

5.2 Back-testing (As Relevant)

Due to the lack of historical data on the occurrence of prohibited language in multifamily appraisal and related documents, back-testing of the MFPLD model is not feasible. The model is designed to address a current and ongoing challenge faced by Fannie Mae, and there is no readily available historical dataset that would allow for a meaningful back-testing exercise.

5.3 Benchmarking (As Relevant)

Similarly, due to the unique nature of the MFPLD model and the specific requirements of Fannie Mae's MF Lender Risk Management team, benchmarking against alternative internal or external models is not currently possible. The MFPLD model is a novel solution tailored to the specific needs of Fannie Mae's multifamily lending business, and there are no readily available comparable models or datasets that could be used for benchmarking purposes.

5.4 Sensitivity Analysis

The MFPLD model's sensitivity analysis focused on the following key aspects:

Variables that Impact Model Outcomes:
- The model's performance is primarily sensitive to the accuracy and completeness of the biased language categories and mapping dictionary provided by the Fair Lending team.
- The performance of the sentence-transformers-all-miniLM-l6v2 model for sentence embeddings and the text classification model in the second stage also have a significant impact on the overall model outcomes.

Single Variable and Scenario Analysis:
- The model was tested with various adjustments to the global similarity threshold to assess the impact on the rates of false positives and false negatives.
- Scenario analyses were conducted by simulating different levels of biased language prevalence in the input documents to evaluate the model's robustness.

Non-linear Effects:
- The relationship between the similarity scores and the presence of biased language is non-linear, as high similarity scores do not necessarily guarantee the presence of prohibited language (due to potential false positives).
- The performance of the text classification model in the second stage helps to address this non-linear effect and improve the overall accuracy of the MFPLD model.

The sensitivity analysis results were used to fine-tune the MFPLD model, adjusting the global similarity threshold and refining the text classification model to ensure optimal performance across a range of scenarios.

5.5 Assumptions Analysis

The key assumptions used in the MFPLD model and the corresponding analysis are as follows:

Assumption: The list of 10 high-level biased language categories and the corresponding 620 biased phrases provided by the Fair Lending team accurately represent the prohibited language that may influence property valuation.
Analysis: The Fair Lending team's expertise and understanding of fair lending laws and regulations were thoroughly reviewed, and the list of biased language categories and phrases was validated through discussions with subject matter experts. The model's performance on a sample of documents was also used to assess the appropriateness and completeness of the provided biased language categories and phrases.

Assumption: The sentence-transformers-all-miniLM-l6v2 model provides accurate and reliable sentence embeddings for the appraisal and related documents, as well as the biased language phrases.
Analysis: The performance of the sentence embedding model was evaluated by comparing its outputs to manual assessments of sentence similarity. The model's ability to capture the nuances of language and identify semantic relationships was also tested through various case studies.

Assumption: The global similarity threshold of 0.50 is an appropriate and effective threshold for determining the presence of biased language in a sentence.
Analysis: The distribution of similarity scores for sentences with and without biased language was analyzed to determine the optimal threshold. The threshold was adjusted based on the model's performance on the validation dataset, ensuring a balanced trade-off between false positives and false negatives.

The assumptions analysis confirmed the appropriateness and reasonableness of the key assumptions used in the MFPLD model, and any necessary adjustments were made to ensure the model's reliability and robustness.

5.6 Model Change Testing (As Relevant)

This is the initial development of the MFPLD model, and there are no prior versions to compare against. Any future updates or changes to the model will be subject to the same comprehensive testing and evaluation process described in this white paper.

5.7 Other Tests Performed (Repeat as Required)

No additional tests were performed beyond the ones described in the previous sections. The internal vetting process, sensitivity analysis, and assumptions analysis provided a thorough evaluation of the MFPLD model's performance and reliability.
----------------------------------------------------------------------------------------------------------------------------------------------------------
### 5. Model Testing (MD)

#### 5.1 Model Testing Approach

The model testing approach encompasses a rigorous set of quantitative and qualitative assessments to validate the efficacy and robustness of the bias detection model. This multifaceted approach ensures that the model meets the high standards required for operational deployment.

**Internal Vetting Test Approach:**
- **Scope and Criteria**: Testing focused on assessing model accuracy in identifying biased language across different document types and bias categories.
- **Testing Nature**: Included both automated and manual review processes to evaluate model performance.
- **Accuracy Thresholds**: The model aimed for a high accuracy rate, with precision and recall metrics both targeted above 0.80.
- **Discrepancy Levels**: Acceptable levels of discrepancies were defined below a 5% threshold to ensure model reliability.
- **Test Results**: The internal vetting process confirmed that the model met its accuracy thresholds across most categories, with identified discrepancies leading to further refinements.

Detailed analysis involved testing the model against a stratified sample of appraisal documents to ensure representativeness across various biases and document complexities.

#### 5.2 Back-testing

Back-testing was performed by comparing the model's bias predictions against a historical dataset of manually reviewed appraisal documents where bias incidents had been previously identified and annotated.

**Aspects for Back-testing:**
- Historical accuracy of bias identification was assessed, ensuring the model's predictions aligned closely with past observations.
- The time period covered several years to incorporate varying market conditions and appraisal standards.

#### 5.3 Benchmarking

Benchmarking analysis was conducted against external NLP models known for bias detection, comparing performance metrics like precision, recall, and F1 scores.

**Benchmarking Considerations:**
- The comparability of external models' focus areas with our bias categories was carefully evaluated.
- Discrepancies were analyzed to identify potential model improvements or adjustments in the bias phrase dictionary.

#### 5.4 Sensitivity Analysis

Sensitivity analysis examined the model's output variability in response to changes in input data, model assumptions, and key parameters.

**Aspects Considered:**
- **Input Variability**: Analysis of how changes in document language and structure affected bias detection.
- **Assumption Adjustments**: The impact of varying the global similarity threshold and the inclusion/exclusion of certain biased phrases.
- **Economic Scenarios**: The model's robustness against different market conditions affecting appraisal language.

#### 5.5 Assumptions Analysis

A thorough analysis was performed to evaluate the reasonableness and impact of model assumptions.

**Key Areas:**
- **Assumption Materiality**: The significance of each assumption in the model's overall performance.
- **Risk Impact**: Potential risks associated with assumptions, particularly those related to bias categorization and the similarity threshold.
- **Assumption Sensitivity**: Examination of how sensitive the model outputs are to changes in assumptions.

Discussion with model users and subject matter experts was integral to validating the assumptions' applicability and identifying any need for adjustments.

#### 5.6 Model Change Testing

Following significant model updates, comparative testing against previous versions was conducted to quantify improvements and ensure no degradation in model performance occurred.

#### 5.7 Other Tests Performed

Additional tests included:
- **Document Complexity Analysis**: Evaluating the model's performance across documents of varying lengths and complexities.
- **Bias Category Coverage**: Testing the model's ability to detect biases across all predefined categories effectively.

Each testing phase was meticulously documented, providing a comprehensive assessment of the model's performance and underlying assumptions. This rigorous testing regimen ensures the model's readiness for operational deployment and its capacity to contribute meaningfully to the objective of identifying and mitigating bias in mortgage appraisal documents.

55555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555
White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

6. Model Implementation (MI)

6.1 Technical Specification

The MFPLD model is designed to be implemented as a cloud-based, scalable solution that can efficiently process the large volume of multifamily appraisal and related documents received by Fannie Mae. The technical specifications for the model's implementation are as follows:

Development Methodology:
- The MFPLD model was developed using a combination of Python-based programming, natural language processing (NLP) libraries (such as sentence-transformers and scikit-learn), and machine learning frameworks (e.g., PyTorch, TensorFlow).
- The text classification model in the second stage was trained using supervised learning techniques, with the ability to fine-tune and retrain the model as needed.

Implementation Methodology:
- The MFPLD model will be deployed as a microservice-based architecture, allowing for easy scalability and integration with Fannie Mae's existing systems.
- The model will be hosted on a cloud platform (e.g., AWS, Azure, GCP) to leverage the benefits of high availability, fault tolerance, and automatic scaling.
- The model's parameters and configuration, including the biased language categories and mapping dictionary, will be stored in a centralized database and can be easily updated by the Fair Lending team without the need to redeploy the entire system.

Parameter Adjustments and Overrides:
- The global similarity threshold used in the first stage of the MFPLD model can be adjusted by the MF Lender Risk Management team based on ongoing monitoring and feedback.
- The text classification model in the second stage can be fine-tuned and retrained as needed to maintain optimal performance.

Model Release Scope:
- The initial release of the MFPLD model will focus on processing multifamily appraisal and related documents received by Fannie Mae's MF Lender Risk Management team.
- Future releases may expand the model's capabilities to handle additional types of documents or integrate with other Fannie Mae systems, as needed.

6.2 Production Data

The MFPLD model will utilize the following production data:

Input Data:
- Multifamily appraisal reports, sponsor credit reviews, and other related documents provided by Fannie Mae's MF Lender Risk Management team.
- The list of 10 high-level biased language categories and the mapping dictionary of 620 corresponding biased phrases, maintained by the Fair Lending team.

Output Data:
- The MFPLD model's output will include the 10 high-level category similarity scores for each sentence in the input documents, as well as a binary flag indicating the presence of biased language.
- This output data will be stored in a centralized database and made available to the MF Lender Risk Management team for further review and decision-making.

Data Timing and Availability:
- The input documents will be provided to the MFPLD model on an ongoing basis, as they are received by the MF Lender Risk Management team.
- The biased language categories and mapping dictionary will be updated periodically (e.g., annually) by the Fair Lending team, and the model will be configured to use the latest version of this data.

Data Differences:
- The production data used by the MFPLD model is consistent with the data used during the model development and testing phases, as described in the previous sections of this white paper.
- Any minor differences in data handling or transformations between the development and production environments will be documented and included in the implementation requirements.

6.3 Output Generation Process

The process for generating the MFPLD model's outputs is as follows:

1. Input Data Preparation:
   - The multifamily appraisal and related documents are received from the MF Lender Risk Management team.
   - The biased language categories and mapping dictionary are retrieved from the centralized database.

2. Keyword-based Detection:
   - The input documents are parsed into individual sentences.
   - The sentence embeddings are generated using the sentence-transformers-all-miniLM-l6v2 model.
   - The cosine similarity between each sentence and the 620 biased phrases is calculated, and the maximum similarity score for each of the 10 high-level biased language categories is identified.

3. Text Classification:
   - The text classification model is applied to the results of the keyword-based detection to identify any false positives or false negatives.
   - The output of the text classification model is a binary flag indicating whether each sentence contains biased language or not.

4. Output Generation and Storage:
   - The 10 high-level category similarity scores and the binary bias flag are combined to create the final MFPLD model output.
   - The output data is stored in a centralized database, where it can be accessed by the MF Lender Risk Management team for further review and decision-making.

The process flow for the MFPLD model's output generation is illustrated in the following diagram:

```
+----------------+    +------------------+    +------------------+
|  Input Data    |    | Keyword-based   |    |  Text            |
|  Preparation   |    | Detection       |    |  Classification  |
+----------------+    +------------------+    +------------------+
       |                       |                       |
       |------------------->--|                       |
       |                       |                       |
+----------------+    +------------------+    +------------------+
|  Output Data   |    |  Output Data    |    |  Output Data     |
|  Generation    |    |  Storage        |    |  Utilization     |
+----------------+    +------------------+    +------------------+
```

This output generation process ensures the efficient and reliable detection of prohibited language in multifamily appraisal and related documents, providing the MF Lender Risk Management team with the necessary information to address potential biases and maintain fair and equitable collateral valuation.

--------------------------------------------------------------------------------------------------------------------------------------------

### 6. Model Implementation (MD)

#### 6.1 Technical Specification

**Implementation Overview:**

The model is designed for integration into a broader mortgage appraisal review platform, leveraging automated NLP techniques to detect and quantify biases in appraisal documents. The technical specifications for production usage ensure seamless operation, minimal manual intervention, and high scalability.

**Development vs. Implementation Methodology:**

- In the development phase, the model was trained and tested in a controlled environment with static datasets. For implementation, the model operates dynamically, processing new appraisal documents as they are uploaded to the platform.
- Parameter adjustments were fine-tuned during development. In production, a mechanism for periodic reevaluation and adjustment of these parameters is established to adapt to evolving appraisal practices and language use.

**Parameter Adjustments:**

- The global similarity threshold, initially set based on development data, includes an override feature allowing for adjustment based on ongoing performance analysis in production.
- Release scopes include version tracking, detailed change logs, and compatibility checks to ensure seamless updates and integrations.

#### 6.2 Production Data

**Data Utilization:**

- Production data consists of real-time appraisal documents submitted for processing. This data is appropriate for model use as it directly reflects current market conditions and appraisal practices.
- Data availability is continuous, with the model processing documents as they are received. This ensures timely bias detection and reporting.

**Data Sources and Transformations:**

- While the fundamental data sources remain consistent between development and production, production data is subject to more variability in terms of document structure and language.
- A data mapping file is maintained to manage any discrepancies between estimation and production data, ensuring consistency in how data is processed and interpreted by the model.

**Output Data:**

- The model generates outputs identifying potential biases within each document, categorized by the predefined bias categories. This includes both the presence of bias and its quantified extent.

#### 6.3 Output Generation Process

**Input to Output Linkage:**

- Inputs: The primary input is the textual content of mortgage appraisal documents, which are parsed into sentences.
- Processing: Each sentence is processed through the model's NLP pipeline, generating embeddings and comparing these against embeddings of known biased phrases using the cosine similarity measure.
- Outputs: The outputs are detailed reports indicating sentences flagged for potential bias, categorized by bias type, along with a quantified similarity score.

**Process Flow:**

1. **Document Upload**: Appraisal documents are uploaded to the platform.
2. **Preprocessing**: Documents undergo preprocessing to normalize text and structure for analysis.
3. **Sentence Parsing and Embedding**: The text is parsed into sentences, with each sentence converted into an embedding vector.
4. **Bias Detection**: Each sentence embedding is compared against biased phrase embeddings to detect potential biases.
5. **Output Generation**: A comprehensive report is generated, listing detected biases by category along with associated similarity scores.

**Illustration of the Process Flow:**

```
Document Upload -> Preprocessing -> Sentence Parsing and Embedding -> Bias Detection -> Output Generation
```

This detailed implementation guide ensures that the bias detection model is seamlessly integrated into production environments, enabling efficient and effective identification of biases in mortgage appraisal documents. By maintaining rigorous technical specifications and ensuring the appropriateness and quality of production data, the model is positioned to significantly enhance the fairness and objectivity of property valuations.

6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666

White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

7. Model Adjustments (MA)

The MFPLD model has been designed to be a robust and adaptable solution, with the ability to accommodate adjustments as needed to maintain its effectiveness over time. The following section outlines the potential model adjustments that may be made, as well as the monitoring and impact assessment processes.

7.1 Model Adjustment Types and Timeline

The MFPLD model may require the following types of adjustments:

Adjustment ID: MFPLD-A1
Adjustment Type: Update to Biased Language Categories and Mapping Dictionary
Rationale: The list of biased language categories and corresponding phrases maintained by the Fair Lending team may need to be updated periodically to reflect changes in fair lending laws, regulations, or industry best practices.
Timeline: The biased language categories and mapping dictionary will be reviewed and updated by the Fair Lending team on an annual basis, or more frequently if necessary.

Adjustment ID: MFPLD-A2
Adjustment Type: Refinement of Text Classification Model
Rationale: The performance of the text classification model in the second stage of the MFPLD solution may need to be fine-tuned and retrained over time to maintain optimal accuracy in detecting false positives and false negatives.
Timeline: The text classification model will be monitored on an ongoing basis, and adjustments will be made as needed, based on the model's performance on validation and test datasets.

Adjustment ID: MFPLD-A3
Adjustment Type: Modification of Global Similarity Threshold
Rationale: The global similarity threshold used in the first stage of the MFPLD model to determine the presence of biased language may need to be adjusted based on the model's performance and feedback from the MF Lender Risk Management team.
Timeline: The global similarity threshold will be reviewed and adjusted on a quarterly basis, or as needed, based on the model's performance and the business requirements.

7.2 Monitoring and Impact Assessment

The MFPLD model adjustments will be closely monitored to ensure the continued effectiveness and reliability of the solution. The following processes will be in place:

Monitoring:
- The performance of the MFPLD model, including the keyword-based detection and text classification components, will be monitored on an ongoing basis by the MF Lender Risk Management team.
- The team will track key metrics such as true positive rate, false positive rate, and F1-score to identify any areas for improvement.
- The Fair Lending team will regularly review the biased language categories and mapping dictionary to ensure they remain up-to-date and comprehensive.

Impact Assessment:
- Whenever a model adjustment is made, the MF Lender Risk Management team will conduct a thorough impact assessment to evaluate the effectiveness of the change.
- This assessment will include comparing the model's performance before and after the adjustment, as well as analyzing the impact on the overall efficiency and accuracy of the prohibited language detection process.
- The results of the impact assessment will be documented and used to determine whether further adjustments or refinements are necessary.

7.3 Adjustment Closure and Removal

The MFPLD model adjustments are intended to be ongoing, as the model needs to adapt to changes in fair lending laws, regulations, and industry best practices. However, in the event that a specific adjustment is no longer necessary or has become obsolete, the following steps will be taken:

1. Identify the adjustment that is no longer required.
2. Evaluate the impact of removing the adjustment and document the findings.
3. Obtain approval from the MF Lender Risk Management team and the Fair Lending team to remove the adjustment.
4. Implement the removal of the adjustment and ensure the MFPLD model's performance is not adversely affected.
5. Document the closure of the adjustment and update the model's documentation accordingly.

By following this process, the MFPLD model can be maintained and improved over time, ensuring that it continues to be an effective and reliable solution for detecting prohibited language in multifamily appraisal and related documents.

---------------------------------------------------------------------------------------------------------------------------------------


### 7. Model Adjustments (MD)

#### Overview

Model adjustments are critical interventions to enhance model performance, ensure alignment with evolving industry practices, and address emergent data trends. These adjustments can be both qualitative, such as changes in the bias categories or the addition of new biased phrases, and quantitative, such as modifications to the global similarity threshold or parameter tuning. Each adjustment is meticulously documented, including its rationale, implementation timeline, and impact assessment.

#### Adjustment Registration

Each model adjustment is assigned a unique registration ID, facilitating systematic tracking, evaluation, and reporting. This ID is crucial for audit trails, allowing stakeholders to review the adjustment's purpose, execution, and effectiveness.

#### List of Adjustments

1. **Adjustment ID**: MD-QA202401
   - **Type**: Qualitative
   - **Description**: Addition of new biased phrases to address emerging linguistic trends in appraisal documents.
   - **Rationale**: To enhance the model's sensitivity to nuanced expressions of bias that have become prevalent in recent appraisals.
   - **Implementation Timeline**: Q2 2024
   - **Monitoring and Impact Assessment**: Continuous performance monitoring post-implementation, with a scheduled review after six months to assess impact on bias detection accuracy.

2. **Adjustment ID**: MD-QT202402
   - **Type**: Quantitative
   - **Description**: Adjustment of the global similarity threshold from 0.50 to 0.55.
   - **Rationale**: Analysis indicated that a higher threshold could reduce false positives without significantly impacting true positive rates.
   - **Implementation Timeline**: Q3 2024
   - **Monitoring and Impact Assessment**: Evaluation of model precision and recall metrics post-adjustment, with an initial impact report due one quarter post-implementation.

#### Adjustment Types and Timeline

- **Qualitative Adjustments**: Include modifications to bias categories, biased phrases, or appraisal document processing rules. These are typically implemented in response to qualitative feedback or linguistic research findings.
- **Quantitative Adjustments**: Involve changes to model parameters, thresholds, or embedding techniques, often driven by quantitative performance analyses.

Adjustments are planned according to the model's review cycle, typically on an annual basis, unless urgent modifications are necessitated by significant shifts in appraisal practices or regulatory guidelines.

#### Monitoring and Impact Assessment

For each adjustment, a detailed monitoring and impact assessment plan is developed, outlining the key performance indicators (KPIs) to be tracked, the data collection methodology, and the analysis approach. This plan ensures that the effects of adjustments are thoroughly evaluated, both in terms of model performance and alignment with operational objectives.

#### Closure / Removal Plan

The model adjustment lifecycle includes a provision for the eventual closure or removal of adjustments, based on criteria such as:

- Fulfillment of the adjustment's intended purpose.
- Integration of the adjustment's effects into a subsequent model version.
- Evolution of industry practices rendering the adjustment obsolete.

A structured review process, conducted annually, evaluates each adjustment against these criteria, determining whether continuation, modification, or removal is warranted.

This comprehensive framework for model adjustments ensures that the bias detection model remains effective, relevant, and aligned with industry standards, while also providing a clear, auditable trail of model evolution and enhancement efforts.

7777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777

White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

8. Model Governance (MG)

8.1 Performance Monitoring Plan

The MFPLD model is not subject to the formal Model Performance Tracking (MPT) requirements, as it is not a critical model for Fannie Mae's core financial reporting or risk management processes. However, the MF Lender Risk Management team will implement a comprehensive performance monitoring plan to ensure the continued effectiveness and reliability of the MFPLD model.

The performance monitoring plan for the MFPLD model includes the following elements:

Frequency of Testing:
- The model's performance will be reviewed on a quarterly basis, with additional ad-hoc reviews conducted as needed (e.g., after significant updates to the biased language categories or mapping dictionary).

Metrics to be Assessed:
- The key performance metrics to be monitored include:
  - True positive rate for the keyword-based detection stage
  - F1-score for the text classification stage
  - Overall accuracy in detecting prohibited language
  - False positive and false negative rates

Thresholds for Model Deterioration:
- The model's performance will be considered to have deteriorated if any of the following thresholds are breached:
  - True positive rate drops below 85% for the keyword-based detection
  - F1-score drops below 0.80 for the text classification stage
  - Overall accuracy in detecting prohibited language falls below 90%
  - False positive rate exceeds 15% or false negative rate exceeds 20%

Monitoring and Reporting:
- The performance monitoring results will be reported to the MF Lender Risk Management team and the Fair Lending team on a quarterly basis.
- Any significant performance issues or deterioration will be immediately escalated, and remedial actions will be taken to address the identified problems.

By implementing this comprehensive performance monitoring plan, the MFPLD model can be closely tracked and adjusted as needed to maintain its effectiveness in detecting prohibited language in multifamily appraisal and related documents.

8.2 Model Issues/Findings

The initial development and testing of the MFPLD model did not uncover any significant issues or findings that could not be adequately addressed. The key issues and findings that were addressed during this version of the model are as follows:

1. Refinement of Biased Language Categories and Mapping Dictionary:
   - Issue: The initial list of biased language categories and corresponding phrases provided by the Fair Lending team was found to be incomplete, leading to some false negatives in the model's performance.
   - Resolution: The Fair Lending team reviewed and expanded the biased language categories and mapping dictionary to ensure comprehensive coverage of prohibited language.

2. Optimization of Global Similarity Threshold:
   - Issue: The initial global similarity threshold of 0.50 resulted in a higher-than-desired false positive rate, leading to unnecessary manual review by the MF Lender Risk Management team.
   - Resolution: The global similarity threshold was adjusted to 0.55 based on the analysis of the similarity score distributions, which improved the balance between true positives and false positives.

3. Refinement of Text Classification Model:
   - Issue: The initial text classification model exhibited a relatively high false negative rate, missing some instances of prohibited language.
   - Resolution: The text classification model was fine-tuned using additional training data, resulting in improved performance with an F1-score of 0.88 on the held-out test dataset.

All identified issues have been successfully resolved, and the MFPLD model is now ready for deployment and ongoing monitoring as described in the performance monitoring plan. Any future issues or findings will be documented and addressed through the model adjustment and governance processes outlined in this white paper.

------------------------------------------------------------------------------------------------------------------

### 8. Model Governance (MD)

#### 8.1 Performance Monitoring Plan

The performance monitoring plan for the bias detection model in mortgage appraisal documents is designed to ensure the model's continued effectiveness, accuracy, and alignment with industry standards and practices. This plan is not subject to the Model Performance Tracking Standard but follows a rigorous internal framework to maintain the highest levels of model integrity and performance.

**Monitoring Frequency and Metrics:**

- **Frequency**: Model performance will be monitored quarterly, with additional ad-hoc reviews triggered by significant changes in appraisal practices, regulatory guidelines, or model performance metrics.
- **Metrics**: Key metrics include precision, recall, F1 score, and the rate of false positives/negatives. These metrics are chosen for their relevance in assessing the model's ability to accurately identify biased language in appraisal documents.
- **Thresholds**: Specific thresholds for each metric have been established, based on historical performance data and industry benchmarks. A deviation of 5% from these thresholds will trigger an in-depth review and potential model adjustment.

**Ongoing Monitoring Report Template**:

While the detailed monitoring report adheres to an internal template, it encompasses aspects such as:
- Comparison of current performance metrics against historical data and thresholds.
- Analysis of model performance across different document types and bias categories.
- Identification and analysis of any new types of bias or linguistic trends emerging in appraisal documents.

This structured approach to performance monitoring ensures that the model remains a reliable and effective tool for detecting bias in mortgage appraisals.

#### 8.2 Model Issues/Findings

**Closed Issues in This Version**:

- **Issue 1**: Previously identified discrepancies in the detection of subtle biases related to geographic location have been addressed through the refinement of the biased phrase dictionary and adjustment of embedding techniques.
- **Issue 2**: An enhancement in the preprocessing algorithm has resolved the issue of document structure variability impacting model performance.

**Open Issues**:

- **Issue 1**: The challenge of detecting biases in highly technical or nuanced property descriptions remains an area for improvement. Ongoing research and model training efforts are focused on this issue, with a targeted resolution in the next model update.
- **Issue 2**: The impact of document length on model performance has been identified as a potential area of concern, particularly for exceptionally long appraisal documents. A comprehensive analysis is underway to assess whether additional preprocessing steps or model adjustments are necessary.

Each closed issue has contributed to the refinement and enhancement of the model, ensuring its continued relevance and effectiveness. Open issues are actively managed, with research and development efforts aimed at their resolution in future model updates. This transparent and proactive approach to addressing model issues and findings is a cornerstone of the model's governance framework, ensuring its ongoing reliability and integrity.

88888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888


White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

9. Future Research

The MFPLD model has been designed as a robust and adaptable solution to address the current challenges faced by Fannie Mae's MF Lender Risk Management team in detecting prohibited language in multifamily appraisal and related documents. However, as the model is deployed and used over time, there may be opportunities for further research and enhancements to improve its performance and expand its capabilities.

Future research directions for the MFPLD model include:

1. Advanced Natural Language Processing Techniques:
   - Explore the use of more advanced NLP models, such as transformer-based language models (e.g., BERT, GPT-3), to further enhance the accuracy of sentence embeddings and the detection of nuanced biased language.
   - Investigate the potential of few-shot or zero-shot learning techniques to expand the model's ability to detect emerging forms of prohibited language without the need for extensive retraining.

2. Multimodal Bias Detection:
   - Expand the model's capabilities to detect biased language not only in textual documents but also in other forms of related content, such as images, graphs, or charts included in the appraisal and related documents.
   - Leverage computer vision and multimodal learning techniques to holistically analyze the entire document for potential biases.

3. Explainable AI:
   - Enhance the model's interpretability and explainability, allowing the MF Lender Risk Management team to better understand the reasoning behind the model's decisions and the specific biased language that was detected.
   - Explore the use of techniques like attention visualization, feature importance analysis, or rule extraction to provide more transparent insights into the model's inner workings.

4. Predictive Analytics:
   - Investigate the potential of using the MFPLD model's outputs to develop predictive analytics capabilities, helping the MF Lender Risk Management team to identify properties or appraisers that may be at a higher risk of using prohibited language.
   - Such predictive insights could enable proactive interventions and targeted training to address bias issues before they manifest in the appraisal process.

Release Priorities:

The initial release of the MFPLD model will focus on the core functionality of detecting prohibited language in multifamily appraisal and related documents, as described in the previous sections of this white paper. This release will establish a solid foundation for the model's deployment and ongoing use by the MF Lender Risk Management team.

Future release priorities for the MFPLD model will be determined based on the feedback and performance monitoring insights gathered from the initial deployment, as well as the evolving needs and priorities of Fannie Mae's multifamily lending business. The research directions outlined above will be evaluated and prioritized based on their potential impact and the available resources and development capacity.

By continuously exploring new research avenues and expanding the MFPLD model's capabilities, Fannie Mae can stay at the forefront of fair lending practices and ensure that the collateral valuation process for multifamily properties remains equitable and unbiased.

--------------------------------------------------------------------------------------------------------------------------------------

### 9. Future Research

The continuous evolution of the bias detection model in mortgage appraisal documents is crucial to maintaining its relevance, effectiveness, and alignment with industry standards and societal expectations. Future research directions and release priorities are shaped by the dual objectives of enhancing model accuracy and expanding its scope to address emerging challenges in bias detection. This section outlines the strategic areas of focus for future development and refinement of the model.

#### Enhancing Linguistic Sensitivity

**Objective**: Improve the model's ability to detect subtle and nuanced expressions of bias that may not be explicitly covered by the current biased phrase dictionary.

**Approach**: Incorporating advanced NLP techniques, such as contextual embeddings and language models trained on domain-specific corpora, to capture the evolving language of bias in real estate appraisals.

#### Expanding Bias Categories

**Objective**: Address emerging categories of bias that reflect changes in societal norms and regulatory focus, ensuring comprehensive coverage across all potential areas of bias in appraisals.

**Approach**: Conducting ongoing reviews of literature, legal cases, and industry guidelines related to bias in real estate, coupled with stakeholder consultations, to identify and incorporate new bias categories into the model.

#### Model Interpretability

**Objective**: Enhance the transparency and interpretability of the model's decision-making processes, facilitating easier review and validation of its findings by users.

**Approach**: Integrating explainability features and tools that provide insights into how the model arrives at its conclusions, particularly in terms of bias detection and categorization.

#### Data Diversity and Inclusivity

**Objective**: Ensure the model effectively addresses bias in a diverse range of property types and geographic locations, encompassing a broad spectrum of appraisal documents.

**Approach**: Diversifying the training and testing datasets to include a wider array of property types, appraisal contexts, and geographic regions. This effort includes actively seeking out datasets from underserved and underrepresented communities.

#### Technological Advancements

**Objective**: Leverage advancements in machine learning and natural language processing to continually improve the model's performance and efficiency.

**Approach**: Keeping abreast of emerging technologies and methodologies in NLP and AI, assessing their applicability to the model, and integrating those that offer significant benefits in terms of accuracy, speed, or scalability.

#### Release Priorities

1. **Short-Term**: Focus on immediate improvements in linguistic sensitivity and the integration of explainability features to enhance model transparency.
2. **Medium-Term**: Expand bias categories and refine the model's ability to handle a diverse range of appraisal documents, emphasizing inclusivity and comprehensiveness.
3. **Long-Term**: Incorporate cutting-edge AI and NLP technologies to ensure the model remains at the forefront of bias detection methodologies, setting industry standards for accuracy and reliability.

The outlined future research directions and release priorities underscore a commitment to continuous improvement and adaptation. By proactively addressing the dynamic nature of language, societal norms, and technological advancements, the model will continue to serve as a vital tool in the fight against bias in mortgage appraisals, promoting fairness and objectivity in property valuation processes.


9999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999

White Paper: Multifamily Prohibited Language Detection (MFPLD) Model

Appendix (A)

A. Model Code & Dataset Location

The MFPLD model development code and estimation data are stored in a secure, centralized repository accessible to the authorized members of the MF Lender Risk Management team and the model development team. The specific location and access instructions are as follows:

Model Development Code:
- Location: Fannie Mae's internal Git repository, project "MFPLD-Model"
- Access: Granted to members of the MF Lender Risk Management team and the model development team

Estimation Data:
- Location: Fannie Mae's internal data warehouse, dataset "MF_Appraisal_Data"
- Access: Granted to members of the MF Lender Risk Management team and the model development team

Any code related to model adjustments will be stored in the same Git repository, with clear versioning and change tracking to ensure proper governance and auditability.

B. Terminology and Acronyms

MFPLD: Multifamily Prohibited Language Detection
APLD: Automated Property Linguistic Detection
NLP: Natural Language Processing
IDE: Interactive Development Environment
MF: Multifamily
MLE: Maximum Likelihood Estimator
OLS: Ordinary Least Squares
LAR: Least Angle Regression
LASSO: Least Absolute Shrinkage and Selection Operator
MPT: Model Performance Tracking
MO: Model Owner
MD: Model Developer
MU: Model User

C. Additional Testing Materials (As Relevant)

Not applicable for this white paper, as the key model testing results and analyses have been included in the main body of the document.

D. References

Bolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V., & Kalai, A. T. (2016). Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. In Advances in neural information processing systems (pp. 4349-4357).

Howell, J., & Korver-Glenn, E. (2020). The Increasing Effect of Neighborhood Racial Composition on Housing Values, 1980–2015. Social Problems, 68(4), 1025-1044.

Perry, A. M., Rothwell, J., & Harshbarger, D. (2018). The devaluation of assets in Black neighborhoods: The case of residential property. Brookings Institution.

Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (pp. 3982-3992).

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).

Zhao, J., Wang, T., Yatskar, M., Ordonez, V., & Chang, K. W. (2017). Men also like shopping: Reducing gender bias amplification using corpus-level constraints. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 2979-2989).

E. Minor Model Change Memo

Not applicable for this initial white paper, as there are no minor model changes to report. Any future minor updates will be documented in this section.

--------------------------------------------------------------------------------------------------------------------
### Appendix (MD)

#### A. Model Code & Dataset Location

- **Location of Model Development Code and Data**: The code and datasets used for model development are stored in our secure internal repository, accessible to authorized personnel. Specific paths and access protocols are detailed in our internal documentation system.
- **IDE / Encapsulated Implementations**: Development was primarily conducted using Jupyter Notebooks, offering a versatile environment for code execution, visualization, and analysis. The location of encapsulated implementations for model adjustments is similarly stored within our secure repository.
- **Access Instructions**: Access to these resources requires authorization. Team members must request access through our IT support system, specifying the reason for access. Upon approval, credentials and detailed instructions for accessing the repositories will be provided.

#### B. Terminology and Acronyms

- **NLP (Natural Language Processing)**: A branch of artificial intelligence that helps computers understand, interpret, and manipulate human language.
- **Embedding**: A representation of text in a high-dimensional vector space, enabling similarity comparisons.
- **Cosine Similarity**: A metric used to measure how similar two vectors are in an N-dimensional space, often used in text analysis.
- **Bias Categories**: Predefined groups of biases identified for monitoring in the appraisal documents, such as gender, race, and location.
- **Global Similarity Threshold**: A predetermined value that sentences must exceed in similarity score to be considered potentially biased.

#### C. Additional Testing Materials

As relevant, this section would contain detailed outcomes from extensive testing phases, including performance metrics across various document sets, sensitivity analyses, and specific case studies illustrating the model's ability to detect nuanced biases. This material is housed in supplementary documentation, available upon request from the model development team.

#### D. References

- **Internal Documents**:
  - Model Development Guidelines.
  - Bias Detection Model Performance Review Q3 2024.

- **External Publications**:
  - Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. *arXiv*.
  - Capozza, D., Hendershott, P., & Mack, C. (2004). An Anatomy of Price Dynamics in Illiquid Markets: Analysis and Evidence from Local Housing Markets. *Real Estate Economics*, 32(1), 1-32.

#### E. Minor Model Change Memo

This section would document the specifics of minor updates to the model, such as adjustments to the biased phrase dictionary, updates to the global similarity threshold, or refinements in the preprocessing steps. Each entry includes a brief description of the change, the rationale behind it, and the expected impact on model performance. Major revisions are detailed in the body of the white paper to ensure comprehensive communication of significant enhancements or modifications.

---

This appendix serves as a comprehensive guide for accessing and understanding the resources, terminologies, and additional materials associated with the development and implementation of the bias detection model. It aims to facilitate a deeper understanding of the model's framework and operational context, ensuring transparency and accessibility for all stakeholders involved.












